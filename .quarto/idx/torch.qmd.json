{"title":"RNN and LSTM model","markdown":{"yaml":{"title":"RNN and LSTM model","subtitle":"Viá»‡t Nam, 2024","categories":["Machine Learning","Forecasting"],"format":{"html":{"code-fold":true,"code-tools":true}},"number-sections":true},"headingText":"Äá»‹nh nghÄ©a:","containsRefs":false,"markdown":"\n\ná» Ä‘Ã¢y ta sáº½ há»c vá» mÃ´ hÃ¬nh machine learning Ä‘Æ°á»£c á»©ng dá»¥ng nhiá»u nháº¥t trong viá»‡c phÃ¢n tÃ­ch dá»¯ liá»‡u thá»i gian lÃ  *RNN* vÃ  *LSTM*.\n\n\n### MÃ´ hÃ¬nh RNN:\n\nÄiá»ƒm chung lÃ  cáº£ hai mÃ´ hÃ¬nh Ä‘á»u thuá»™c phÃ¢n lá»›p *Deep learning* - nghÄ©a lÃ  há»c mÃ¡y sÃ¢u vá»›i Ä‘áº·c Ä‘iá»ƒm chung lÃ  phÃ¢n chia dá»¯ liá»‡u thÃ nh nhiá»u lá»›p vÃ  báº¯t Ä‘áº§u \"há»c\" dáº§n qua tá»«ng lá»›p Ä‘á»ƒ Ä‘Æ°a ra káº¿t quáº£ cuá»‘i cÃ¹ng. á» hÃ¬nh dÆ°á»›i Ä‘Ã¢y, $X_o$ Ä‘áº¡i diá»‡n cho dá»¯ liá»‡u Ä‘áº§u vÃ o, $h_t$ lÃ  output Ä‘áº§u ra cá»§a tá»«ng step vÃ  $A$ lÃ  nhá»¯ng gÃ¬ Ä‘Ã£ \"há»c\" Ä‘Æ°á»£c táº¡i step Ä‘Ã³ vÃ  Ä‘Æ°á»£c truyá»n cho step tiáº¿p theo. Trong tÃ i liá»‡u chuáº©n thÃ¬ há» thÆ°á»ng kÃ­ hiá»‡u lÃ  $X_t$, $Y_t$, $h_{t-1}$.\n\n```{=html}\n<div style=\"text-align: center; margin-bottom: 20px;\">\n  <img src=\"img/RNN.png\" style=\"max-width: 100%; height: auto; display: block; margin: 0 auto;\">\n  \n  <!-- Picture Name -->\n  <div style=\"text-align: left; margin-top: 10px;\">\n    HÃ¬nh 1: Minh há»a vá» sá»± phÃ¢n chia dá»¯ liá»‡u thÃ nh nhiá»u lá»›p\n  </div>\n  \n  <!-- Source Link -->\n  <div style=\"text-align: right; font-style: italic; margin-top: 5px;\">\n    Source: <a href=\"https://dominhhai.github.io/vi/2017/10/what-is-lstm/\" target=\"_blank\">Link to Image</a>\n  </div>\n</div>\n```\nKhi nhÃ¬n hÃ¬nh thÃ¬ báº¡n cÃ³ thá»ƒ bá»‘i rá»‘i chÆ°a hiá»ƒu cÃ¡c kÃ­ tá»± vÃ  hÃ¬nh áº£nh thÃ¬ báº¡n cÃ³ thá»ƒ tÆ°á»Ÿng tÆ°á»£ng **há»c mÃ¡y** nhÆ° 1 Ä‘á»©a tráº» vÃ  Ä‘á»ƒ nÃ³ cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c cÃ¢u: \"HÃ´m nay con Ä‘i há»c\" thÃ¬ nÃ³ pháº£i há»c tá»«ng chá»¯ cÃ¡i nhÆ°: a,b,c,... trÆ°á»›c rÃ²i má»›i ghÃ©p thÃ nh tá»« Ä‘Æ¡n nhÆ°: \"HÃ´m\",\"Nay\",... rá»“i ghÃ©p thÃ nh cÃ¢u trÃªn. Váº­y giáº£ sá»­ nhÆ° hÃ´m nay há»c Ä‘Æ°á»£c tá»« \"HÃ´m\" thÃ¬ nÃ³ sáº½ báº¯t Ä‘áº§u ghi nhá»› tá»« Ä‘Ã£ há»c vÃ o trong $A$. Náº¿u sau nÃ y ta cáº§n **há»c mÃ¡y** hiá»ƒu cÃ¢u \"HÃ´m sau con Ä‘i chÆ¡i\" thÃ¬ tá»‘c Ä‘á»™ há»c cá»§a **há»c mÃ¡y** sáº½ nhanh lÃªn vÃ¬ thay vÃ¬ nÃ³ pháº£i há»c 5 chá»¯ Ä‘Æ¡n nhÆ° thÃ´ng thÆ°á»ng thÃ¬ nÃ³ chá»‰ cáº§n há»c 4 chá»¯ cÃ²n láº¡i trá»« chá»¯ \"hÃ´m\". Váº­y báº¡n Ä‘Ã£ hiá»ƒu Ã½ tÆ°á»Ÿng ná»n táº£ng cá»§a *RNN* rá»“i ha!\n\nNáº¿u muá»‘n hiá»ƒu thÃªm vá» *RNN*, báº¡n cÃ³ thá»ƒ tham kháº£o link nÃ y: [Recurrent Neural Network: Tá»« RNN Ä‘áº¿n LSTM](https://viblo.asia/p/recurrent-neural-network-tu-rnn-den-lstm-gGJ597z1ZX2).\n\nVÃ  trong *RNN* cÃ³ 1 váº¥n Ä‘á» lá»›n lÃ  *Vanishing Gradient* nghÄ©a lÃ  mÃ´ hÃ¬nh sáº½ khÃ´ng cÃ²n \"há»c\" thÃªm Ä‘Æ°á»£c ná»¯a cho dÃ¹ tÄƒng sá»‘ `epochs`. Theo pháº§n chá»©ng minh cá»§a [anh Tuáº¥n](https://nttuan8.com/bai-14-long-short-term-memory-lstm/) cho tháº¥y *RNN* sáº½ luÃ´n xáº£y ra váº¥n Ä‘á» Ä‘Ã³ cho dÃ¹ báº¡n cÃ³ xÃ¢y dá»±ng mÃ´ hÃ¬nh tá»‘t nhÆ° tháº¿ nÃ o. Äiá»u nÃ y cÃ³ thá»ƒ hiá»ƒu Ä‘Æ¡n giáº£n nhÆ° viá»‡c báº¡n há»c liÃªn tá»¥c dáº«n tá»›i quÃ¡ táº£i. Do Ä‘Ã³, *RNN* chá»‰ há»c cÃ¡c thÃ´ng tin $A$ tá»« cÃ¡c step gáº§n nháº¥t vÃ  Ä‘Ã³ lÃ  lÃ­ do ra Ä‘á»i *LSTM - Long short term memory.*\n\n::: callout-warning\n<u>LÆ°u Ã½</u>: Äiá»u nÃ y khÃ´ng cÃ³ nghÄ©a *LSTM* luÃ´n tá»‘t hÆ¡n *RNN* vÃ¬ cÃ³ nhá»¯ng bÃ i toÃ¡n vá»›i Ä‘áº§u vÃ o Ä‘Æ¡n giáº£n thÃ¬ mÃ´ hÃ¬nh chá»‰ cáº§n há»c cÃ¡c step Ä‘áº§u lÃ  Ä‘Ã£ \"há»c\" Ä‘áº§y Ä‘á»§ thÃ´ng tin cáº§n thiáº¿t. \nMÃ´ hÃ¬nh *LSTM* phá»• biáº¿n vá»›i cÃ¡c bÃ i toÃ¡n phá»©c táº¡p nhÆ° tá»± Ä‘á»™ng dá»‹ch ngÃ´n ngá»¯, ghi chÃ©p láº¡i theo giá»ng nÃ³i...\n:::\n\n### MÃ´ hÃ¬nh LSTM:\n\nCÃ³ thá»ƒ xem mÃ´ hÃ¬nh *LSTM* nhÆ° biáº¿n thá»ƒ cá»§a *RNN*. Vá» cáº¥u trÃºc, *LSTM* cÃ³ ba cá»•ng chÃ­nh giÃºp nÃ³ xá»­ lÃ½ vÃ  duy trÃ¬ thÃ´ng tin qua cÃ¡c bÆ°á»›c thá»i gian:\n\n-   Cá»•ng quÃªn (Forget Gate): Quyáº¿t Ä‘á»‹nh thÃ´ng tin nÃ o cáº§n bá»‹ quÃªn trong tráº¡ng thÃ¡i Ã´ nhá»›.\n\n-   Cá»•ng nháº­p (Input Gate): XÃ¡c Ä‘á»‹nh thÃ´ng tin nÃ o cáº§n Ä‘Æ°á»£c ghi vÃ o tráº¡ng thÃ¡i Ã´ nhá»›.\n\n-   Cá»•ng xuáº¥t (Output Gate): Quyáº¿t Ä‘á»‹nh thÃ´ng tin nÃ o sáº½ Ä‘Æ°á»£c xuáº¥t ra tá»« tráº¡ng thÃ¡i Ã´ nhá»› Ä‘á»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n dá»± Ä‘oÃ¡n tiáº¿p theo.\n\n## XÃ¢y dá»±ng mÃ´ hÃ¬nh:\n\n### Load dá»¯ liá»‡u:\n\nÄáº§u tiÃªn ta sáº½ load dá»¯ liá»‡u láº¡i nhÆ° trÆ°á»›c. á» Ä‘Ã¢y, Ä‘á»ƒ Ä‘Æ¡n giáº£n, mÃ¬nh chá»‰ xÃ¢y dá»±ng mÃ´ hÃ¬nh cho *product A* thÃ´i.\n\n```{r}\n#| include: false\n#| warning: false\n#| message: false\npacman::p_load(\njanitor,\ntidyverse,\ndplyr,\ntidyr,\nmagrittr,\nggplot2)\n```\n\n```{r}\n#| include: false\n# Set the start and end date for the 6-month period\nstart_date <- as.Date(\"2024-05-01\")\nend_date <- as.Date(\"2024-10-31\")\n\n# Generate date range\ndates <- seq.Date(start_date, \n                  end_date, \n                  by = \"day\")\n\n# Set a random seed for reproducibility\nset.seed(42)\n\n# Create a vector of weekdays for each date\nweekdays <- weekdays(dates)\n\n# Simulate sales data for Product A, B, and C based on weekday patterns\nproduct_a_sales <- sample(5:50, length(dates), replace = TRUE)\nproduct_b_sales <- sample(3:40, length(dates), replace = TRUE)\nproduct_c_sales <- sample(2:30, length(dates), replace = TRUE)\n\n# Adjust sales based on the weekday\nfor (i in 1:length(dates)) {\n  if (weekdays[i] == \"Wednesday\" | weekdays[i] == \"Saturday\") {\n    # High demand for Product A and B on Wednesday and Saturday\n    product_a_sales[i] <- sample(40:70, 1)\n    product_b_sales[i] <- sample(30:60, 1)\n  } else if (weekdays[i] == \"Monday\" | weekdays[i] == \"Tuesday\") {\n    # High demand for Product C on Monday and Tuesday\n    product_c_sales[i] <- sample(20:40, 1)\n  }\n}\n\n# Create a data frame with the adjusted sales data\nsales_data <- data.frame(\n  Date = dates,\n  Weekday = weekdays,\n  Product_A = product_a_sales,\n  Product_B = product_b_sales,\n  Product_C = product_c_sales\n)\n```\n\nGiáº£ sá»­ cÃ´ng ty mÃ¬nh Ä‘ang kinh doanh 3 loáº¡i máº·t hÃ ng *product A*,*product B*,*product C* vÃ  Ä‘Ã¢y lÃ  biá»ƒu Ä‘á»“ thá»ƒ hiá»‡n nhu cáº§u cá»§a cáº£ 3 máº·t hÃ ng tá»« thÃ¡ng 5 tá»›i thÃ¡ng 10.\n\n```{r}\n#| warning: false\n#| message: false\nlibrary(highcharter)\nsales_data |> \n  select(-Weekday) |> \n  pivot_longer(cols = c(Product_A, Product_B, Product_C),\n               names_to = \"Product\",\n               values_to = \"Sales\") |> \n  hchart(\"line\", hcaes(x = Date, y = Sales, group = Product))\n```\n\nNáº¿u ta phÃ¢n tich sÃ¢u vá» nhu cáº§u cá»§a tá»«ng máº·t hÃ ng theo thá»© trong tuáº§n, ta sáº½ tháº¥y ráº±ng máº·t hÃ ng A, B thÃ¬ bÃ¡n cháº¡y vÃ o thá»© 4 vÃ  thá»© 7, cÃ²n máº·t hÃ ng C thÃ¬ bÃ¡n cháº¡y vÃ o thá»© 2 vÃ  thá»© 3.\n\n::: panel-tabset\n\n##### Product A:\n```{r}\n#| warning: false\n#| message: false\n#| echo: false\nmA<-sales_data |> \n  select(Date, \n         Weekday,\n         Product_A)  \n\n# Ensure 'Weekday' is a factor with the correct order\nmA$Weekday <- factor(mA$Weekday, \n                     levels = c(\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"))\n\nhcboxplot(\n    x = mA$Product_A,\n    var = mA$Weekday,\n    name = \"Weekday sales\") |> \n  hc_title(text = \"Comparing sales data between weekday\") |> \n  hc_yAxis(title = list(text = \"No.product\")) |> \n  hc_chart(type = \"column\")\n```\n\n##### Product B:\n```{r}\n#| warning: false\n#| message: false\n#| echo: false\nmB<-sales_data |> \n  select(Date, \n         Weekday,\n         Product_B)  \n\n# Ensure 'Weekday' is a factor with the correct order\nmA$Weekday <- factor(mB$Weekday, \n                     levels = c(\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"))\n\nhcboxplot(\n    x = mB$Product_B,\n    var = mB$Weekday,\n    name = \"Weekday sales\") |> \n  hc_title(text = \"Comparing sales data between weekday\") |> \n  hc_yAxis(title = list(text = \"No.product\")) |> \n   hc_chart(type = \"column\")\n```\n\n##### Product C:\n```{r}\n#| warning: false\n#| message: false\n#| echo: false\nmC<-sales_data |> \n  select(Date, \n         Weekday,\n         Product_C)  \n\n# Ensure 'Weekday' is a factor with the correct order\nmA$Weekday <- factor(mC$Weekday, \n                     levels = c(\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"))\n\nhcboxplot(\n    x = mC$Product_C,\n    var = mC$Weekday,\n    name = \"Weekday sales\") |> \n  hc_title(text = \"Comparing sales data between weekday\") |> \n  hc_yAxis(title = list(text = \"No.product\")) |> \n   hc_chart(type = \"column\")\n```\n:::\n\n```{r}\n#| warning: false\n#| message: false\n#| include: false\nlibrary(tidyverse)\n# Set the start and end date for the 6-month period\nstart_date <- as.Date(\"2024-05-01\")\nend_date <- as.Date(\"2024-10-31\")\n\n# Generate date range\ndates <- seq.Date(start_date, \n                  end_date, \n                  by = \"day\")\n\n# Set a random seed for reproducibility\nset.seed(42)\n\n# Create a vector of weekdays for each date\nweekdays <- weekdays(dates)\n\n# Simulate sales data for Product A, B, and C based on weekday patterns\nproduct_a_sales <- sample(5:50, length(dates), replace = TRUE)\nproduct_b_sales <- sample(3:40, length(dates), replace = TRUE)\nproduct_c_sales <- sample(2:30, length(dates), replace = TRUE)\n\n# Adjust sales based on the weekday\nfor (i in 1:length(dates)) {\n  if (weekdays[i] == \"Wednesday\" | weekdays[i] == \"Saturday\") {\n    # High demand for Product A and B on Wednesday and Saturday\n    product_a_sales[i] <- sample(40:70, 1)\n    product_b_sales[i] <- sample(30:60, 1)\n  } else if (weekdays[i] == \"Monday\" | weekdays[i] == \"Tuesday\") {\n    # High demand for Product C on Monday and Tuesday\n    product_c_sales[i] <- sample(20:40, 1)\n  }\n}\n```\n\nThÃ´ng thÆ°á»ng dá»¯ liá»‡u Ä‘á»ƒ *train model* trong *machine learning* thÆ°á»ng cáº§n tráº£i qua bÆ°á»›c *normalize data* nghÄ©a lÃ  Ä‘Æ°a táº¥t cáº£ dá»¯ liá»‡u vá» chung 1 thÆ°á»›c Ä‘o vÃ  pháº¡m vi. NguyÃªn do vÃ¬ Ä‘iá»u nÃ y giÃºp nhiá»u thuáº­t toÃ¡n há»c mÃ¡y dá»… dÃ ng há»™i tá»¥ hÆ¡n. VÃ­ dá»¥, cÃ¡c thuáº­t toÃ¡n nhÆ° *k-Nearest Neighbors (KNN)* vÃ  *Support Vector Machines (SVM)* ráº¥t nháº¡y cáº£m vá»›i khoáº£ng cÃ¡ch giá»¯a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u nÃªn náº¿u dá»¯ liá»‡u khÃ´ng Ä‘Æ°á»£c chuáº©n hÃ³a, thuáº­t toÃ¡n cÃ³ thá»ƒ Æ°u tiÃªn cÃ¡c Ä‘áº·c trÆ°ng cÃ³ pháº¡m vi lá»›n hÆ¡n vÃ  bá» qua cÃ¡c Ä‘áº·c trÆ°ng cÃ³ pháº¡m vi nhá» hÆ¡n, dáº«n Ä‘áº¿n hiá»‡u suáº¥t kÃ©m. VÃ  cÃ´ng thá»©c phá»• biáº¿n nháº¥t cho chuáº©n hÃ³a lÃ :\n\n$$\n\\text{Normalized Value} = \\frac{x - \\min(x)}{\\max(x) - \\min(x)}\n$$\n\n```{r}\n#| warning: false\n#| message: false\n# Create a data frame with the adjusted sales data\nsales_data <- data.frame(\n  Date = dates,\n  Weekday = weekdays,\n  Product_A = product_a_sales,\n  Product_B = product_b_sales,\n  Product_C = product_c_sales\n)\n\n# Convert the sales data to a time series (ts) object for Product A\nproduct_a_ts <- ts(sales_data$Product_A, start = c(2024, 5), \n                   frequency = 365)\n                   \n\n# Normalzie data:\ntime_series_data<-scale(product_a_ts)\n\nlibrary(highcharter)\nhighchart() %>%\n  hc_add_series(data = as.numeric(time_series_data), type = \"line\", name = \"Sales of Product A\") %>%\n  hc_title(text = \"Normalized Time Series of Product A\") %>%\n  hc_xAxis(title = list(text = \"Date\")) %>%\n  hc_yAxis(title = list(text = \"Normalized Sales\")) %>%\n  hc_tooltip(shared = TRUE) %>%\n  hc_plotOptions(line = list(marker = list(enabled = FALSE)))\n```\n\n### Chia dá»¯ liá»‡u:\n\nVáº­y Ä‘á»ƒ *train data*, mÃ¬nh sáº½ chia bá»™ dá»¯ liá»‡u thÃ nh 3 pháº§n:\n\n-   *Training data*: dÃ¹ng Ä‘á»ƒ huáº¥n luyá»‡n vÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh.\n\n-   *Evaluating data*: Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh vá»«a huáº¥n luyá»‡n.\n\n-   *Testing data*: dÃ¹ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ láº¡i náº¿u muá»‘n mÃ´ hÃ¬nh há»c láº¡i dá»¯ liá»‡u\n\n```{r}\n#| warning: false\n#| message: false\nlibrary(keras)\nlibrary(tensorflow)\nlibrary(dplyr)\n\n# Function to create supervised learning format from time series\ncreate_supervised_data <- function(series, n_in = 1, n_out = 1) {\n  series <- as.vector(series)  # Convert time series object to vector\n  data <- data.frame(series)\n  \n  # Use base R lag function for ts objects (lag() from stats package)\n  for (i in 1:n_in) {\n    data <- cbind(data, stats::lag(series, -i))\n  }\n  \n  colnames(data) <- c(paste0('t-', 1:n_in), 't+1')  # Correctly name columns\n  return(data)\n}\n\n# Prepare the data with 12 input lags and 1 output (next time step)\nsupervised_data <- create_supervised_data(time_series_data,\n                                          n_in = 12, \n                                          n_out = 1)\n\n# Remove NA rows created by lag function\nsupervised_data <- na.omit(supervised_data)\n\n# Step 2: Split data into training and test sets\ntrain_size <- round(0.7 * nrow(supervised_data))   # 70% for training\nval_size <- round(0.1 * nrow(supervised_data))     # 10% for validation\ntest_size <- nrow(supervised_data) - train_size - val_size  # 20% for testing\n\ntrain_data <- supervised_data[1:train_size, ]\nval_data <- supervised_data[(train_size + 1):(train_size + val_size), ]\ntest_data <- supervised_data[(train_size + val_size + 1):nrow(supervised_data), ]\n\n# Correct column selection\nx_train <- as.matrix(train_data[, 1:12])  # Input features (12 lags)\ny_train <- as.matrix(train_data[, 't+1'])  # Target output (next time step)\n\nx_val <- as.matrix(val_data[, 1:12])  # Input features for validation\ny_val <- as.matrix(val_data[, 't+1'])  # Actual output for validation\n\nx_test <- as.matrix(test_data[, 1:12])  # Input features for testing\ny_test <- as.matrix(test_data[, 't+1'])  # Actual output for testing\n\n\n## Plot the result:\nlibrary(xts)\nn<-quantile(sales_data$Date, \n            probs = c(0, 0.7, 0.8,1), \n            type = 1)\n\nm1<-sales_data %>% \n  filter(Date <= n[[2]])\nm2<-sales_data %>% \n  filter(Date <= n[[3]] & Date > n[[2]])\nm3<-sales_data %>% \n  filter(Date <= n[[4]] & Date > n[[3]])\n\ndemand_training<-xts(x=m1$Product_A,\n                     order.by=m1$Date)\ndemand_testing<-xts(x=m2$Product_A,\n                     order.by=m2$Date)\ndemand_forecasting<-xts(x=m3$Product_A,\n                     order.by=m3$Date)\n\nlibrary(dygraphs)\nlines<-cbind(demand_training,\n             demand_testing,\n             demand_forecasting)\ndygraph(lines,\n        main = \"Training and testing data\", \n        ylab = \"Quantity order (Unit: Millions)\") %>% \n  dySeries(\"demand_training\", label = \"Training data\") %>%\n  dySeries(\"demand_testing\", label = \"Testing data\") %>%\n  dySeries(\"demand_forecasting\", label = \"Forecasting data\") %>%\n  dyOptions(fillGraph = TRUE, fillAlpha = 0.4) %>% \n  dyRangeSelector(height = 20)\n```\n\n### MÃ´ hÃ¬nh RNN:\n\nSau Ä‘Ã³, ta sáº½ báº¯t Ä‘áº§u *train model* báº±ng cÃ¡ch táº¡o thÃªm 12 cá»™t giÃ¡ trá»‹ lÃ  giÃ¡ trá»‹ quÃ¡ khá»© cá»§a *demand*. Báº¡n sáº½ báº¯t Ä‘áº§u Ä‘á»‹nh nghÄ©a mÃ´ hÃ¬nh gá»“m:\n\n-   *Input*: dÃ¹ng hÃ m `layer_input(shape = input_shape)` vá»›i `input_shape` lÃ  sá»‘ lÆ°á»£ng *predictor*.\n\n-   *Layer*: lÃ  cÃ¡c hidden layer trong mÃ´ hÃ¬nh thÃªm vÃ o báº±ng hÃ m `layer_dense(x, units = 64, activation = 'relu')` vá»›i Ä‘á»‘i sá»‘ `units` thÆ°á»ng lÃ  bá»™i sá»‘ cá»§a 32 nhÆ° 32,64,256,...\n\n-   *Output*: dÃ¹ng hÃ m `layer_dense(x, units = 1)` Ä‘á»ƒ Ä‘á»‹nh nghÄ©a lÃ  Ä‘áº§u ra chá»‰ cÃ³ 1 giÃ¡ trá»‹.\n\n```{r}\n# Step 3: Build a simple transformer-like model\nRNN_model <- function(input_shape) {\n  inputs <- layer_input(shape = input_shape)\n\n  # Transformer Encoder Layer (simplified)\n  x <- inputs\n  x <- layer_dense(x, units = 64, activation = 'relu')  # Dense layer\n  x <- layer_dense(x, units = 32, activation = 'relu')  # Another dense layer\n\n  # Output layer\n  x <- layer_dense(x, units = 1)\n  \n  model <- keras_model(inputs, x)\n  return(model)\n}\n\n# Example input shape (12 time steps input per sample)\ninput_shape <- c(12)\n\nRNN_model <- RNN_model(input_shape)\n```\n\n```{r}\n#| warning: false\n#| message: false\n#| include: false\n# Step 4: Compile the model\nRNN_model %>% compile(\n  loss = 'mse',\n  optimizer = optimizer_adam(),\n  metrics = c('mae')\n)\n\n# Step 5: Train the model\nRNN_history <- RNN_model %>% fit(\n  x_train, \n  y_train,\n  epochs = 50, \n  batch_size = 32,\n  validation_data = list(x_val, y_val)\n)\n\nRNN_result <- RNN_model %>% \n    evaluate(x_test, y_test)\n```\n\nÄá»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh truyá»n thá»‘ng nhÆ° *linear regression* thÃ¬ báº¡n Ä‘Ã£ quen vá»›i thÃ´ng sá»‘ $R^2$ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh, cÃ²n vá»›i mÃ´ hÃ¬nh *Machine learning* thÃ¬ dÃ¹ng khÃ¡i niá»‡m *loss function - hÃ m máº¥t mÃ¡t*. Vá» khÃ¡i niá»‡m, *loss function* sáº½ Ä‘o lÆ°á»ng chÃªnh lá»‡ch giá»¯a *predicted* vÃ  *actual* trong bá»™ *training data* nÃªn khi cÃ ng tÄƒng `epochs` nghÄ©a lÃ  tÄƒng sá»‘ láº§n há»c láº¡i dá»¯ liá»‡u thÃ¬ *loss function* sáº½ tÃ­nh ra giÃ¡ trá»‹ cÃ ng tháº¥p. NhÆ° mÃ´ hÃ¬nh trÃªn thÃ¬ mÃ¬nh Ä‘áº·t Ä‘á»‘i sá»‘ `loss = mse` nghÄ©a lÃ  sá»­ dá»¥ng *Mean Squared Error* Ä‘á»ƒ tá»‘i Æ°u quy trÃ¬nh há»c cá»§a há»c mÃ¡y. CÃ´ng thá»©c nhÆ° sau:\n\n$$\nMSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_{\\text{pred}}(i) - y_{\\text{true}}(i))^2\n$$\n\nCÃ²n Ä‘á»‘i sá»‘ `metrics = c('mae')` nghÄ©a lÃ  tiÃªu chÃ­ khÃ¡c Ä‘á»ƒ theo dÃµi vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh. Váº­y táº¡i sao cáº§n cÃ³ 2 tham sá»‘ Ä‘Ã¡nh giÃ¡ song song nhÆ° váº­y lÃ  vÃ¬ nhÆ° Ä‘Ã£ nÃ³i, náº¿u báº¡n cÃ ng tÄƒng `epochs` thÃ¬ giÃ¡ trá»‹ *loss* cÃ ng tháº¥p trong khi dÃ¹ng `metrics` sáº½ Ä‘Æ°a ra Ä‘Ã¡nh giÃ¡ khÃ¡ch quan hÆ¡n vá» mÃ´ hÃ¬nh mÃ  khÃ´ng phá»¥ thuá»™c vÃ o sá»‘ láº§n `epochs`. CÃ´ng thá»©c nhÆ° sau:\n\n$$\n\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_{\\text{pred}}(i) - y_{\\text{true}}(i)|\n$$\n\nVáº­y khi cháº¡y code, R sáº½ return output nhÆ° biá»ƒu Ä‘á»“ dÆ°á»›i Ä‘Ã¢y lÃ  so sÃ¡nh tham sá»‘ cá»§a *mse* vÃ  *mae* giá»¯a *training data* vÃ  *evaluating data*. Ã tÆ°á»Ÿng lÃ  Ä‘Ã¡nh giÃ¡ thá»­ mÃ´ hÃ¬nh cÃ³ dá»± Ä‘oÃ¡n tá»‘t khÃ´ng khi cÃ³ dá»¯ liá»‡u má»›i vÃ o.\n\nTiáº¿p theo, ta sáº½ dÃ¹ng *test data* Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh vá»«a xÃ¢y dá»±ng. Káº¿t quáº£ cÃ³ váº» khÃ¡ tuyá»‡t vÃ¬ mÃ´ hÃ¬nh gáº§n nhÆ° theo sÃ¡t Ä‘Æ°á»£c dá»¯ liá»‡u cá»§a *test data*.\n\n```{r}\n# Step 6: Make predictions\nRNN_forecast <- RNN_model %>% \n  predict(x_test)\n\n# Step 7: Combine predicted and observed\nplot_data <- data.frame(\n  time = c(min(m3$Date)-days(1),m3$Date),  # Time for the test set\n  actual = y_test,  # Actual values from the test set\n  forecast = RNN_forecast  # Forecasted values\n)\n\n# Step 8: Plot using Highcharts\nhighchart() %>%\n  hc_title(text = \"Time Series Forecasting with Highcharts\") %>%\n  hc_xAxis(\n    categories = plot_data$time,\n    title = list(text = \"Time\")\n  ) %>%\n  hc_yAxis(\n    title = list(text = \"Value\"),\n    plotLines = list(list(\n      value = 0,\n      width = 1,\n      color = \"gray\"\n    ))\n  ) %>%\n  hc_add_series(\n    name = \"Actual Data\",\n    data = plot_data$actual,\n    type = \"line\",\n    color = \"#1f77b4\"  # Blue color for actual data\n  ) %>%\n  hc_add_series(\n    name = \"Forecast\",\n    data = plot_data$forecast,\n    type = \"line\",\n    color = \"#ff7f0e\"  # Orange color for forecast data\n  ) %>%\n  hc_tooltip(\n    shared = TRUE,\n    crosshairs = TRUE\n  ) %>%\n  hc_legend(\n    enabled = TRUE\n  )\n```\n\n### MÃ´ hÃ¬nh LSTM:\n\nTiáº¿p theo, ta sáº½ xÃ¢y dá»±ng thá»­ mÃ´ hÃ¬nh *LSTM*. MÃ´ hÃ¬nh LSTM thÆ°á»ng bao gá»“m cÃ¡c lá»›p sau:\n\n-   Lá»›p LSTM: ÄÃ¢y lÃ  lá»›p chÃ­nh, cÃ³ thá»ƒ cÃ³ má»™t hoáº·c nhiá»u lá»›p LSTM chá»“ng lÃªn nhau. Má»—i lá»›p LSTM cÃ³ thá»ƒ tráº£ vá» toÃ n bá»™ chuá»—i báº±ng `return_sequences = TRUE` hoáº·c chá»‰ tráº£ vá» giÃ¡ trá»‹ cuá»‘i cÃ¹ng báº±ng `return_sequences = FALSE`.\n\n-   Lá»›p Dense: Sau khi thÃ´ng tin Ä‘Æ°á»£c xá»­ lÃ½ qua cÃ¡c lá»›p LSTM, nÃ³ sáº½ Ä‘Æ°á»£c Ä‘Æ°a qua cÃ¡c lá»›p Dense (lá»›p fully connected) Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n cuá»‘i cÃ¹ng.\n\n-   Lá»›p Dropout (tÃ¹y chá»n): Äá»ƒ trÃ¡nh overfitting, cÃ³ thá»ƒ thÃªm lá»›p dropout Ä‘á»ƒ táº¯t ngáº«u nhiÃªn má»™t sá»‘ nÆ¡-ron trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n.\n\n```{r}\n#| warning: false\n#| message: false\n#| include: false\n# Step 3: Build an enhanced LSTM model\nLSTM_model <- function(input_shape) {\n  # Define input layer\n  inputs <- layer_input(shape = input_shape)\n  \n  # First LSTM layer (returns the full sequence for the next layer)\n  x <- layer_lstm(units = 50, return_sequences = TRUE, activation = 'tanh')(inputs)\n  \n  # Second LSTM layer (returns the full sequence, could also be 'return_sequences = FALSE' for output prediction)\n  x <- layer_lstm(units = 50, return_sequences = FALSE, activation = 'tanh')(x)\n  \n  # Output layer (prediction for the next time step)\n  outputs <- layer_dense(units = 1)(x)\n  \n  # Create the model\n  model <- keras_model(inputs, outputs)\n  \n  # Return the model\n  return(model)\n}\n\n\n# Update input shape for LSTM (timesteps = 12, features = 1)\ninput_shape <- c(12, 1)\n\n# Reshape the input data for LSTM (add a feature dimension)\nx_train <- array_reshape(x_train, dim = c(nrow(x_train), 12, 1))\nx_test <- array_reshape(x_test, dim = c(nrow(x_test), 12, 1))\nx_val <- array_reshape(x_val, dim = c(nrow(x_val), 12, 1))\n\n# Build the enhanced LSTM model\nLSTM_model <- LSTM_model(input_shape)\n\n# Step 4: Compile the model\nLSTM_model %>% compile(\n  loss = 'mse',\n  optimizer = optimizer_adam(),\n  metrics = c('mae')\n)\n\n# Step 5: Train the model\nLSTM_history <- LSTM_model %>% fit(\n  x_train, y_train,\n  epochs = 50, batch_size = 32,\n  validation_data = list(x_val, y_val)\n)\n\nLSTM_result <- LSTM_model %>% \n    evaluate(x_test, y_test)\n```\n\nVáº­y giá» ta sáº½ so sÃ¡nh vá»›i mÃ´ hÃ¬nh *RNN* trÆ°á»›c vá»›i mÃ´ hÃ¬nh *LSTM* qua 2 thÃ´ng sá»‘ Ä‘Ã£ chá»n *mse* vÃ  *mae*.\n\n```{r}\n#| warning: false\n#| message: false\n# Extract metrics into a data frame\nresults_df <- data.frame(\n  Model = c(\"RNN\", \"LSTM\"),\n  Metric = c(\"Loss\", \"metric\"),\n  MSE = c(RNN_result[[1]],RNN_result[[2]]),\n  MAE = c(LSTM_result[[1]], LSTM_result[[2]])\n)\n\nlibrary(gt)\n# Create a gt table\nresults_df %>%\n  gt() %>%\n  tab_header(\n    title = \"Model Performance Metrics\",\n    subtitle = \"Comparison of MSE and MAE for RNN and LSTM\"\n  ) %>%\n  fmt_number(\n    columns = vars(MSE, MAE),\n    decimals = 4\n  ) %>%\n  cols_label(\n    Model = \"Model Type\",\n    MSE = \"Mean Squared Error\",\n    MAE = \"Mean Absolute Error\"\n  ) %>%\n  tab_options(\n    table.font.size = 14,\n    heading.title.font.size = 16,\n    heading.subtitle.font.size = 14\n  )\n```\n\nKáº¿t quáº£ cho tháº¥y mÃ´ hÃ¬nh *RNN* truyá»n thá»‘ng Ä‘Æ°a ra káº¿t quáº£ tá»‘t hÆ¡n *LSTM* máº·c dÃ¹ sai sá»‘ cá»§a *LSTM* Ä‘á»u \\< 0.03 lÃ  khÃ´ng quÃ¡ tá»‡ nhÆ°ng tiÃªu chÃ­ váº«n lÃ  mÃ´ hÃ¬nh nÃ o hiá»‡u quáº£ nháº¥t.\n\n```{r}\nLSTM_forecast <- LSTM_model %>% \n  predict(x_test)\n\ncompare<-data.frame(Date = c(min(m3$Date)-days(1),m3$Date),\n                    LSTM = round(LSTM_forecast - y_test,3),\n                    RNN = round(RNN_forecast - y_test,3)\n)\n\n# Create the highchart plot\nhighchart() %>%\n  hc_chart(type = \"line\") %>%\n  hc_title(text = \"Residual Comparison: LSTM vs RNN\") %>%\n  hc_xAxis(\n    categories = compare$Date,\n    title = list(text = \"Date\")\n  ) %>%\n  hc_yAxis(\n    title = list(text = \"Residuals\"),\n    plotLines = list(\n      list(value = 0, color = \"gray\", width = 1, dashStyle = \"Dash\")\n    )\n  ) %>%\n  hc_add_series(\n    name = \"LSTM Residuals\",\n    data = compare$LSTM,\n    color = \"#1f77b4\"\n  ) %>%\n  hc_add_series(\n    name = \"RNN Residuals\",\n    data = compare$RNN,\n    color = \"#ff7f0e\"\n  ) %>%\n  hc_tooltip(shared = TRUE) %>%\n  hc_legend(enabled = TRUE)\n```\n\n\n## Káº¿t luáº­n:\n\nNhÆ° váº­y, chÃºng ta Ä‘Ã£ Ä‘Æ°á»£c há»c vá» thuáº­t toÃ¡n Genetic vÃ  mÃ´ hÃ¬nh MILP cÅ©ng nhÆ° cÃ¡ch thá»±c hiá»‡n trong Rstudio.\n\nNáº¿u báº¡n cÃ³ cÃ¢u há»i hay tháº¯c máº¯c nÃ o, Ä‘á»«ng ngáº§n ngáº¡i liÃªn há»‡ vá»›i mÃ¬nh qua Gmail. BÃªn cáº¡nh Ä‘Ã³, náº¿u báº¡n muá»‘n xem láº¡i cÃ¡c bÃ i viáº¿t trÆ°á»›c Ä‘Ã¢y cá»§a mÃ¬nh, hÃ£y nháº¥n vÃ o hai nÃºt dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ truy cáº­p trang **Rpubs** hoáº·c mÃ£ nguá»“n trÃªn **Github**. Ráº¥t vui Ä‘Æ°á»£c Ä‘á»“ng hÃ nh cÃ¹ng báº¡n, háº¹n gáº·p láº¡i! ğŸ˜„ğŸ˜„ğŸ˜„\n\n```{=html}\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Contact Me</title>\n    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css\">\n    <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/simple-icons@v6.0.0/svgs/rstudio.svg\">\n    <style>\n        body { font-family: Arial, sans-serif; background-color: $secondary-color; }\n        .container { max-width: 400px; margin: auto; padding: 20px; background: white; border-radius: 8px; box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1); }\n        label { display: block; margin: 10px 0 5px; }\n        input[type=\"email\"] { width: 100%; padding: 10px; margin-bottom: 15px; border: 1px solid #ccc; border-radius: 4px; }\n        .github-button, .rpubs-button { margin-top: 20px; text-align: center; }\n        .github-button button, .rpubs-button button { background-color: #333; color: white; border: none; padding: 10px; cursor: pointer; border-radius: 4px; width: 100%; }\n        .github-button button:hover, .rpubs-button button:hover { background-color: #555; }\n        .rpubs-button button { background-color: #75AADB; }\n        .rpubs-button button:hover { background-color: #5A9BC2; }\n        .rpubs-icon { margin-right: 5px; width: 20px; vertical-align: middle; filter: brightness(0) invert(1); }\n        .error-message { color: red; font-size: 0.9em; margin-top: 5px; }\n    </style>\n</head>\n<body>\n    <div class=\"container\">\n        <h2>Contact Me</h2>\n        <form id=\"emailForm\">\n            <label for=\"email\">Your Email:</label>\n            <input type=\"email\" id=\"email\" name=\"email\" required aria-label=\"Email Address\">\n            <div class=\"error-message\" id=\"error-message\" style=\"display: none;\">Please enter a valid email address.</div>\n            <button type=\"submit\">Send Email</button>\n        </form>\n        <div class=\"github-button\">\n            <button>\n                <a href=\"https://github.com/Loccx78vn/Time_series_forcasting\" target=\"_blank\" style=\"color: white; text-decoration: none;\">\n                    <i class=\"fab fa-github\"></i> View Code on GitHub\n                </a>\n            </button>\n        </div>\n        <div class=\"rpubs-button\">\n            <button>\n                <a href=\"https://rpubs.com/loccx\" target=\"_blank\" style=\"color: white; text-decoration: none;\">\n                    <img src=\"https://cdn.jsdelivr.net/npm/simple-icons@v6.0.0/icons/rstudio.svg\" alt=\"RStudio icon\" class=\"rpubs-icon\"> Visit my RPubs\n                </a>\n            </button>\n        </div>\n    </div>\n\n    <script>\n        document.getElementById('emailForm').addEventListener('submit', function(event) {\n            event.preventDefault(); // Prevent default form submission\n            const emailInput = document.getElementById('email');\n            const email = emailInput.value;\n            const errorMessage = document.getElementById('error-message');\n\n            // Simple email validation regex\n            const emailPattern = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n\n            if (emailPattern.test(email)) {\n                errorMessage.style.display = 'none'; // Hide error message\n                const yourEmail = 'loccaoxuan103@gmail.com'; // Your email\n                const gmailLink = `https://mail.google.com/mail/?view=cm&fs=1&to=${yourEmail}&su=Help%20Request%20from%20${encodeURIComponent(email)}`;\n                window.open(gmailLink, '_blank'); // Open in new tab\n            } else {\n                errorMessage.style.display = 'block'; // Show error message\n            }\n        });\n    </script>\n</body>\n</html>\n```","srcMarkdownNoYaml":"\n\ná» Ä‘Ã¢y ta sáº½ há»c vá» mÃ´ hÃ¬nh machine learning Ä‘Æ°á»£c á»©ng dá»¥ng nhiá»u nháº¥t trong viá»‡c phÃ¢n tÃ­ch dá»¯ liá»‡u thá»i gian lÃ  *RNN* vÃ  *LSTM*.\n\n## Äá»‹nh nghÄ©a:\n\n### MÃ´ hÃ¬nh RNN:\n\nÄiá»ƒm chung lÃ  cáº£ hai mÃ´ hÃ¬nh Ä‘á»u thuá»™c phÃ¢n lá»›p *Deep learning* - nghÄ©a lÃ  há»c mÃ¡y sÃ¢u vá»›i Ä‘áº·c Ä‘iá»ƒm chung lÃ  phÃ¢n chia dá»¯ liá»‡u thÃ nh nhiá»u lá»›p vÃ  báº¯t Ä‘áº§u \"há»c\" dáº§n qua tá»«ng lá»›p Ä‘á»ƒ Ä‘Æ°a ra káº¿t quáº£ cuá»‘i cÃ¹ng. á» hÃ¬nh dÆ°á»›i Ä‘Ã¢y, $X_o$ Ä‘áº¡i diá»‡n cho dá»¯ liá»‡u Ä‘áº§u vÃ o, $h_t$ lÃ  output Ä‘áº§u ra cá»§a tá»«ng step vÃ  $A$ lÃ  nhá»¯ng gÃ¬ Ä‘Ã£ \"há»c\" Ä‘Æ°á»£c táº¡i step Ä‘Ã³ vÃ  Ä‘Æ°á»£c truyá»n cho step tiáº¿p theo. Trong tÃ i liá»‡u chuáº©n thÃ¬ há» thÆ°á»ng kÃ­ hiá»‡u lÃ  $X_t$, $Y_t$, $h_{t-1}$.\n\n```{=html}\n<div style=\"text-align: center; margin-bottom: 20px;\">\n  <img src=\"img/RNN.png\" style=\"max-width: 100%; height: auto; display: block; margin: 0 auto;\">\n  \n  <!-- Picture Name -->\n  <div style=\"text-align: left; margin-top: 10px;\">\n    HÃ¬nh 1: Minh há»a vá» sá»± phÃ¢n chia dá»¯ liá»‡u thÃ nh nhiá»u lá»›p\n  </div>\n  \n  <!-- Source Link -->\n  <div style=\"text-align: right; font-style: italic; margin-top: 5px;\">\n    Source: <a href=\"https://dominhhai.github.io/vi/2017/10/what-is-lstm/\" target=\"_blank\">Link to Image</a>\n  </div>\n</div>\n```\nKhi nhÃ¬n hÃ¬nh thÃ¬ báº¡n cÃ³ thá»ƒ bá»‘i rá»‘i chÆ°a hiá»ƒu cÃ¡c kÃ­ tá»± vÃ  hÃ¬nh áº£nh thÃ¬ báº¡n cÃ³ thá»ƒ tÆ°á»Ÿng tÆ°á»£ng **há»c mÃ¡y** nhÆ° 1 Ä‘á»©a tráº» vÃ  Ä‘á»ƒ nÃ³ cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c cÃ¢u: \"HÃ´m nay con Ä‘i há»c\" thÃ¬ nÃ³ pháº£i há»c tá»«ng chá»¯ cÃ¡i nhÆ°: a,b,c,... trÆ°á»›c rÃ²i má»›i ghÃ©p thÃ nh tá»« Ä‘Æ¡n nhÆ°: \"HÃ´m\",\"Nay\",... rá»“i ghÃ©p thÃ nh cÃ¢u trÃªn. Váº­y giáº£ sá»­ nhÆ° hÃ´m nay há»c Ä‘Æ°á»£c tá»« \"HÃ´m\" thÃ¬ nÃ³ sáº½ báº¯t Ä‘áº§u ghi nhá»› tá»« Ä‘Ã£ há»c vÃ o trong $A$. Náº¿u sau nÃ y ta cáº§n **há»c mÃ¡y** hiá»ƒu cÃ¢u \"HÃ´m sau con Ä‘i chÆ¡i\" thÃ¬ tá»‘c Ä‘á»™ há»c cá»§a **há»c mÃ¡y** sáº½ nhanh lÃªn vÃ¬ thay vÃ¬ nÃ³ pháº£i há»c 5 chá»¯ Ä‘Æ¡n nhÆ° thÃ´ng thÆ°á»ng thÃ¬ nÃ³ chá»‰ cáº§n há»c 4 chá»¯ cÃ²n láº¡i trá»« chá»¯ \"hÃ´m\". Váº­y báº¡n Ä‘Ã£ hiá»ƒu Ã½ tÆ°á»Ÿng ná»n táº£ng cá»§a *RNN* rá»“i ha!\n\nNáº¿u muá»‘n hiá»ƒu thÃªm vá» *RNN*, báº¡n cÃ³ thá»ƒ tham kháº£o link nÃ y: [Recurrent Neural Network: Tá»« RNN Ä‘áº¿n LSTM](https://viblo.asia/p/recurrent-neural-network-tu-rnn-den-lstm-gGJ597z1ZX2).\n\nVÃ  trong *RNN* cÃ³ 1 váº¥n Ä‘á» lá»›n lÃ  *Vanishing Gradient* nghÄ©a lÃ  mÃ´ hÃ¬nh sáº½ khÃ´ng cÃ²n \"há»c\" thÃªm Ä‘Æ°á»£c ná»¯a cho dÃ¹ tÄƒng sá»‘ `epochs`. Theo pháº§n chá»©ng minh cá»§a [anh Tuáº¥n](https://nttuan8.com/bai-14-long-short-term-memory-lstm/) cho tháº¥y *RNN* sáº½ luÃ´n xáº£y ra váº¥n Ä‘á» Ä‘Ã³ cho dÃ¹ báº¡n cÃ³ xÃ¢y dá»±ng mÃ´ hÃ¬nh tá»‘t nhÆ° tháº¿ nÃ o. Äiá»u nÃ y cÃ³ thá»ƒ hiá»ƒu Ä‘Æ¡n giáº£n nhÆ° viá»‡c báº¡n há»c liÃªn tá»¥c dáº«n tá»›i quÃ¡ táº£i. Do Ä‘Ã³, *RNN* chá»‰ há»c cÃ¡c thÃ´ng tin $A$ tá»« cÃ¡c step gáº§n nháº¥t vÃ  Ä‘Ã³ lÃ  lÃ­ do ra Ä‘á»i *LSTM - Long short term memory.*\n\n::: callout-warning\n<u>LÆ°u Ã½</u>: Äiá»u nÃ y khÃ´ng cÃ³ nghÄ©a *LSTM* luÃ´n tá»‘t hÆ¡n *RNN* vÃ¬ cÃ³ nhá»¯ng bÃ i toÃ¡n vá»›i Ä‘áº§u vÃ o Ä‘Æ¡n giáº£n thÃ¬ mÃ´ hÃ¬nh chá»‰ cáº§n há»c cÃ¡c step Ä‘áº§u lÃ  Ä‘Ã£ \"há»c\" Ä‘áº§y Ä‘á»§ thÃ´ng tin cáº§n thiáº¿t. \nMÃ´ hÃ¬nh *LSTM* phá»• biáº¿n vá»›i cÃ¡c bÃ i toÃ¡n phá»©c táº¡p nhÆ° tá»± Ä‘á»™ng dá»‹ch ngÃ´n ngá»¯, ghi chÃ©p láº¡i theo giá»ng nÃ³i...\n:::\n\n### MÃ´ hÃ¬nh LSTM:\n\nCÃ³ thá»ƒ xem mÃ´ hÃ¬nh *LSTM* nhÆ° biáº¿n thá»ƒ cá»§a *RNN*. Vá» cáº¥u trÃºc, *LSTM* cÃ³ ba cá»•ng chÃ­nh giÃºp nÃ³ xá»­ lÃ½ vÃ  duy trÃ¬ thÃ´ng tin qua cÃ¡c bÆ°á»›c thá»i gian:\n\n-   Cá»•ng quÃªn (Forget Gate): Quyáº¿t Ä‘á»‹nh thÃ´ng tin nÃ o cáº§n bá»‹ quÃªn trong tráº¡ng thÃ¡i Ã´ nhá»›.\n\n-   Cá»•ng nháº­p (Input Gate): XÃ¡c Ä‘á»‹nh thÃ´ng tin nÃ o cáº§n Ä‘Æ°á»£c ghi vÃ o tráº¡ng thÃ¡i Ã´ nhá»›.\n\n-   Cá»•ng xuáº¥t (Output Gate): Quyáº¿t Ä‘á»‹nh thÃ´ng tin nÃ o sáº½ Ä‘Æ°á»£c xuáº¥t ra tá»« tráº¡ng thÃ¡i Ã´ nhá»› Ä‘á»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n dá»± Ä‘oÃ¡n tiáº¿p theo.\n\n## XÃ¢y dá»±ng mÃ´ hÃ¬nh:\n\n### Load dá»¯ liá»‡u:\n\nÄáº§u tiÃªn ta sáº½ load dá»¯ liá»‡u láº¡i nhÆ° trÆ°á»›c. á» Ä‘Ã¢y, Ä‘á»ƒ Ä‘Æ¡n giáº£n, mÃ¬nh chá»‰ xÃ¢y dá»±ng mÃ´ hÃ¬nh cho *product A* thÃ´i.\n\n```{r}\n#| include: false\n#| warning: false\n#| message: false\npacman::p_load(\njanitor,\ntidyverse,\ndplyr,\ntidyr,\nmagrittr,\nggplot2)\n```\n\n```{r}\n#| include: false\n# Set the start and end date for the 6-month period\nstart_date <- as.Date(\"2024-05-01\")\nend_date <- as.Date(\"2024-10-31\")\n\n# Generate date range\ndates <- seq.Date(start_date, \n                  end_date, \n                  by = \"day\")\n\n# Set a random seed for reproducibility\nset.seed(42)\n\n# Create a vector of weekdays for each date\nweekdays <- weekdays(dates)\n\n# Simulate sales data for Product A, B, and C based on weekday patterns\nproduct_a_sales <- sample(5:50, length(dates), replace = TRUE)\nproduct_b_sales <- sample(3:40, length(dates), replace = TRUE)\nproduct_c_sales <- sample(2:30, length(dates), replace = TRUE)\n\n# Adjust sales based on the weekday\nfor (i in 1:length(dates)) {\n  if (weekdays[i] == \"Wednesday\" | weekdays[i] == \"Saturday\") {\n    # High demand for Product A and B on Wednesday and Saturday\n    product_a_sales[i] <- sample(40:70, 1)\n    product_b_sales[i] <- sample(30:60, 1)\n  } else if (weekdays[i] == \"Monday\" | weekdays[i] == \"Tuesday\") {\n    # High demand for Product C on Monday and Tuesday\n    product_c_sales[i] <- sample(20:40, 1)\n  }\n}\n\n# Create a data frame with the adjusted sales data\nsales_data <- data.frame(\n  Date = dates,\n  Weekday = weekdays,\n  Product_A = product_a_sales,\n  Product_B = product_b_sales,\n  Product_C = product_c_sales\n)\n```\n\nGiáº£ sá»­ cÃ´ng ty mÃ¬nh Ä‘ang kinh doanh 3 loáº¡i máº·t hÃ ng *product A*,*product B*,*product C* vÃ  Ä‘Ã¢y lÃ  biá»ƒu Ä‘á»“ thá»ƒ hiá»‡n nhu cáº§u cá»§a cáº£ 3 máº·t hÃ ng tá»« thÃ¡ng 5 tá»›i thÃ¡ng 10.\n\n```{r}\n#| warning: false\n#| message: false\nlibrary(highcharter)\nsales_data |> \n  select(-Weekday) |> \n  pivot_longer(cols = c(Product_A, Product_B, Product_C),\n               names_to = \"Product\",\n               values_to = \"Sales\") |> \n  hchart(\"line\", hcaes(x = Date, y = Sales, group = Product))\n```\n\nNáº¿u ta phÃ¢n tich sÃ¢u vá» nhu cáº§u cá»§a tá»«ng máº·t hÃ ng theo thá»© trong tuáº§n, ta sáº½ tháº¥y ráº±ng máº·t hÃ ng A, B thÃ¬ bÃ¡n cháº¡y vÃ o thá»© 4 vÃ  thá»© 7, cÃ²n máº·t hÃ ng C thÃ¬ bÃ¡n cháº¡y vÃ o thá»© 2 vÃ  thá»© 3.\n\n::: panel-tabset\n\n##### Product A:\n```{r}\n#| warning: false\n#| message: false\n#| echo: false\nmA<-sales_data |> \n  select(Date, \n         Weekday,\n         Product_A)  \n\n# Ensure 'Weekday' is a factor with the correct order\nmA$Weekday <- factor(mA$Weekday, \n                     levels = c(\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"))\n\nhcboxplot(\n    x = mA$Product_A,\n    var = mA$Weekday,\n    name = \"Weekday sales\") |> \n  hc_title(text = \"Comparing sales data between weekday\") |> \n  hc_yAxis(title = list(text = \"No.product\")) |> \n  hc_chart(type = \"column\")\n```\n\n##### Product B:\n```{r}\n#| warning: false\n#| message: false\n#| echo: false\nmB<-sales_data |> \n  select(Date, \n         Weekday,\n         Product_B)  \n\n# Ensure 'Weekday' is a factor with the correct order\nmA$Weekday <- factor(mB$Weekday, \n                     levels = c(\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"))\n\nhcboxplot(\n    x = mB$Product_B,\n    var = mB$Weekday,\n    name = \"Weekday sales\") |> \n  hc_title(text = \"Comparing sales data between weekday\") |> \n  hc_yAxis(title = list(text = \"No.product\")) |> \n   hc_chart(type = \"column\")\n```\n\n##### Product C:\n```{r}\n#| warning: false\n#| message: false\n#| echo: false\nmC<-sales_data |> \n  select(Date, \n         Weekday,\n         Product_C)  \n\n# Ensure 'Weekday' is a factor with the correct order\nmA$Weekday <- factor(mC$Weekday, \n                     levels = c(\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"))\n\nhcboxplot(\n    x = mC$Product_C,\n    var = mC$Weekday,\n    name = \"Weekday sales\") |> \n  hc_title(text = \"Comparing sales data between weekday\") |> \n  hc_yAxis(title = list(text = \"No.product\")) |> \n   hc_chart(type = \"column\")\n```\n:::\n\n```{r}\n#| warning: false\n#| message: false\n#| include: false\nlibrary(tidyverse)\n# Set the start and end date for the 6-month period\nstart_date <- as.Date(\"2024-05-01\")\nend_date <- as.Date(\"2024-10-31\")\n\n# Generate date range\ndates <- seq.Date(start_date, \n                  end_date, \n                  by = \"day\")\n\n# Set a random seed for reproducibility\nset.seed(42)\n\n# Create a vector of weekdays for each date\nweekdays <- weekdays(dates)\n\n# Simulate sales data for Product A, B, and C based on weekday patterns\nproduct_a_sales <- sample(5:50, length(dates), replace = TRUE)\nproduct_b_sales <- sample(3:40, length(dates), replace = TRUE)\nproduct_c_sales <- sample(2:30, length(dates), replace = TRUE)\n\n# Adjust sales based on the weekday\nfor (i in 1:length(dates)) {\n  if (weekdays[i] == \"Wednesday\" | weekdays[i] == \"Saturday\") {\n    # High demand for Product A and B on Wednesday and Saturday\n    product_a_sales[i] <- sample(40:70, 1)\n    product_b_sales[i] <- sample(30:60, 1)\n  } else if (weekdays[i] == \"Monday\" | weekdays[i] == \"Tuesday\") {\n    # High demand for Product C on Monday and Tuesday\n    product_c_sales[i] <- sample(20:40, 1)\n  }\n}\n```\n\nThÃ´ng thÆ°á»ng dá»¯ liá»‡u Ä‘á»ƒ *train model* trong *machine learning* thÆ°á»ng cáº§n tráº£i qua bÆ°á»›c *normalize data* nghÄ©a lÃ  Ä‘Æ°a táº¥t cáº£ dá»¯ liá»‡u vá» chung 1 thÆ°á»›c Ä‘o vÃ  pháº¡m vi. NguyÃªn do vÃ¬ Ä‘iá»u nÃ y giÃºp nhiá»u thuáº­t toÃ¡n há»c mÃ¡y dá»… dÃ ng há»™i tá»¥ hÆ¡n. VÃ­ dá»¥, cÃ¡c thuáº­t toÃ¡n nhÆ° *k-Nearest Neighbors (KNN)* vÃ  *Support Vector Machines (SVM)* ráº¥t nháº¡y cáº£m vá»›i khoáº£ng cÃ¡ch giá»¯a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u nÃªn náº¿u dá»¯ liá»‡u khÃ´ng Ä‘Æ°á»£c chuáº©n hÃ³a, thuáº­t toÃ¡n cÃ³ thá»ƒ Æ°u tiÃªn cÃ¡c Ä‘áº·c trÆ°ng cÃ³ pháº¡m vi lá»›n hÆ¡n vÃ  bá» qua cÃ¡c Ä‘áº·c trÆ°ng cÃ³ pháº¡m vi nhá» hÆ¡n, dáº«n Ä‘áº¿n hiá»‡u suáº¥t kÃ©m. VÃ  cÃ´ng thá»©c phá»• biáº¿n nháº¥t cho chuáº©n hÃ³a lÃ :\n\n$$\n\\text{Normalized Value} = \\frac{x - \\min(x)}{\\max(x) - \\min(x)}\n$$\n\n```{r}\n#| warning: false\n#| message: false\n# Create a data frame with the adjusted sales data\nsales_data <- data.frame(\n  Date = dates,\n  Weekday = weekdays,\n  Product_A = product_a_sales,\n  Product_B = product_b_sales,\n  Product_C = product_c_sales\n)\n\n# Convert the sales data to a time series (ts) object for Product A\nproduct_a_ts <- ts(sales_data$Product_A, start = c(2024, 5), \n                   frequency = 365)\n                   \n\n# Normalzie data:\ntime_series_data<-scale(product_a_ts)\n\nlibrary(highcharter)\nhighchart() %>%\n  hc_add_series(data = as.numeric(time_series_data), type = \"line\", name = \"Sales of Product A\") %>%\n  hc_title(text = \"Normalized Time Series of Product A\") %>%\n  hc_xAxis(title = list(text = \"Date\")) %>%\n  hc_yAxis(title = list(text = \"Normalized Sales\")) %>%\n  hc_tooltip(shared = TRUE) %>%\n  hc_plotOptions(line = list(marker = list(enabled = FALSE)))\n```\n\n### Chia dá»¯ liá»‡u:\n\nVáº­y Ä‘á»ƒ *train data*, mÃ¬nh sáº½ chia bá»™ dá»¯ liá»‡u thÃ nh 3 pháº§n:\n\n-   *Training data*: dÃ¹ng Ä‘á»ƒ huáº¥n luyá»‡n vÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh.\n\n-   *Evaluating data*: Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh vá»«a huáº¥n luyá»‡n.\n\n-   *Testing data*: dÃ¹ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ láº¡i náº¿u muá»‘n mÃ´ hÃ¬nh há»c láº¡i dá»¯ liá»‡u\n\n```{r}\n#| warning: false\n#| message: false\nlibrary(keras)\nlibrary(tensorflow)\nlibrary(dplyr)\n\n# Function to create supervised learning format from time series\ncreate_supervised_data <- function(series, n_in = 1, n_out = 1) {\n  series <- as.vector(series)  # Convert time series object to vector\n  data <- data.frame(series)\n  \n  # Use base R lag function for ts objects (lag() from stats package)\n  for (i in 1:n_in) {\n    data <- cbind(data, stats::lag(series, -i))\n  }\n  \n  colnames(data) <- c(paste0('t-', 1:n_in), 't+1')  # Correctly name columns\n  return(data)\n}\n\n# Prepare the data with 12 input lags and 1 output (next time step)\nsupervised_data <- create_supervised_data(time_series_data,\n                                          n_in = 12, \n                                          n_out = 1)\n\n# Remove NA rows created by lag function\nsupervised_data <- na.omit(supervised_data)\n\n# Step 2: Split data into training and test sets\ntrain_size <- round(0.7 * nrow(supervised_data))   # 70% for training\nval_size <- round(0.1 * nrow(supervised_data))     # 10% for validation\ntest_size <- nrow(supervised_data) - train_size - val_size  # 20% for testing\n\ntrain_data <- supervised_data[1:train_size, ]\nval_data <- supervised_data[(train_size + 1):(train_size + val_size), ]\ntest_data <- supervised_data[(train_size + val_size + 1):nrow(supervised_data), ]\n\n# Correct column selection\nx_train <- as.matrix(train_data[, 1:12])  # Input features (12 lags)\ny_train <- as.matrix(train_data[, 't+1'])  # Target output (next time step)\n\nx_val <- as.matrix(val_data[, 1:12])  # Input features for validation\ny_val <- as.matrix(val_data[, 't+1'])  # Actual output for validation\n\nx_test <- as.matrix(test_data[, 1:12])  # Input features for testing\ny_test <- as.matrix(test_data[, 't+1'])  # Actual output for testing\n\n\n## Plot the result:\nlibrary(xts)\nn<-quantile(sales_data$Date, \n            probs = c(0, 0.7, 0.8,1), \n            type = 1)\n\nm1<-sales_data %>% \n  filter(Date <= n[[2]])\nm2<-sales_data %>% \n  filter(Date <= n[[3]] & Date > n[[2]])\nm3<-sales_data %>% \n  filter(Date <= n[[4]] & Date > n[[3]])\n\ndemand_training<-xts(x=m1$Product_A,\n                     order.by=m1$Date)\ndemand_testing<-xts(x=m2$Product_A,\n                     order.by=m2$Date)\ndemand_forecasting<-xts(x=m3$Product_A,\n                     order.by=m3$Date)\n\nlibrary(dygraphs)\nlines<-cbind(demand_training,\n             demand_testing,\n             demand_forecasting)\ndygraph(lines,\n        main = \"Training and testing data\", \n        ylab = \"Quantity order (Unit: Millions)\") %>% \n  dySeries(\"demand_training\", label = \"Training data\") %>%\n  dySeries(\"demand_testing\", label = \"Testing data\") %>%\n  dySeries(\"demand_forecasting\", label = \"Forecasting data\") %>%\n  dyOptions(fillGraph = TRUE, fillAlpha = 0.4) %>% \n  dyRangeSelector(height = 20)\n```\n\n### MÃ´ hÃ¬nh RNN:\n\nSau Ä‘Ã³, ta sáº½ báº¯t Ä‘áº§u *train model* báº±ng cÃ¡ch táº¡o thÃªm 12 cá»™t giÃ¡ trá»‹ lÃ  giÃ¡ trá»‹ quÃ¡ khá»© cá»§a *demand*. Báº¡n sáº½ báº¯t Ä‘áº§u Ä‘á»‹nh nghÄ©a mÃ´ hÃ¬nh gá»“m:\n\n-   *Input*: dÃ¹ng hÃ m `layer_input(shape = input_shape)` vá»›i `input_shape` lÃ  sá»‘ lÆ°á»£ng *predictor*.\n\n-   *Layer*: lÃ  cÃ¡c hidden layer trong mÃ´ hÃ¬nh thÃªm vÃ o báº±ng hÃ m `layer_dense(x, units = 64, activation = 'relu')` vá»›i Ä‘á»‘i sá»‘ `units` thÆ°á»ng lÃ  bá»™i sá»‘ cá»§a 32 nhÆ° 32,64,256,...\n\n-   *Output*: dÃ¹ng hÃ m `layer_dense(x, units = 1)` Ä‘á»ƒ Ä‘á»‹nh nghÄ©a lÃ  Ä‘áº§u ra chá»‰ cÃ³ 1 giÃ¡ trá»‹.\n\n```{r}\n# Step 3: Build a simple transformer-like model\nRNN_model <- function(input_shape) {\n  inputs <- layer_input(shape = input_shape)\n\n  # Transformer Encoder Layer (simplified)\n  x <- inputs\n  x <- layer_dense(x, units = 64, activation = 'relu')  # Dense layer\n  x <- layer_dense(x, units = 32, activation = 'relu')  # Another dense layer\n\n  # Output layer\n  x <- layer_dense(x, units = 1)\n  \n  model <- keras_model(inputs, x)\n  return(model)\n}\n\n# Example input shape (12 time steps input per sample)\ninput_shape <- c(12)\n\nRNN_model <- RNN_model(input_shape)\n```\n\n```{r}\n#| warning: false\n#| message: false\n#| include: false\n# Step 4: Compile the model\nRNN_model %>% compile(\n  loss = 'mse',\n  optimizer = optimizer_adam(),\n  metrics = c('mae')\n)\n\n# Step 5: Train the model\nRNN_history <- RNN_model %>% fit(\n  x_train, \n  y_train,\n  epochs = 50, \n  batch_size = 32,\n  validation_data = list(x_val, y_val)\n)\n\nRNN_result <- RNN_model %>% \n    evaluate(x_test, y_test)\n```\n\nÄá»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh truyá»n thá»‘ng nhÆ° *linear regression* thÃ¬ báº¡n Ä‘Ã£ quen vá»›i thÃ´ng sá»‘ $R^2$ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh, cÃ²n vá»›i mÃ´ hÃ¬nh *Machine learning* thÃ¬ dÃ¹ng khÃ¡i niá»‡m *loss function - hÃ m máº¥t mÃ¡t*. Vá» khÃ¡i niá»‡m, *loss function* sáº½ Ä‘o lÆ°á»ng chÃªnh lá»‡ch giá»¯a *predicted* vÃ  *actual* trong bá»™ *training data* nÃªn khi cÃ ng tÄƒng `epochs` nghÄ©a lÃ  tÄƒng sá»‘ láº§n há»c láº¡i dá»¯ liá»‡u thÃ¬ *loss function* sáº½ tÃ­nh ra giÃ¡ trá»‹ cÃ ng tháº¥p. NhÆ° mÃ´ hÃ¬nh trÃªn thÃ¬ mÃ¬nh Ä‘áº·t Ä‘á»‘i sá»‘ `loss = mse` nghÄ©a lÃ  sá»­ dá»¥ng *Mean Squared Error* Ä‘á»ƒ tá»‘i Æ°u quy trÃ¬nh há»c cá»§a há»c mÃ¡y. CÃ´ng thá»©c nhÆ° sau:\n\n$$\nMSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_{\\text{pred}}(i) - y_{\\text{true}}(i))^2\n$$\n\nCÃ²n Ä‘á»‘i sá»‘ `metrics = c('mae')` nghÄ©a lÃ  tiÃªu chÃ­ khÃ¡c Ä‘á»ƒ theo dÃµi vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh. Váº­y táº¡i sao cáº§n cÃ³ 2 tham sá»‘ Ä‘Ã¡nh giÃ¡ song song nhÆ° váº­y lÃ  vÃ¬ nhÆ° Ä‘Ã£ nÃ³i, náº¿u báº¡n cÃ ng tÄƒng `epochs` thÃ¬ giÃ¡ trá»‹ *loss* cÃ ng tháº¥p trong khi dÃ¹ng `metrics` sáº½ Ä‘Æ°a ra Ä‘Ã¡nh giÃ¡ khÃ¡ch quan hÆ¡n vá» mÃ´ hÃ¬nh mÃ  khÃ´ng phá»¥ thuá»™c vÃ o sá»‘ láº§n `epochs`. CÃ´ng thá»©c nhÆ° sau:\n\n$$\n\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_{\\text{pred}}(i) - y_{\\text{true}}(i)|\n$$\n\nVáº­y khi cháº¡y code, R sáº½ return output nhÆ° biá»ƒu Ä‘á»“ dÆ°á»›i Ä‘Ã¢y lÃ  so sÃ¡nh tham sá»‘ cá»§a *mse* vÃ  *mae* giá»¯a *training data* vÃ  *evaluating data*. Ã tÆ°á»Ÿng lÃ  Ä‘Ã¡nh giÃ¡ thá»­ mÃ´ hÃ¬nh cÃ³ dá»± Ä‘oÃ¡n tá»‘t khÃ´ng khi cÃ³ dá»¯ liá»‡u má»›i vÃ o.\n\nTiáº¿p theo, ta sáº½ dÃ¹ng *test data* Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh vá»«a xÃ¢y dá»±ng. Káº¿t quáº£ cÃ³ váº» khÃ¡ tuyá»‡t vÃ¬ mÃ´ hÃ¬nh gáº§n nhÆ° theo sÃ¡t Ä‘Æ°á»£c dá»¯ liá»‡u cá»§a *test data*.\n\n```{r}\n# Step 6: Make predictions\nRNN_forecast <- RNN_model %>% \n  predict(x_test)\n\n# Step 7: Combine predicted and observed\nplot_data <- data.frame(\n  time = c(min(m3$Date)-days(1),m3$Date),  # Time for the test set\n  actual = y_test,  # Actual values from the test set\n  forecast = RNN_forecast  # Forecasted values\n)\n\n# Step 8: Plot using Highcharts\nhighchart() %>%\n  hc_title(text = \"Time Series Forecasting with Highcharts\") %>%\n  hc_xAxis(\n    categories = plot_data$time,\n    title = list(text = \"Time\")\n  ) %>%\n  hc_yAxis(\n    title = list(text = \"Value\"),\n    plotLines = list(list(\n      value = 0,\n      width = 1,\n      color = \"gray\"\n    ))\n  ) %>%\n  hc_add_series(\n    name = \"Actual Data\",\n    data = plot_data$actual,\n    type = \"line\",\n    color = \"#1f77b4\"  # Blue color for actual data\n  ) %>%\n  hc_add_series(\n    name = \"Forecast\",\n    data = plot_data$forecast,\n    type = \"line\",\n    color = \"#ff7f0e\"  # Orange color for forecast data\n  ) %>%\n  hc_tooltip(\n    shared = TRUE,\n    crosshairs = TRUE\n  ) %>%\n  hc_legend(\n    enabled = TRUE\n  )\n```\n\n### MÃ´ hÃ¬nh LSTM:\n\nTiáº¿p theo, ta sáº½ xÃ¢y dá»±ng thá»­ mÃ´ hÃ¬nh *LSTM*. MÃ´ hÃ¬nh LSTM thÆ°á»ng bao gá»“m cÃ¡c lá»›p sau:\n\n-   Lá»›p LSTM: ÄÃ¢y lÃ  lá»›p chÃ­nh, cÃ³ thá»ƒ cÃ³ má»™t hoáº·c nhiá»u lá»›p LSTM chá»“ng lÃªn nhau. Má»—i lá»›p LSTM cÃ³ thá»ƒ tráº£ vá» toÃ n bá»™ chuá»—i báº±ng `return_sequences = TRUE` hoáº·c chá»‰ tráº£ vá» giÃ¡ trá»‹ cuá»‘i cÃ¹ng báº±ng `return_sequences = FALSE`.\n\n-   Lá»›p Dense: Sau khi thÃ´ng tin Ä‘Æ°á»£c xá»­ lÃ½ qua cÃ¡c lá»›p LSTM, nÃ³ sáº½ Ä‘Æ°á»£c Ä‘Æ°a qua cÃ¡c lá»›p Dense (lá»›p fully connected) Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n cuá»‘i cÃ¹ng.\n\n-   Lá»›p Dropout (tÃ¹y chá»n): Äá»ƒ trÃ¡nh overfitting, cÃ³ thá»ƒ thÃªm lá»›p dropout Ä‘á»ƒ táº¯t ngáº«u nhiÃªn má»™t sá»‘ nÆ¡-ron trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n.\n\n```{r}\n#| warning: false\n#| message: false\n#| include: false\n# Step 3: Build an enhanced LSTM model\nLSTM_model <- function(input_shape) {\n  # Define input layer\n  inputs <- layer_input(shape = input_shape)\n  \n  # First LSTM layer (returns the full sequence for the next layer)\n  x <- layer_lstm(units = 50, return_sequences = TRUE, activation = 'tanh')(inputs)\n  \n  # Second LSTM layer (returns the full sequence, could also be 'return_sequences = FALSE' for output prediction)\n  x <- layer_lstm(units = 50, return_sequences = FALSE, activation = 'tanh')(x)\n  \n  # Output layer (prediction for the next time step)\n  outputs <- layer_dense(units = 1)(x)\n  \n  # Create the model\n  model <- keras_model(inputs, outputs)\n  \n  # Return the model\n  return(model)\n}\n\n\n# Update input shape for LSTM (timesteps = 12, features = 1)\ninput_shape <- c(12, 1)\n\n# Reshape the input data for LSTM (add a feature dimension)\nx_train <- array_reshape(x_train, dim = c(nrow(x_train), 12, 1))\nx_test <- array_reshape(x_test, dim = c(nrow(x_test), 12, 1))\nx_val <- array_reshape(x_val, dim = c(nrow(x_val), 12, 1))\n\n# Build the enhanced LSTM model\nLSTM_model <- LSTM_model(input_shape)\n\n# Step 4: Compile the model\nLSTM_model %>% compile(\n  loss = 'mse',\n  optimizer = optimizer_adam(),\n  metrics = c('mae')\n)\n\n# Step 5: Train the model\nLSTM_history <- LSTM_model %>% fit(\n  x_train, y_train,\n  epochs = 50, batch_size = 32,\n  validation_data = list(x_val, y_val)\n)\n\nLSTM_result <- LSTM_model %>% \n    evaluate(x_test, y_test)\n```\n\nVáº­y giá» ta sáº½ so sÃ¡nh vá»›i mÃ´ hÃ¬nh *RNN* trÆ°á»›c vá»›i mÃ´ hÃ¬nh *LSTM* qua 2 thÃ´ng sá»‘ Ä‘Ã£ chá»n *mse* vÃ  *mae*.\n\n```{r}\n#| warning: false\n#| message: false\n# Extract metrics into a data frame\nresults_df <- data.frame(\n  Model = c(\"RNN\", \"LSTM\"),\n  Metric = c(\"Loss\", \"metric\"),\n  MSE = c(RNN_result[[1]],RNN_result[[2]]),\n  MAE = c(LSTM_result[[1]], LSTM_result[[2]])\n)\n\nlibrary(gt)\n# Create a gt table\nresults_df %>%\n  gt() %>%\n  tab_header(\n    title = \"Model Performance Metrics\",\n    subtitle = \"Comparison of MSE and MAE for RNN and LSTM\"\n  ) %>%\n  fmt_number(\n    columns = vars(MSE, MAE),\n    decimals = 4\n  ) %>%\n  cols_label(\n    Model = \"Model Type\",\n    MSE = \"Mean Squared Error\",\n    MAE = \"Mean Absolute Error\"\n  ) %>%\n  tab_options(\n    table.font.size = 14,\n    heading.title.font.size = 16,\n    heading.subtitle.font.size = 14\n  )\n```\n\nKáº¿t quáº£ cho tháº¥y mÃ´ hÃ¬nh *RNN* truyá»n thá»‘ng Ä‘Æ°a ra káº¿t quáº£ tá»‘t hÆ¡n *LSTM* máº·c dÃ¹ sai sá»‘ cá»§a *LSTM* Ä‘á»u \\< 0.03 lÃ  khÃ´ng quÃ¡ tá»‡ nhÆ°ng tiÃªu chÃ­ váº«n lÃ  mÃ´ hÃ¬nh nÃ o hiá»‡u quáº£ nháº¥t.\n\n```{r}\nLSTM_forecast <- LSTM_model %>% \n  predict(x_test)\n\ncompare<-data.frame(Date = c(min(m3$Date)-days(1),m3$Date),\n                    LSTM = round(LSTM_forecast - y_test,3),\n                    RNN = round(RNN_forecast - y_test,3)\n)\n\n# Create the highchart plot\nhighchart() %>%\n  hc_chart(type = \"line\") %>%\n  hc_title(text = \"Residual Comparison: LSTM vs RNN\") %>%\n  hc_xAxis(\n    categories = compare$Date,\n    title = list(text = \"Date\")\n  ) %>%\n  hc_yAxis(\n    title = list(text = \"Residuals\"),\n    plotLines = list(\n      list(value = 0, color = \"gray\", width = 1, dashStyle = \"Dash\")\n    )\n  ) %>%\n  hc_add_series(\n    name = \"LSTM Residuals\",\n    data = compare$LSTM,\n    color = \"#1f77b4\"\n  ) %>%\n  hc_add_series(\n    name = \"RNN Residuals\",\n    data = compare$RNN,\n    color = \"#ff7f0e\"\n  ) %>%\n  hc_tooltip(shared = TRUE) %>%\n  hc_legend(enabled = TRUE)\n```\n\n\n## Káº¿t luáº­n:\n\nNhÆ° váº­y, chÃºng ta Ä‘Ã£ Ä‘Æ°á»£c há»c vá» thuáº­t toÃ¡n Genetic vÃ  mÃ´ hÃ¬nh MILP cÅ©ng nhÆ° cÃ¡ch thá»±c hiá»‡n trong Rstudio.\n\nNáº¿u báº¡n cÃ³ cÃ¢u há»i hay tháº¯c máº¯c nÃ o, Ä‘á»«ng ngáº§n ngáº¡i liÃªn há»‡ vá»›i mÃ¬nh qua Gmail. BÃªn cáº¡nh Ä‘Ã³, náº¿u báº¡n muá»‘n xem láº¡i cÃ¡c bÃ i viáº¿t trÆ°á»›c Ä‘Ã¢y cá»§a mÃ¬nh, hÃ£y nháº¥n vÃ o hai nÃºt dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ truy cáº­p trang **Rpubs** hoáº·c mÃ£ nguá»“n trÃªn **Github**. Ráº¥t vui Ä‘Æ°á»£c Ä‘á»“ng hÃ nh cÃ¹ng báº¡n, háº¹n gáº·p láº¡i! ğŸ˜„ğŸ˜„ğŸ˜„\n\n```{=html}\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Contact Me</title>\n    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css\">\n    <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/simple-icons@v6.0.0/svgs/rstudio.svg\">\n    <style>\n        body { font-family: Arial, sans-serif; background-color: $secondary-color; }\n        .container { max-width: 400px; margin: auto; padding: 20px; background: white; border-radius: 8px; box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1); }\n        label { display: block; margin: 10px 0 5px; }\n        input[type=\"email\"] { width: 100%; padding: 10px; margin-bottom: 15px; border: 1px solid #ccc; border-radius: 4px; }\n        .github-button, .rpubs-button { margin-top: 20px; text-align: center; }\n        .github-button button, .rpubs-button button { background-color: #333; color: white; border: none; padding: 10px; cursor: pointer; border-radius: 4px; width: 100%; }\n        .github-button button:hover, .rpubs-button button:hover { background-color: #555; }\n        .rpubs-button button { background-color: #75AADB; }\n        .rpubs-button button:hover { background-color: #5A9BC2; }\n        .rpubs-icon { margin-right: 5px; width: 20px; vertical-align: middle; filter: brightness(0) invert(1); }\n        .error-message { color: red; font-size: 0.9em; margin-top: 5px; }\n    </style>\n</head>\n<body>\n    <div class=\"container\">\n        <h2>Contact Me</h2>\n        <form id=\"emailForm\">\n            <label for=\"email\">Your Email:</label>\n            <input type=\"email\" id=\"email\" name=\"email\" required aria-label=\"Email Address\">\n            <div class=\"error-message\" id=\"error-message\" style=\"display: none;\">Please enter a valid email address.</div>\n            <button type=\"submit\">Send Email</button>\n        </form>\n        <div class=\"github-button\">\n            <button>\n                <a href=\"https://github.com/Loccx78vn/Time_series_forcasting\" target=\"_blank\" style=\"color: white; text-decoration: none;\">\n                    <i class=\"fab fa-github\"></i> View Code on GitHub\n                </a>\n            </button>\n        </div>\n        <div class=\"rpubs-button\">\n            <button>\n                <a href=\"https://rpubs.com/loccx\" target=\"_blank\" style=\"color: white; text-decoration: none;\">\n                    <img src=\"https://cdn.jsdelivr.net/npm/simple-icons@v6.0.0/icons/rstudio.svg\" alt=\"RStudio icon\" class=\"rpubs-icon\"> Visit my RPubs\n                </a>\n            </button>\n        </div>\n    </div>\n\n    <script>\n        document.getElementById('emailForm').addEventListener('submit', function(event) {\n            event.preventDefault(); // Prevent default form submission\n            const emailInput = document.getElementById('email');\n            const email = emailInput.value;\n            const errorMessage = document.getElementById('error-message');\n\n            // Simple email validation regex\n            const emailPattern = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n\n            if (emailPattern.test(email)) {\n                errorMessage.style.display = 'none'; // Hide error message\n                const yourEmail = 'loccaoxuan103@gmail.com'; // Your email\n                const gmailLink = `https://mail.google.com/mail/?view=cm&fs=1&to=${yourEmail}&su=Help%20Request%20from%20${encodeURIComponent(email)}`;\n                window.open(gmailLink, '_blank'); // Open in new tab\n            } else {\n                errorMessage.style.display = 'block'; // Show error message\n            }\n        });\n    </script>\n</body>\n</html>\n```"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"number-sections":true,"output-file":"torch.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.30","editor":"source","theme":{"light":"theme-light.scss","dark":"theme-dark.scss"},"title":"RNN and LSTM model","subtitle":"Viá»‡t Nam, 2024","categories":["Machine Learning","Forecasting"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}