[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cao XuÃ¢n Lá»™c",
    "section": "",
    "text": "Xin chÃ o, mÃ¬nh lÃ  Lá»™c, sinh nÄƒm 2003 vÃ  lÃ  má»™t chÃ ng trai Ä‘áº¿n tá»« máº£nh Ä‘áº¥t Ä‘áº§y náº¯ng vÃ  giÃ³ - PhÃº YÃªn, Viá»‡t Nam. MÃ¬nh cÃ³ báº±ng cá»­ nhÃ¢n trÆ°á»ng Äáº¡i há»c Kinh Táº¿ - TÃ i ChÃ­nh (UEF) vÃ  chuyÃªn ngÃ nh cá»§a mÃ¬nh lÃ  Logistics vÃ  quáº£n lÃ½ chuá»—i cung á»©ng.\nLÃ  ngÆ°á»i cÃ³ niá»m Ä‘am mÃª máº¡nh máº½ vá»›i R, mÃ¬nh cÃ³ sá»Ÿ thÃ­ch viáº¿t post vá» viá»‡c phÃ¢n tÃ­ch dá»¯ liá»‡u vá»›i R Ä‘á»ƒ á»©ng dá»¥ng vÃ o cÃ¡c cÃ´ng viá»‡c, bÃ i toÃ¡n thÆ°á»ng gáº·p trong Supply Chain. NgoÃ i ra, sá»Ÿ thÃ­ch cá»§a mÃ¬nh lÃ  nghe sÃ¡ch nÃ³i vÃ  Ä‘i bá»™!\nCÃ¢u slogan mÃ  mÃ¬nh thÃ­ch nháº¥t lÃ : â€œDonâ€™t fear the risk, fear the opportunity lost!â€ vÃ  Ä‘Ã³ cÅ©ng lÃ  cÃ¡ch mÃ¬nh sá»‘ng vÃ  lÃ m viá»‡c Ä‘áº¿n bÃ¢y giá» ğŸ’ğŸ’ğŸ’.\nHi vá»ng cÃ¡c báº¡n sáº½ thÃ­ch bÃ i viáº¿t cá»§a mÃ¬nh!\n    \n    \n    Go to Next Page\n    \n    \n        \n            Go to Next Page\n            â”"
  },
  {
    "objectID": "torch.html",
    "href": "torch.html",
    "title": "RNN and LSTM model",
    "section": "",
    "text": "á» Ä‘Ã¢y ta sáº½ há»c vá» mÃ´ hÃ¬nh machine learning Ä‘Æ°á»£c á»©ng dá»¥ng nhiá»u nháº¥t trong viá»‡c phÃ¢n tÃ­ch dá»¯ liá»‡u thá»i gian lÃ  RNN vÃ  LSTM."
  },
  {
    "objectID": "torch.html#Ä‘á»‹nh-nghÄ©a",
    "href": "torch.html#Ä‘á»‹nh-nghÄ©a",
    "title": "RNN and LSTM model",
    "section": "1 Äá»‹nh nghÄ©a:",
    "text": "1 Äá»‹nh nghÄ©a:\n\n1.1 MÃ´ hÃ¬nh RNN:\nÄiá»ƒm chung lÃ  cáº£ hai mÃ´ hÃ¬nh Ä‘á»u thuá»™c phÃ¢n lá»›p Deep learning - nghÄ©a lÃ  há»c mÃ¡y sÃ¢u vá»›i Ä‘áº·c Ä‘iá»ƒm chung lÃ  phÃ¢n chia dá»¯ liá»‡u thÃ nh nhiá»u lá»›p vÃ  báº¯t Ä‘áº§u â€œhá»câ€ dáº§n qua tá»«ng lá»›p Ä‘á»ƒ Ä‘Æ°a ra káº¿t quáº£ cuá»‘i cÃ¹ng. á» hÃ¬nh dÆ°á»›i Ä‘Ã¢y, \\(X_o\\) Ä‘áº¡i diá»‡n cho dá»¯ liá»‡u Ä‘áº§u vÃ o, \\(h_t\\) lÃ  output Ä‘áº§u ra cá»§a tá»«ng step vÃ  \\(A\\) lÃ  nhá»¯ng gÃ¬ Ä‘Ã£ â€œhá»câ€ Ä‘Æ°á»£c táº¡i step Ä‘Ã³ vÃ  Ä‘Æ°á»£c truyá»n cho step tiáº¿p theo. Trong tÃ i liá»‡u chuáº©n thÃ¬ há» thÆ°á»ng kÃ­ hiá»‡u lÃ  \\(X_t\\), \\(Y_t\\), \\(h_{t-1}\\).\n\n  \n  \n  \n  \n    HÃ¬nh 1: Minh há»a vá» sá»± phÃ¢n chia dá»¯ liá»‡u thÃ nh nhiá»u lá»›p\n  \n  \n  \n  \n    Source: Link to Image\n  \n\nKhi nhÃ¬n hÃ¬nh thÃ¬ báº¡n cÃ³ thá»ƒ bá»‘i rá»‘i chÆ°a hiá»ƒu cÃ¡c kÃ­ tá»± vÃ  hÃ¬nh áº£nh thÃ¬ báº¡n cÃ³ thá»ƒ tÆ°á»Ÿng tÆ°á»£ng há»c mÃ¡y nhÆ° 1 Ä‘á»©a tráº» vÃ  Ä‘á»ƒ nÃ³ cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c cÃ¢u: â€œHÃ´m nay con Ä‘i há»câ€ thÃ¬ nÃ³ pháº£i há»c tá»«ng chá»¯ cÃ¡i nhÆ°: a,b,c,â€¦ trÆ°á»›c rÃ²i má»›i ghÃ©p thÃ nh tá»« Ä‘Æ¡n nhÆ°: â€œHÃ´mâ€,â€œNayâ€,â€¦ rá»“i ghÃ©p thÃ nh cÃ¢u trÃªn. Váº­y giáº£ sá»­ nhÆ° hÃ´m nay há»c Ä‘Æ°á»£c tá»« â€œHÃ´mâ€ thÃ¬ nÃ³ sáº½ báº¯t Ä‘áº§u ghi nhá»› tá»« Ä‘Ã£ há»c vÃ o trong \\(A\\). Náº¿u sau nÃ y ta cáº§n há»c mÃ¡y hiá»ƒu cÃ¢u â€œHÃ´m sau con Ä‘i chÆ¡iâ€ thÃ¬ tá»‘c Ä‘á»™ há»c cá»§a há»c mÃ¡y sáº½ nhanh lÃªn vÃ¬ thay vÃ¬ nÃ³ pháº£i há»c 5 chá»¯ Ä‘Æ¡n nhÆ° thÃ´ng thÆ°á»ng thÃ¬ nÃ³ chá»‰ cáº§n há»c 4 chá»¯ cÃ²n láº¡i trá»« chá»¯ â€œhÃ´mâ€. Váº­y báº¡n Ä‘Ã£ hiá»ƒu Ã½ tÆ°á»Ÿng ná»n táº£ng cá»§a RNN rá»“i ha!\nNáº¿u muá»‘n hiá»ƒu thÃªm vá» RNN, báº¡n cÃ³ thá»ƒ tham kháº£o link nÃ y: Recurrent Neural Network: Tá»« RNN Ä‘áº¿n LSTM.\nVÃ  trong RNN cÃ³ 1 váº¥n Ä‘á» lá»›n lÃ  Vanishing Gradient nghÄ©a lÃ  mÃ´ hÃ¬nh sáº½ khÃ´ng cÃ²n â€œhá»câ€ thÃªm Ä‘Æ°á»£c ná»¯a cho dÃ¹ tÄƒng sá»‘ epochs. Theo pháº§n chá»©ng minh cá»§a anh Tuáº¥n cho tháº¥y RNN sáº½ luÃ´n xáº£y ra váº¥n Ä‘á» Ä‘Ã³ cho dÃ¹ báº¡n cÃ³ xÃ¢y dá»±ng mÃ´ hÃ¬nh tá»‘t nhÆ° tháº¿ nÃ o. Äiá»u nÃ y cÃ³ thá»ƒ hiá»ƒu Ä‘Æ¡n giáº£n nhÆ° viá»‡c báº¡n há»c liÃªn tá»¥c dáº«n tá»›i quÃ¡ táº£i. Do Ä‘Ã³, RNN chá»‰ há»c cÃ¡c thÃ´ng tin \\(A\\) tá»« cÃ¡c step gáº§n nháº¥t vÃ  Ä‘Ã³ lÃ  lÃ­ do ra Ä‘á»i LSTM - Long short term memory.\n\n\n\n\n\n\nWarning\n\n\n\nLÆ°u Ã½: Äiá»u nÃ y khÃ´ng cÃ³ nghÄ©a LSTM luÃ´n tá»‘t hÆ¡n RNN vÃ¬ cÃ³ nhá»¯ng bÃ i toÃ¡n vá»›i Ä‘áº§u vÃ o Ä‘Æ¡n giáº£n thÃ¬ mÃ´ hÃ¬nh chá»‰ cáº§n há»c cÃ¡c step Ä‘áº§u lÃ  Ä‘Ã£ â€œhá»câ€ Ä‘áº§y Ä‘á»§ thÃ´ng tin cáº§n thiáº¿t. MÃ´ hÃ¬nh LSTM phá»• biáº¿n vá»›i cÃ¡c bÃ i toÃ¡n phá»©c táº¡p nhÆ° tá»± Ä‘á»™ng dá»‹ch ngÃ´n ngá»¯, ghi chÃ©p láº¡i theo giá»ng nÃ³iâ€¦\n\n\n\n\n1.2 MÃ´ hÃ¬nh LSTM:\nCÃ³ thá»ƒ xem mÃ´ hÃ¬nh LSTM nhÆ° biáº¿n thá»ƒ cá»§a RNN. Vá» cáº¥u trÃºc, LSTM cÃ³ ba cá»•ng chÃ­nh giÃºp nÃ³ xá»­ lÃ½ vÃ  duy trÃ¬ thÃ´ng tin qua cÃ¡c bÆ°á»›c thá»i gian:\n\nCá»•ng quÃªn (Forget Gate): Quyáº¿t Ä‘á»‹nh thÃ´ng tin nÃ o cáº§n bá»‹ quÃªn trong tráº¡ng thÃ¡i Ã´ nhá»›.\nCá»•ng nháº­p (Input Gate): XÃ¡c Ä‘á»‹nh thÃ´ng tin nÃ o cáº§n Ä‘Æ°á»£c ghi vÃ o tráº¡ng thÃ¡i Ã´ nhá»›.\nCá»•ng xuáº¥t (Output Gate): Quyáº¿t Ä‘á»‹nh thÃ´ng tin nÃ o sáº½ Ä‘Æ°á»£c xuáº¥t ra tá»« tráº¡ng thÃ¡i Ã´ nhá»› Ä‘á»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n dá»± Ä‘oÃ¡n tiáº¿p theo."
  },
  {
    "objectID": "torch.html#xÃ¢y-dá»±ng-mÃ´-hÃ¬nh",
    "href": "torch.html#xÃ¢y-dá»±ng-mÃ´-hÃ¬nh",
    "title": "RNN and LSTM model",
    "section": "2 XÃ¢y dá»±ng mÃ´ hÃ¬nh:",
    "text": "2 XÃ¢y dá»±ng mÃ´ hÃ¬nh:\n\n2.1 Load dá»¯ liá»‡u:\nÄáº§u tiÃªn ta sáº½ load dá»¯ liá»‡u láº¡i nhÆ° trÆ°á»›c. á» Ä‘Ã¢y, Ä‘á»ƒ Ä‘Æ¡n giáº£n, mÃ¬nh chá»‰ xÃ¢y dá»±ng mÃ´ hÃ¬nh cho product A thÃ´i.\nGiáº£ sá»­ cÃ´ng ty mÃ¬nh Ä‘ang kinh doanh 3 loáº¡i máº·t hÃ ng product A,product B,product C vÃ  Ä‘Ã¢y lÃ  biá»ƒu Ä‘á»“ thá»ƒ hiá»‡n nhu cáº§u cá»§a cáº£ 3 máº·t hÃ ng tá»« thÃ¡ng 5 tá»›i thÃ¡ng 10.\n\n\nCode\nlibrary(highcharter)\nsales_data |&gt; \n  select(-Weekday) |&gt; \n  pivot_longer(cols = c(Product_A, Product_B, Product_C),\n               names_to = \"Product\",\n               values_to = \"Sales\") |&gt; \n  hchart(\"line\", hcaes(x = Date, y = Sales, group = Product))\n\n\n\n\n\n\nNáº¿u ta phÃ¢n tich sÃ¢u vá» nhu cáº§u cá»§a tá»«ng máº·t hÃ ng theo thá»© trong tuáº§n, ta sáº½ tháº¥y ráº±ng máº·t hÃ ng A, B thÃ¬ bÃ¡n cháº¡y vÃ o thá»© 4 vÃ  thá»© 7, cÃ²n máº·t hÃ ng C thÃ¬ bÃ¡n cháº¡y vÃ o thá»© 2 vÃ  thá»© 3.\n\nProduct A:Product B:Product C:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThÃ´ng thÆ°á»ng dá»¯ liá»‡u Ä‘á»ƒ train model trong machine learning thÆ°á»ng cáº§n tráº£i qua bÆ°á»›c normalize data nghÄ©a lÃ  Ä‘Æ°a táº¥t cáº£ dá»¯ liá»‡u vá» chung 1 thÆ°á»›c Ä‘o vÃ  pháº¡m vi. NguyÃªn do vÃ¬ Ä‘iá»u nÃ y giÃºp nhiá»u thuáº­t toÃ¡n há»c mÃ¡y dá»… dÃ ng há»™i tá»¥ hÆ¡n. VÃ­ dá»¥, cÃ¡c thuáº­t toÃ¡n nhÆ° k-Nearest Neighbors (KNN) vÃ  Support Vector Machines (SVM) ráº¥t nháº¡y cáº£m vá»›i khoáº£ng cÃ¡ch giá»¯a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u nÃªn náº¿u dá»¯ liá»‡u khÃ´ng Ä‘Æ°á»£c chuáº©n hÃ³a, thuáº­t toÃ¡n cÃ³ thá»ƒ Æ°u tiÃªn cÃ¡c Ä‘áº·c trÆ°ng cÃ³ pháº¡m vi lá»›n hÆ¡n vÃ  bá» qua cÃ¡c Ä‘áº·c trÆ°ng cÃ³ pháº¡m vi nhá» hÆ¡n, dáº«n Ä‘áº¿n hiá»‡u suáº¥t kÃ©m. VÃ  cÃ´ng thá»©c phá»• biáº¿n nháº¥t cho chuáº©n hÃ³a lÃ :\n\\[\n\\text{Normalized Value} = \\frac{x - \\min(x)}{\\max(x) - \\min(x)}\n\\]\n\n\nCode\n# Create a data frame with the adjusted sales data\nsales_data &lt;- data.frame(\n  Date = dates,\n  Weekday = weekdays,\n  Product_A = product_a_sales,\n  Product_B = product_b_sales,\n  Product_C = product_c_sales\n)\n\n# Convert the sales data to a time series (ts) object for Product A\nproduct_a_ts &lt;- ts(sales_data$Product_A, start = c(2024, 5), \n                   frequency = 365)\n                   \n\n# Normalzie data:\ntime_series_data&lt;-scale(product_a_ts)\n\nlibrary(highcharter)\nhighchart() %&gt;%\n  hc_add_series(data = as.numeric(time_series_data), type = \"line\", name = \"Sales of Product A\") %&gt;%\n  hc_title(text = \"Normalized Time Series of Product A\") %&gt;%\n  hc_xAxis(title = list(text = \"Date\")) %&gt;%\n  hc_yAxis(title = list(text = \"Normalized Sales\")) %&gt;%\n  hc_tooltip(shared = TRUE) %&gt;%\n  hc_plotOptions(line = list(marker = list(enabled = FALSE)))\n\n\n\n\n\n\n\n\n2.2 Chia dá»¯ liá»‡u:\nVáº­y Ä‘á»ƒ train data, mÃ¬nh sáº½ chia bá»™ dá»¯ liá»‡u thÃ nh 3 pháº§n:\n\nTraining data: dÃ¹ng Ä‘á»ƒ huáº¥n luyá»‡n vÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh.\nEvaluating data: Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh vá»«a huáº¥n luyá»‡n.\nTesting data: dÃ¹ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ láº¡i náº¿u muá»‘n mÃ´ hÃ¬nh há»c láº¡i dá»¯ liá»‡u\n\n\n\nCode\nlibrary(keras)\nlibrary(tensorflow)\nlibrary(dplyr)\n\n# Function to create supervised learning format from time series\ncreate_supervised_data &lt;- function(series, n_in = 1, n_out = 1) {\n  series &lt;- as.vector(series)  # Convert time series object to vector\n  data &lt;- data.frame(series)\n  \n  # Use base R lag function for ts objects (lag() from stats package)\n  for (i in 1:n_in) {\n    data &lt;- cbind(data, stats::lag(series, -i))\n  }\n  \n  colnames(data) &lt;- c(paste0('t-', 1:n_in), 't+1')  # Correctly name columns\n  return(data)\n}\n\n# Prepare the data with 12 input lags and 1 output (next time step)\nsupervised_data &lt;- create_supervised_data(time_series_data,\n                                          n_in = 12, \n                                          n_out = 1)\n\n# Remove NA rows created by lag function\nsupervised_data &lt;- na.omit(supervised_data)\n\n# Step 2: Split data into training and test sets\ntrain_size &lt;- round(0.7 * nrow(supervised_data))   # 70% for training\nval_size &lt;- round(0.1 * nrow(supervised_data))     # 10% for validation\ntest_size &lt;- nrow(supervised_data) - train_size - val_size  # 20% for testing\n\ntrain_data &lt;- supervised_data[1:train_size, ]\nval_data &lt;- supervised_data[(train_size + 1):(train_size + val_size), ]\ntest_data &lt;- supervised_data[(train_size + val_size + 1):nrow(supervised_data), ]\n\n# Correct column selection\nx_train &lt;- as.matrix(train_data[, 1:12])  # Input features (12 lags)\ny_train &lt;- as.matrix(train_data[, 't+1'])  # Target output (next time step)\n\nx_val &lt;- as.matrix(val_data[, 1:12])  # Input features for validation\ny_val &lt;- as.matrix(val_data[, 't+1'])  # Actual output for validation\n\nx_test &lt;- as.matrix(test_data[, 1:12])  # Input features for testing\ny_test &lt;- as.matrix(test_data[, 't+1'])  # Actual output for testing\n\n\n## Plot the result:\nlibrary(xts)\nn&lt;-quantile(sales_data$Date, \n            probs = c(0, 0.7, 0.8,1), \n            type = 1)\n\nm1&lt;-sales_data %&gt;% \n  filter(Date &lt;= n[[2]])\nm2&lt;-sales_data %&gt;% \n  filter(Date &lt;= n[[3]] & Date &gt; n[[2]])\nm3&lt;-sales_data %&gt;% \n  filter(Date &lt;= n[[4]] & Date &gt; n[[3]])\n\ndemand_training&lt;-xts(x=m1$Product_A,\n                     order.by=m1$Date)\ndemand_testing&lt;-xts(x=m2$Product_A,\n                     order.by=m2$Date)\ndemand_forecasting&lt;-xts(x=m3$Product_A,\n                     order.by=m3$Date)\n\nlibrary(dygraphs)\nlines&lt;-cbind(demand_training,\n             demand_testing,\n             demand_forecasting)\ndygraph(lines,\n        main = \"Training and testing data\", \n        ylab = \"Quantity order (Unit: Millions)\") %&gt;% \n  dySeries(\"demand_training\", label = \"Training data\") %&gt;%\n  dySeries(\"demand_testing\", label = \"Testing data\") %&gt;%\n  dySeries(\"demand_forecasting\", label = \"Forecasting data\") %&gt;%\n  dyOptions(fillGraph = TRUE, fillAlpha = 0.4) %&gt;% \n  dyRangeSelector(height = 20)\n\n\n\n\n\n\n\n\n2.3 MÃ´ hÃ¬nh RNN:\nSau Ä‘Ã³, ta sáº½ báº¯t Ä‘áº§u train model báº±ng cÃ¡ch táº¡o thÃªm 12 cá»™t giÃ¡ trá»‹ lÃ  giÃ¡ trá»‹ quÃ¡ khá»© cá»§a demand. Báº¡n sáº½ báº¯t Ä‘áº§u Ä‘á»‹nh nghÄ©a mÃ´ hÃ¬nh gá»“m:\n\nInput: dÃ¹ng hÃ m layer_input(shape = input_shape) vá»›i input_shape lÃ  sá»‘ lÆ°á»£ng predictor.\nLayer: lÃ  cÃ¡c hidden layer trong mÃ´ hÃ¬nh thÃªm vÃ o báº±ng hÃ m layer_dense(x, units = 64, activation = 'relu') vá»›i Ä‘á»‘i sá»‘ units thÆ°á»ng lÃ  bá»™i sá»‘ cá»§a 32 nhÆ° 32,64,256,â€¦\nOutput: dÃ¹ng hÃ m layer_dense(x, units = 1) Ä‘á»ƒ Ä‘á»‹nh nghÄ©a lÃ  Ä‘áº§u ra chá»‰ cÃ³ 1 giÃ¡ trá»‹.\n\n\n\nCode\n# Step 3: Build a simple transformer-like model\nRNN_model &lt;- function(input_shape) {\n  inputs &lt;- layer_input(shape = input_shape)\n\n  # Transformer Encoder Layer (simplified)\n  x &lt;- inputs\n  x &lt;- layer_dense(x, units = 64, activation = 'relu')  # Dense layer\n  x &lt;- layer_dense(x, units = 32, activation = 'relu')  # Another dense layer\n\n  # Output layer\n  x &lt;- layer_dense(x, units = 1)\n  \n  model &lt;- keras_model(inputs, x)\n  return(model)\n}\n\n# Example input shape (12 time steps input per sample)\ninput_shape &lt;- c(12)\n\nRNN_model &lt;- RNN_model(input_shape)\n\n\nÄá»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh truyá»n thá»‘ng nhÆ° linear regression thÃ¬ báº¡n Ä‘Ã£ quen vá»›i thÃ´ng sá»‘ \\(R^2\\) Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh, cÃ²n vá»›i mÃ´ hÃ¬nh Machine learning thÃ¬ dÃ¹ng khÃ¡i niá»‡m loss function - hÃ m máº¥t mÃ¡t. Vá» khÃ¡i niá»‡m, loss function sáº½ Ä‘o lÆ°á»ng chÃªnh lá»‡ch giá»¯a predicted vÃ  actual trong bá»™ training data nÃªn khi cÃ ng tÄƒng epochs nghÄ©a lÃ  tÄƒng sá»‘ láº§n há»c láº¡i dá»¯ liá»‡u thÃ¬ loss function sáº½ tÃ­nh ra giÃ¡ trá»‹ cÃ ng tháº¥p. NhÆ° mÃ´ hÃ¬nh trÃªn thÃ¬ mÃ¬nh Ä‘áº·t Ä‘á»‘i sá»‘ loss = mse nghÄ©a lÃ  sá»­ dá»¥ng Mean Squared Error Ä‘á»ƒ tá»‘i Æ°u quy trÃ¬nh há»c cá»§a há»c mÃ¡y. CÃ´ng thá»©c nhÆ° sau:\n\\[\nMSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_{\\text{pred}}(i) - y_{\\text{true}}(i))^2\n\\]\nCÃ²n Ä‘á»‘i sá»‘ metrics = c('mae') nghÄ©a lÃ  tiÃªu chÃ­ khÃ¡c Ä‘á»ƒ theo dÃµi vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh. Váº­y táº¡i sao cáº§n cÃ³ 2 tham sá»‘ Ä‘Ã¡nh giÃ¡ song song nhÆ° váº­y lÃ  vÃ¬ nhÆ° Ä‘Ã£ nÃ³i, náº¿u báº¡n cÃ ng tÄƒng epochs thÃ¬ giÃ¡ trá»‹ loss cÃ ng tháº¥p trong khi dÃ¹ng metrics sáº½ Ä‘Æ°a ra Ä‘Ã¡nh giÃ¡ khÃ¡ch quan hÆ¡n vá» mÃ´ hÃ¬nh mÃ  khÃ´ng phá»¥ thuá»™c vÃ o sá»‘ láº§n epochs. CÃ´ng thá»©c nhÆ° sau:\n\\[\n\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_{\\text{pred}}(i) - y_{\\text{true}}(i)|\n\\]\nVáº­y khi cháº¡y code, R sáº½ return output nhÆ° biá»ƒu Ä‘á»“ dÆ°á»›i Ä‘Ã¢y lÃ  so sÃ¡nh tham sá»‘ cá»§a mse vÃ  mae giá»¯a training data vÃ  evaluating data. Ã tÆ°á»Ÿng lÃ  Ä‘Ã¡nh giÃ¡ thá»­ mÃ´ hÃ¬nh cÃ³ dá»± Ä‘oÃ¡n tá»‘t khÃ´ng khi cÃ³ dá»¯ liá»‡u má»›i vÃ o.\nTiáº¿p theo, ta sáº½ dÃ¹ng test data Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh vá»«a xÃ¢y dá»±ng. Káº¿t quáº£ cÃ³ váº» khÃ¡ tuyá»‡t vÃ¬ mÃ´ hÃ¬nh gáº§n nhÆ° theo sÃ¡t Ä‘Æ°á»£c dá»¯ liá»‡u cá»§a test data.\n\n\nCode\n# Step 6: Make predictions\nRNN_forecast &lt;- RNN_model %&gt;% \n  predict(x_test)\n\n\n2/2 - 0s - 95ms/epoch - 48ms/step\n\n\nCode\n# Step 7: Combine predicted and observed\nplot_data &lt;- data.frame(\n  time = c(min(m3$Date)-days(1),m3$Date),  # Time for the test set\n  actual = y_test,  # Actual values from the test set\n  forecast = RNN_forecast  # Forecasted values\n)\n\n# Step 8: Plot using Highcharts\nhighchart() %&gt;%\n  hc_title(text = \"Time Series Forecasting with Highcharts\") %&gt;%\n  hc_xAxis(\n    categories = plot_data$time,\n    title = list(text = \"Time\")\n  ) %&gt;%\n  hc_yAxis(\n    title = list(text = \"Value\"),\n    plotLines = list(list(\n      value = 0,\n      width = 1,\n      color = \"gray\"\n    ))\n  ) %&gt;%\n  hc_add_series(\n    name = \"Actual Data\",\n    data = plot_data$actual,\n    type = \"line\",\n    color = \"#1f77b4\"  # Blue color for actual data\n  ) %&gt;%\n  hc_add_series(\n    name = \"Forecast\",\n    data = plot_data$forecast,\n    type = \"line\",\n    color = \"#ff7f0e\"  # Orange color for forecast data\n  ) %&gt;%\n  hc_tooltip(\n    shared = TRUE,\n    crosshairs = TRUE\n  ) %&gt;%\n  hc_legend(\n    enabled = TRUE\n  )\n\n\n\n\n\n\n\n\n2.4 MÃ´ hÃ¬nh LSTM:\nTiáº¿p theo, ta sáº½ xÃ¢y dá»±ng thá»­ mÃ´ hÃ¬nh LSTM. MÃ´ hÃ¬nh LSTM thÆ°á»ng bao gá»“m cÃ¡c lá»›p sau:\n\nLá»›p LSTM: ÄÃ¢y lÃ  lá»›p chÃ­nh, cÃ³ thá»ƒ cÃ³ má»™t hoáº·c nhiá»u lá»›p LSTM chá»“ng lÃªn nhau. Má»—i lá»›p LSTM cÃ³ thá»ƒ tráº£ vá» toÃ n bá»™ chuá»—i báº±ng return_sequences = TRUE hoáº·c chá»‰ tráº£ vá» giÃ¡ trá»‹ cuá»‘i cÃ¹ng báº±ng return_sequences = FALSE.\nLá»›p Dense: Sau khi thÃ´ng tin Ä‘Æ°á»£c xá»­ lÃ½ qua cÃ¡c lá»›p LSTM, nÃ³ sáº½ Ä‘Æ°á»£c Ä‘Æ°a qua cÃ¡c lá»›p Dense (lá»›p fully connected) Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n cuá»‘i cÃ¹ng.\nLá»›p Dropout (tÃ¹y chá»n): Äá»ƒ trÃ¡nh overfitting, cÃ³ thá»ƒ thÃªm lá»›p dropout Ä‘á»ƒ táº¯t ngáº«u nhiÃªn má»™t sá»‘ nÆ¡-ron trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n.\n\nVáº­y giá» ta sáº½ so sÃ¡nh vá»›i mÃ´ hÃ¬nh RNN trÆ°á»›c vá»›i mÃ´ hÃ¬nh LSTM qua 2 thÃ´ng sá»‘ Ä‘Ã£ chá»n mse vÃ  mae.\n\n\nCode\n# Extract metrics into a data frame\nresults_df &lt;- data.frame(\n  Model = c(\"RNN\", \"LSTM\"),\n  Metric = c(\"Loss\", \"metric\"),\n  MSE = c(RNN_result[[1]],RNN_result[[2]]),\n  MAE = c(LSTM_result[[1]], LSTM_result[[2]])\n)\n\nlibrary(gt)\n# Create a gt table\nresults_df %&gt;%\n  gt() %&gt;%\n  tab_header(\n    title = \"Model Performance Metrics\",\n    subtitle = \"Comparison of MSE and MAE for RNN and LSTM\"\n  ) %&gt;%\n  fmt_number(\n    columns = vars(MSE, MAE),\n    decimals = 4\n  ) %&gt;%\n  cols_label(\n    Model = \"Model Type\",\n    MSE = \"Mean Squared Error\",\n    MAE = \"Mean Absolute Error\"\n  ) %&gt;%\n  tab_options(\n    table.font.size = 14,\n    heading.title.font.size = 16,\n    heading.subtitle.font.size = 14\n  )\n\n\n\n\n\n\n\n\nModel Performance Metrics\n\n\nComparison of MSE and MAE for RNN and LSTM\n\n\nModel Type\nMetric\nMean Squared Error\nMean Absolute Error\n\n\n\n\nRNN\nLoss\n0.0000\n0.0001\n\n\nLSTM\nmetric\n0.0019\n0.0055\n\n\n\n\n\n\n\nKáº¿t quáº£ cho tháº¥y mÃ´ hÃ¬nh RNN truyá»n thá»‘ng Ä‘Æ°a ra káº¿t quáº£ tá»‘t hÆ¡n LSTM máº·c dÃ¹ sai sá»‘ cá»§a LSTM Ä‘á»u &lt; 0.03 lÃ  khÃ´ng quÃ¡ tá»‡ nhÆ°ng tiÃªu chÃ­ váº«n lÃ  mÃ´ hÃ¬nh nÃ o hiá»‡u quáº£ nháº¥t.\n\n\nCode\nLSTM_forecast &lt;- LSTM_model %&gt;% \n  predict(x_test)\n\n\n2/2 - 1s - 745ms/epoch - 372ms/step\n\n\nCode\ncompare&lt;-data.frame(Date = c(min(m3$Date)-days(1),m3$Date),\n                    LSTM = round(LSTM_forecast - y_test,3),\n                    RNN = round(RNN_forecast - y_test,3)\n)\n\n# Create the highchart plot\nhighchart() %&gt;%\n  hc_chart(type = \"line\") %&gt;%\n  hc_title(text = \"Residual Comparison: LSTM vs RNN\") %&gt;%\n  hc_xAxis(\n    categories = compare$Date,\n    title = list(text = \"Date\")\n  ) %&gt;%\n  hc_yAxis(\n    title = list(text = \"Residuals\"),\n    plotLines = list(\n      list(value = 0, color = \"gray\", width = 1, dashStyle = \"Dash\")\n    )\n  ) %&gt;%\n  hc_add_series(\n    name = \"LSTM Residuals\",\n    data = compare$LSTM,\n    color = \"#1f77b4\"\n  ) %&gt;%\n  hc_add_series(\n    name = \"RNN Residuals\",\n    data = compare$RNN,\n    color = \"#ff7f0e\"\n  ) %&gt;%\n  hc_tooltip(shared = TRUE) %&gt;%\n  hc_legend(enabled = TRUE)\n\n\n\n\n\n\n\n\n2.5 XÃ¡c Ä‘á»‹nh cáº¥u trÃºc mÃ´ hÃ¬nh:\nNáº¿u báº¡n Ä‘á»ƒ Ã½, thá»±c cháº¥t code cho mÃ´ hÃ¬nh cho nhÆ° mÃ¬nh Ä‘Ã£ trÃ¬nh bÃ y thÃ¬ khÃ¡ Ä‘Æ¡n giáº£n vÃ  Ä‘iá»u khÃ³ nháº¥t trong mÃ´ hÃ¬nh lÃ  xÃ¡c Ä‘á»‹nh sá»‘ lá»›p layer trong mÃ´ hÃ¬nh. NhÆ° bÃ i toÃ¡n time series forecasting thÃ¬ mÃ¬nh chá»‰ cáº§n 2,3 lá»›p layer Ä‘Æ¡n giáº£n lÃ  Ä‘Ã£ Ä‘áº¡t káº¿t quáº£ tá»‘t vá»›i sai sá»‘ ráº¥t tháº¥p (&lt; 0.03), cÃ²n vá»›i cÃ¡c bÃ i toÃ¡n phá»©c táº¡p hÆ¡n thÃ¬ sá»‘ layer sáº½ nhiá»u hÆ¡n.\nVáº­y quy táº¯c xÃ¡c Ä‘á»‹nh mÃ´ hÃ¬nh lÃ  nhÆ° tháº¿ nÃ o ? CÃ¢u tráº£ lá»i lÃ  khÃ´ng cÃ³ quy táº¯c nÃ o cáº£ vÃ  chá»‰ cÃ³ cÃ¡c tips mÃ  mÃ¬nh lá»¥m nháº·t trÃªn máº¡ng nhÆ° sau:\n\nNumber of layer nÃªn náº±m giá»¯a sá»‘ input vÃ  sá»‘ output. NhÆ° bÃ i thá»±c hÃ nh trÃªn thÃ¬ sá»‘ layer nÃªn náº±m trong khoáº£ng (1,12). Hoáº·c báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng hÃ m dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ xÃ¡c Ä‘á»‹nh.\n\n\\[\nN_h = \\frac{N_s}{\\alpha \\cdot (N_i + N_o)}\n\\]\nVá»›i cÃ¡c tham sá»‘ gá»“m:\n\n\\(N_h\\) lÃ  sá»‘ lÆ°á»£ng hidden neurons.\n\\(N_s\\) lÃ  sá»‘ lÆ°á»£ng máº«u trong training data.\n\\(\\alpha\\) lÃ  yáº¿u tá»‘ tá»· lá»‡ tÃ¹y Ã½ (thÆ°á»ng tá»« 2-10).\n\\(N_i\\) lÃ  sá»‘ lÆ°á»£ng nÆ¡-ron input\n\\(N_o\\) lÃ  sá»‘ lÆ°á»£ng nÆ¡-ron output.\n\n\nCÃ¡c hÃ m acvtivation nhÆ° Tanh thÃ¬ phÃ¹ há»£p cho dá»± bÃ¡o giÃ¡ trá»‹ liÃªn tá»¥c tá»« dá»¯ liá»‡u chuá»—i, ReLU giÃºp cho quÃ¡ trÃ¬nh training nhanh hÆ¡n vÃ  khÃ´ng gÃ¢y ra vanishing problem do khÃ´ng bá»‹ cháº·n, Softmax thÆ°á»ng dÃ¹ng á»Ÿ final layer cho bÃ i toÃ¡n classification, Sigmoid thÆ°á»ng dÃ¹ng cho há»“i quy logic.\nNumber of neurons: Sá»‘ lÆ°á»£ng nÆ¡-ron trong má»™t lá»›p quyáº¿t Ä‘á»‹nh lÆ°á»£ng thÃ´ng tin mÃ  máº¡ng cÃ³ thá»ƒ lÆ°u trá»¯. Nhiá»u nÆ¡-ron giÃºp máº¡ng há»c Ä‘Æ°á»£c cÃ¡c máº«u phá»©c táº¡p hÆ¡n, nhÆ°ng cÅ©ng lÃ m tÄƒng nguy cÆ¡ overfitting (quÃ¡ khá»›p) vÃ  yÃªu cáº§u nhiá»u tÃ i nguyÃªn tÃ­nh toÃ¡n hÆ¡n. Báº¡n cÃ³ thá»ƒ báº¯t Ä‘áº§u vá»›i má»™t sá»‘ lÆ°á»£ng nÆ¡-ron tÆ°Æ¡ng Ä‘á»‘i nhá», nhÆ° 128 hoáº·c 256â€¦"
  },
  {
    "objectID": "torch.html#káº¿t-luáº­n",
    "href": "torch.html#káº¿t-luáº­n",
    "title": "RNN and LSTM model",
    "section": "3 Káº¿t luáº­n:",
    "text": "3 Káº¿t luáº­n:\nNhÆ° váº­y, chÃºng ta Ä‘Ã£ Ä‘Æ°á»£c há»c vá» mÃ´ hÃ¬nh RNN vÃ  LSTM vÃ  cÃ¡ch xÃ¢y dá»±ng chÃºng trong R.\nNáº¿u báº¡n cÃ³ cÃ¢u há»i hay tháº¯c máº¯c nÃ o, Ä‘á»«ng ngáº§n ngáº¡i liÃªn há»‡ vá»›i mÃ¬nh qua Gmail. BÃªn cáº¡nh Ä‘Ã³, náº¿u báº¡n muá»‘n xem láº¡i cÃ¡c bÃ i viáº¿t trÆ°á»›c Ä‘Ã¢y cá»§a mÃ¬nh, hÃ£y nháº¥n vÃ o hai nÃºt dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ truy cáº­p trang Rpubs hoáº·c mÃ£ nguá»“n trÃªn Github. Ráº¥t vui Ä‘Æ°á»£c Ä‘á»“ng hÃ nh cÃ¹ng báº¡n, háº¹n gáº·p láº¡i! ğŸ˜„ğŸ˜„ğŸ˜„\n\n\n\n    \n    \n    Contact Me\n    \n    \n    \n\n\n    \n        Contact Me\n        \n            Your Email:\n            \n            Please enter a valid email address.\n            Send Email\n        \n        \n            \n                \n                     View Code on GitHub\n                \n            \n        \n        \n            \n                \n                     Visit my RPubs"
  },
  {
    "objectID": "torch.html#mÃ´-hÃ¬nh-rnn",
    "href": "torch.html#mÃ´-hÃ¬nh-rnn",
    "title": "RNN and LSTM model",
    "section": "1 MÃ´ hÃ¬nh RNN:",
    "text": "1 MÃ´ hÃ¬nh RNN:\n\n1.1 Äá»‹nh nghÄ©a:\nÄiá»ƒm chung lÃ  cáº£ hai mÃ´ hÃ¬nh Ä‘á»u thuá»™c phÃ¢n lá»›p Deep learning - nghÄ©a lÃ  há»c mÃ¡y sÃ¢u vá»›i Ä‘áº·c Ä‘iá»ƒm chung lÃ  phÃ¢n chia dá»¯ liá»‡u thÃ nh nhiá»u lá»›p vÃ  báº¯t Ä‘áº§u â€œhá»câ€ dáº§n qua tá»«ng lá»›p Ä‘á»ƒ Ä‘Æ°a ra káº¿t quáº£ cuá»‘i cÃ¹ng. á» hÃ¬nh dÆ°á»›i Ä‘Ã¢y, \\(X_o\\) Ä‘áº¡i diá»‡n cho dá»¯ liá»‡u Ä‘áº§u vÃ o, \\(h_t\\) lÃ  output Ä‘áº§u ra cá»§a tá»«ng step vÃ  \\(A\\) lÃ  nhá»¯ng gÃ¬ Ä‘Ã£ â€œhá»câ€ Ä‘Æ°á»£c táº¡i step Ä‘Ã³ vÃ  Ä‘Æ°á»£c truyá»n cho step tiáº¿p theo. Trong tÃ i liá»‡u chuáº©n thÃ¬ há» thÆ°á»ng kÃ­ hiá»‡u lÃ  \\(X_t\\), \\(Y_t\\), \\(h_{t-1}\\).\n\n  \n  \n  \n  \n    HÃ¬nh 1: Minh há»a vá» sá»± phÃ¢n chia dá»¯ liá»‡u thÃ nh nhiá»u lá»›p\n  \n  \n  \n  \n    Source: Link to Image\n  \n\nKhi nhÃ¬n hÃ¬nh thÃ¬ báº¡n cÃ³ thá»ƒ bá»‘i rá»‘i chÆ°a hiá»ƒu cÃ¡c kÃ­ tá»± vÃ  hÃ¬nh áº£nh thÃ¬ báº¡n cÃ³ thá»ƒ tÆ°á»Ÿng tÆ°á»£ng há»c mÃ¡y nhÆ° 1 Ä‘á»©a tráº» vÃ  Ä‘á»ƒ nÃ³ cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c cÃ¢u: â€œHÃ´m nay con Ä‘i há»câ€ thÃ¬ nÃ³ pháº£i há»c tá»«ng chá»¯ cÃ¡i nhÆ°: a,b,c,â€¦ trÆ°á»›c rÃ²i má»›i ghÃ©p thÃ nh tá»« Ä‘Æ¡n nhÆ°: â€œHÃ´mâ€,â€œNayâ€,â€¦ rá»“i ghÃ©p thÃ nh cÃ¢u trÃªn.\nVáº­y giáº£ sá»­ nhÆ° hÃ´m nay há»c Ä‘Æ°á»£c tá»« â€œHÃ´mâ€ thÃ¬ nÃ³ sáº½ báº¯t Ä‘áº§u ghi nhá»› tá»« Ä‘Ã£ há»c vÃ o trong \\(A\\). Náº¿u sau nÃ y ta cáº§n há»c mÃ¡y hiá»ƒu cÃ¢u â€œHÃ´m sau con Ä‘i chÆ¡iâ€ thÃ¬ tá»‘c Ä‘á»™ há»c cá»§a há»c mÃ¡y sáº½ nhanh lÃªn vÃ¬ thay vÃ¬ nÃ³ pháº£i há»c 5 chá»¯ Ä‘Æ¡n nhÆ° thÃ´ng thÆ°á»ng thÃ¬ nÃ³ chá»‰ cáº§n há»c 4 chá»¯ cÃ²n láº¡i trá»« chá»¯ â€œhÃ´mâ€. Váº­y báº¡n Ä‘Ã£ hiá»ƒu Ã½ tÆ°á»Ÿng ná»n táº£ng cá»§a RNN rá»“i ha!\n\n\n1.2 NguyÃªn lÃ­ hoáº¡t Ä‘á»™ng:\nÄáº§u tiÃªn, RNN sáº½ tÃ­nh toÃ¡n hidden state lÃ  \\(h_t\\) vá»›i cÃ´ng thá»©c lÃ :\n\\[\n   \\mathbf{h}_t = \\text{activation}(\\mathbf{W}_\\text{hh} \\mathbf{h}_{t-1} + \\mathbf{W}_\\text{xh} \\mathbf{x}_t + \\mathbf{b}_\\text{h})\n\\] Sau Ä‘Ã³, \\(h_t\\) sáº½ Ä‘Æ°á»£c lÃ m input cho cÃ¡c state sau vÃ  dá»±a vÃ o Ä‘Ã³ Ä‘á»ƒ tÃ­nh output vá»›i cÃ´ng thá»©c lÃ :\n\\[\ny_t = W_y \\cdot h_t + b_y\n\\]\nVÃ­ dá»¥: MÃ¬nh muá»‘n dá»± Ä‘oÃ¡n hÃ nh Ä‘á»™ng trong cÃ¢u nÃ³i â€œI am reading bookâ€ báº±ng mÃ´ hÃ¬nh RNN nhÆ° sau:\n\nBÆ°á»›c 1: Chuyá»ƒn Ä‘á»•i thÃ nh dáº¡ng sá»‘ báº±ng embedding layer:\n\nMÃ¬nh sáº½ gÃ¡n tá»«ng tá»« Ä‘Æ¡n sang dáº¡ng sá»‘ nhÆ°:\n\nâ€œIâ€ -&gt; \\(x_1\\)\nâ€œamâ€ -&gt; \\(x_2\\)\nâ€œreadingâ€ -&gt; \\(x_3\\)\nâ€œbookâ€ -&gt; \\(x_4\\)\nBÆ°á»›c 2: ThÃªm hidden layer vÃ  báº¯t Ä‘áº§u tÃ­nh toÃ¡n:\n\nCho input: â€œIâ€ \\[\n   h_1 = \\tanh(W_x \\cdot x_1 + W_h \\cdot h_0 + b)\n\\]\nCho input: â€œamâ€ \\[\n   h_2 = \\tanh(W_x \\cdot x_2 + W_h \\cdot h_1 + b)\n\\] Cho input: â€œreadingâ€ \\[\n   h_3 = \\tanh(W_x \\cdot x_3 + W_h \\cdot h_2 + b)\n\\]\nCho input: â€œbookâ€ \\[\n   h_4 = \\tanh(W_x \\cdot x_4 + W_h \\cdot h_3 + b)\n\\]\n\nBÆ°á»›c 3: TÃ­nh toÃ¡n output: DÃ¹ng hÃ m activation softmax Ä‘á»ƒ phÃ¢n lá»›p theo xÃ¡c suáº¥t.\n\n\\[\n\\hat{y} = \\text{softmax}(W_y \\cdot h_4 + b_y)\n\\] Náº¿u muá»‘n hiá»ƒu thÃªm vá» cÃ¡ch hoáº¡t Ä‘á»™ng RNN, báº¡n cÃ³ thá»ƒ tham kháº£o link nÃ y: Recurrent Neural Network: Tá»« RNN Ä‘áº¿n LSTM.\n\n\n1.3 Váº¥n Ä‘á» lá»›n cá»§a RNN:\nRNN cÃ³ 1 váº¥n Ä‘á» lá»›n lÃ  Vanishing Gradient nghÄ©a lÃ  mÃ´ hÃ¬nh sáº½ khÃ´ng cÃ²n â€œhá»câ€ thÃªm Ä‘Æ°á»£c ná»¯a cho dÃ¹ tÄƒng sá»‘ epochs. NguyÃªn nhÃ¢n vÃ¬ sao nhÆ° váº­y thÃ¬ báº¡n cÃ³ thá»ƒ tham kháº£o pháº§n chá»©ng minh cá»§a anh Tuáº¥n.\n\n  \n  \n  \n  \n    HÃ¬nh 2: Vanishing Gradient Problem\n  \n  \n  \n  \n    Source: Link to Image\n  \n\nVáº¥n Ä‘á» nÃ y sáº½ lÃ m network khÃ³ update weight dáº«n tá»›i thá»i gian há»c lÃ¢u vÃ  khÃ³ Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c output. Báº¡n cÃ³ thá»ƒ hiá»ƒu Ä‘Æ¡n giáº£n nhÆ° viá»‡c báº¡n há»c liÃªn tá»¥c dáº«n tá»›i quÃ¡ táº£i vÃ  RNN cÅ©ng khÃ´ng nhÆ° váº­y. Do Ä‘Ã³, RNN chá»‰ há»c cÃ¡c thÃ´ng tin tá»« state gáº§n vÃ  Ä‘Ã³ lÃ  lÃ­ do ra Ä‘á»i LSTM - Long short term memory.\n\n\n\n\n\n\nWarning\n\n\n\nLÆ°u Ã½: Äiá»u nÃ y khÃ´ng cÃ³ nghÄ©a LSTM luÃ´n tá»‘t hÆ¡n RNN vÃ¬ cÃ³ nhá»¯ng bÃ i toÃ¡n vá»›i Ä‘áº§u vÃ o Ä‘Æ¡n giáº£n thÃ¬ mÃ´ hÃ¬nh chá»‰ cáº§n há»c cÃ¡c step Ä‘áº§u lÃ  Ä‘Ã£ â€œhá»câ€ Ä‘áº§y Ä‘á»§ thÃ´ng tin cáº§n thiáº¿t. MÃ´ hÃ¬nh LSTM phá»• biáº¿n vá»›i cÃ¡c bÃ i toÃ¡n phá»©c táº¡p nhÆ° tá»± Ä‘á»™ng dá»‹ch ngÃ´n ngá»¯, ghi chÃ©p láº¡i theo giá»ng nÃ³iâ€¦\n\n\n\n\n1.4 MÃ´ hÃ¬nh LSTM:\nCÃ³ thá»ƒ xem mÃ´ hÃ¬nh LSTM nhÆ° biáº¿n thá»ƒ cá»§a RNN. Vá» cáº¥u trÃºc, LSTM phá»©c táº¡p hÆ¡n RNN:\n\n  \n  \n  \n  \n    HÃ¬nh 3: So sÃ¡nh mÃ´ hÃ¬nh RNN vÃ  LSTM\n  \n  \n  \n  \n    Source: Link to Image\n  \n\nCáº¥u trÃºc cÆ¡ báº£n gá»“m:\n\nCá»•ng quÃªn (Forget Gate): cÃ³ tÃ¡c dá»¥ng quyáº¿t Ä‘á»‹nh thÃ´ng tin nÃ o cáº§n bá»‹ quÃªn trong tráº¡ng thÃ¡i Ã´ nhá»›.\nCá»•ng nháº­p (Input Gate): XÃ¡c Ä‘á»‹nh thÃ´ng tin nÃ o cáº§n Ä‘Æ°á»£c ghi vÃ o tráº¡ng thÃ¡i Ã´ nhá»›.\nCá»•ng xuáº¥t (Output Gate): Quyáº¿t Ä‘á»‹nh thÃ´ng tin nÃ o sáº½ Ä‘Æ°á»£c xuáº¥t ra tá»« tráº¡ng thÃ¡i Ã´ nhá»› Ä‘á»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n dá»± Ä‘oÃ¡n tiáº¿p theo.\n\nBáº¡n cÃ³ thá»ƒ kham kháº£o thÃªm bÃ i viáº¿t cá»§a dominhhai vá» cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a RNN vÃ  LSTM Ä‘á»ƒ hiá»ƒu thÃªm.\nTiáº¿p theo, ta sáº½ báº¯t Ä‘áº§u xÃ¢y dá»±ng thá»­ mÃ´ hÃ¬nh trong R."
  },
  {
    "objectID": "transfer.html",
    "href": "transfer.html",
    "title": "MÃ´ hÃ¬nh Transformer",
    "section": "",
    "text": "Trong má»™t nghiÃªn cá»©u cá»§a (Jimeng Shi, Mahek Jain, and Giri Narasimhan 2022) vá» viá»‡c á»©ng dá»¥ng hÃ ng loáº¡t cÃ¡c mÃ´ hÃ¬nh thuá»™c phÃ¢n lá»›p Deep learning vÃ  so sÃ¡nh Ä‘á»ƒ chá»n ra mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n tá»‘t nháº¥t chá»‰ sá»‘ PM2.5 (lÃ  chá»‰ sá»‘ Ä‘o lÆ°á»ng lÆ°á»£ng háº¡t bá»¥i li ti cÃ³ trong khÃ´ng khÃ­ vá»›i kÃ­ch thÆ°á»›c 2,5 micron trá»Ÿ xuá»‘ng). Káº¿t quáº£ cÃ³ bao gá»“m: â€œMÃ´ hÃ¬nh Transformer dá»± Ä‘oÃ¡n tá»‘t nháº¥t cho dá»± Ä‘oÃ¡n long-term trong tÆ°Æ¡ng lai. LSTM vÃ  GRU vÆ°á»£t trá»™i hÆ¡n RNN cho cÃ¡c dá»± Ä‘oÃ¡n short-term.â€\nVáº­y mÃ´ hÃ¬nh Transformer lÃ  gÃ¬ ? ChÃºng ta sáº½ há»c nÃ³ á»Ÿ bÃ i nÃ y."
  },
  {
    "objectID": "transfer.html#mÃ´-hÃ¬nh-transformer",
    "href": "transfer.html#mÃ´-hÃ¬nh-transformer",
    "title": "MÃ´ hÃ¬nh Transformer",
    "section": "1 MÃ´ hÃ¬nh Transformer:",
    "text": "1 MÃ´ hÃ¬nh Transformer:\n\n1.1 Giá»›i thiá»‡u:\n\n\nCode\npacman::p_load(torch,\n               dplyr,\n               tidyverse)\n\n\nCháº¯c cÃ¡c báº¡n Ä‘Ã£ quÃ¡ quen thuá»™c vá»›i Chatgpt - má»™t cÃ´ng cá»¥ AI máº¡nh máº½ trong thá»i gian gáº§n Ä‘Ã¢y vá»›i lÆ°á»£ng ngÆ°á»i sá»­ dá»¥ng cá»±c kÃ¬ cao. NhÆ° biá»ƒu Ä‘á»“ dÆ°á»›i Ä‘Ã¢y, tá»« khi launched Chatgpt chá»‰ tá»‘n 5 ngÃ y Ä‘á»ƒ Ä‘áº¡t 1 triá»‡u ngÆ°á»i sá»­ dá»¥ng vÃ  ngoÃ i ra theo thá»‘ng kÃª Ä‘áº¿n thÃ¡ng 2/2024, Chatgpt Ä‘Ã£ cÃ³ tá»›i 1.6 tá»‰ lÆ°á»£t thÄƒm quan.\n\n  \n  \n  \n  \n    HÃ¬nh 1: Thá»i gian Ä‘á»ƒ Ä‘áº¡t 1 triá»‡u ngÆ°á»i dÃ¹ng cá»§a Chatgpt\n  \n  \n  \n  \n    Source: Link to Image\n  \n\nÃ tÆ°á»Ÿng ban Ä‘áº§u cá»§a Chatgpt chÃ­nh lÃ  dá»±a trÃªn cáº¥u trÃºc mÃ´ hÃ¬nh Transformer - 1 dáº¡ng Deep learning chá»‰ má»›i Ä‘Æ°á»£c giá»›i thiá»‡u vá»›i tháº¿ giá»›i tá»« nÄƒm 2017 nhÆ°ng cÃ³ sá»©c áº£nh hÆ°á»Ÿng ráº¥t lá»›n, nháº¥t lÃ  trong lÄ©nh vá»±c Generative AI.\nKhÃ¡i niá»‡m vá» mÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c giá»›i thiá»‡u láº§n Ä‘áº§u vÃ o nÄƒm 2017 cá»§a cÃ¡c nhÃ  nghiÃªn cá»©u cá»§a Google trong bÃ i tÃ i liá»‡u Attention is all you need. MÃ´ hÃ¬nh nÃ y dá»±a trÃªn Ã½ tÆ°á»Ÿng lÃ  xÃ¡c Ä‘á»‹nh cÃ¡c thÃ nh pháº§n quan trá»ng trong sequence vÃ  cho phÃ©p mÃ´ hÃ¬nh Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh dá»±a trÃªn sá»± phá»¥ thuá»™c giá»¯a cÃ¡c pháº§n tá»­ trong Ä‘áº§u vÃ o, báº¥t ká»ƒ khoáº£ng cÃ¡ch cá»§a chÃºng vá»›i nhau, quÃ¡ trÃ¬nh nÃ y gá»i lÃ  Attention mechanisms. Dá»±a vÃ o Ä‘Ã³, mÃ´ hÃ¬nh Transformer sáº½ chuyá»ƒn Ä‘á»•i má»™t chuá»—i input thÃ nh 1 chuá»—i output khÃ¡c nhÆ°ng váº«n Ä‘áº£m báº£o giá»¯ láº¡i cÃ¡c Ä‘áº·c Ä‘iá»ƒm quan trá»ng cá»§a sequence Ä‘Ã³.\n\n  \n  \n  \n  \n    HÃ¬nh 2: Input vÃ  output cá»§a mÃ´ hÃ¬nh\n  \n  \n  \n  \n    Source: Link to Image\n  \n\nVÃ­ dá»¥ vá»›i viá»‡c dá»‹ch thuáº­t vÄƒn báº£n sáº½ cÃ³ nhá»¯ng tá»« trong cÃ¢u, cÃ¢u trong Ä‘oáº¡n vÄƒn Ä‘áº¡i diá»‡n cho Ã½ nghÄ©a toÃ n cÃ¢u, toÃ n Ä‘oáº¡n vÄƒn. Hay vá»›i vá» viá»‡c phÃ¢n tÃ­ch demand trong time series, lÆ°á»£ng mua hÃ ng vÃ o nhá»¯ng ngÃ y nghá»‰, cuá»‘i tuáº§n sáº½ Ä‘Æ°a ra insight tá»‘t hÆ¡n vÃ o cÃ¡c ngÃ y bÃ¬nh thÆ°á»ng. NhÆ° váº­y, báº¡n tháº¥y Ä‘Ã³, mÃ´ hÃ¬nh Transformer phÃ¹ há»£p vá»›i cÃ¡c task thuá»™c dáº¡ng dá»‹ch vÄƒn báº£n, dá»± Ä‘oÃ¡n chuá»—i hÃ nh Ä‘á»™ng liÃªn tiáº¿p cá»§a Ä‘á»‘i tÆ°á»£ng,â€¦\n\n\n1.2 So sÃ¡nh vá»›i RNN, LSTM:\nNhÆ° hÃ¬nh trÃªn, báº¡n cÃ³ thá»ƒ tháº¥y mÃ´ hÃ¬nh Transformer cÅ©ng gá»“m Encoder vÃ  Decoder giá»‘ng nhÆ° cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a RNN, LSTM. NhÆ°ng khÃ¡c nhau á»Ÿ chá»—, thay vÃ¬ cÆ¡ cháº¿ Ä‘Ã³ hoáº¡t Ä‘á»™ng á»Ÿ tá»«ng timestep liÃªn tá»¥c nhau nhÆ° RNN thÃ¬ á»Ÿ Transformer input Ä‘Æ°á»£c Ä‘áº©y vÃ o cÃ¹ng 1 lÃºc (nghÄ©a lÃ  khÃ´ng cÃ²n há»c theo tá»«ng timestep ná»¯a). Nhá» váº­y, Transformer sáº½ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c cÃ¡c thÃ nh pháº§n quan trá»ng trong sequence vÃ  lá»±a chá»n thÃ´ng sá»‘ cho chÃºng (Hiá»ƒu Ä‘Æ¡n giáº£n nhÆ° viá»‡c báº¡n cáº§n nghe háº¿t Ä‘oáº¡n thoáº¡i cá»§a ngÆ°á»i Ä‘á»‘i diá»‡n thÃ¬ má»›i hiá»ƒu Ä‘Æ°á»£c há» Ä‘ang nÃ³i gÃ¬ vÃ  chá»n lá»c cÃ¡c keyword Ä‘á»ƒ xÃ¡c Ä‘á»‹nh Ã½ chÃ­nh cá»§a Ä‘oáº¡n vÄƒn Ä‘Ã³ vÃ  Ä‘Ã³ lÃ  Ã½ tÆ°á»Ÿng chÃ­nh xÃ¢y dá»±ng lÃªn mÃ´ hÃ¬nh nÃ y).\n\n  \n  \n  \n  \n    HÃ¬nh 3: So sÃ¡nh performance giá»¯a mÃ´ hÃ¬nh Transformer vÃ  LSTM\n  \n  \n  \n  \n    Source: Link to Image\n  \n\nNgoÃ i ra, chÃ­nh cÆ¡ cháº¿ Self-attention Ä‘Ã£ táº¡o sá»± khÃ¡c biá»‡t lá»›n cho mÃ´ hÃ¬nh Transformer so vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c. NhÆ° hÃ¬nh dÆ°á»›i Ä‘Ã¢y lÃ  nghiÃªn cá»©u cá»§a vá» viá»‡c á»©ng dá»¥ng Deep learning Ä‘á»ƒ táº¡o phá»¥ Ä‘á» cho video. NghiÃªn cá»©u Ä‘Ã£ so sÃ¡nh performance giá»¯a 2 mÃ´ hÃ¬nh (i) Transformer-based model vÃ  (ii) LSTM-based model khi hyperparamater tuning. Káº¿t quáº£ cho tháº¥y sá»± vÆ°á»£t trá»™i cá»§a Transformer khi chá»‰ sá»‘ accuracy lÃªn tá»›i 97%.\nTiáº¿p theo, chÃºng ta sáº½ tÃ¬m hiá»ƒu vá» cÃ¡c thÃ nh pháº§n chÃ­nh trong mÃ´ hÃ¬nh Transformer."
  },
  {
    "objectID": "transfer.html#cÃ¡c-thÃ nh-pháº§n-cÆ¡-báº£n-trong-transformer",
    "href": "transfer.html#cÃ¡c-thÃ nh-pháº§n-cÆ¡-báº£n-trong-transformer",
    "title": "MÃ´ hÃ¬nh Transformer",
    "section": "2 CÃ¡c thÃ nh pháº§n cÆ¡ báº£n trong Transformer:",
    "text": "2 CÃ¡c thÃ nh pháº§n cÆ¡ báº£n trong Transformer:\nVá» nguyÃªn lÃ­ hoáº¡t Ä‘á»™ng, mÃ¬nh sáº½ chia thÃ nh cÃ¡c pháº§n nhÆ° sau theo cÃ¡ch giáº£i thÃ­ch cÃ¡ nhÃ¢n Ä‘á»ƒ giÃºp má»i ngÆ°á»i dá»… hiá»ƒu:\n\nThÃ nh pháº§n 1: Tensor\n\nÄáº§u tiÃªn, cÃ¡c báº¡n pháº£i hiá»ƒu vá» tensor lÃ  gÃ¬? ThÃ¬ nÃ³ lÃ  má»™t Ä‘á»‘i tÆ°á»£ng toÃ¡n há»c nháº±m tá»•ng há»£p hÃ³a 1 hoáº·c nhiá»u chiá»u trong 1 object. Dáº¡ng Ä‘Æ¡n giáº£n cá»§a tensor nhÆ° lÃ  scalar (sá»‘ Ä‘Æ¡n giáº£n), vector (chuá»—i cÃ¡c sá»‘),â€¦\n\n  \n  \n  \n  \n    HÃ¬nh 4: Tensor lÃ  gÃ¬\n  \n  \n  \n  \n    Source: Link to Image\n  \n\nVÃ  má»¥c Ä‘Ã­ch cá»§a viá»‡c chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u sang dáº¡ng tensor lÃ  Ä‘á»ƒ giÃºp cho viá»‡c tÃ­nh toÃ¡n trÃªn GPU nhanh hÆ¡n vÃ  tÄƒng tá»‘c Ä‘á»™ training machine learning model. NgoÃ i ra, váº«n cÃ³ cÃ¡c thÃ´ng tin khÃ¡c hay vá» tensor trong R, báº¡n cÃ³ thá»ƒ kham kháº£o link nÃ y: Tensors.\n\nThÃ nh pháº§n 2: Embedding vÃ  positional encoding\n\nKhi dá»¯ liá»‡u Ä‘Æ°á»£c Ä‘Æ°a vÃ o, nÃ³ sáº½ tráº£i qua bÆ°á»›c embedding (cÃ¡ch Ä‘á»ƒ biá»ƒu diá»…n dá»¯ liá»‡u Ä‘a chiá»u trong khÃ´ng gian Ã­t chiá»u). Náº¿u dá»¯ liá»‡u cá»§a báº¡n dáº¡ng hÃ¬nh áº£nh hoáº·c dáº¡ng vÄƒn báº£n thÃ¬ bÆ°á»›c nÃ y ráº¥t cáº§n thiáº¿t (vÃ¬ cÃ¡c mÃ´ hÃ¬nh machine learning chá»‰ lÃ m viá»‡c Ä‘Æ°á»£c vá»›i dá»¯ liá»‡u dáº¡ng sá»‘).\nNgoÃ i ra, vÃ¬ mÃ´ hÃ¬nh Transformer khÃ´ng cÃ³ kháº£ nÄƒng xá»­ lÃ½ dá»¯ liá»‡u theo thá»© tá»± tuáº§n tá»± (khÃ¡c vá»›i RNN hoáº·c LSTM), nÃ³ sáº½ cáº§n má»™t chá»‰ bÃ¡o Ä‘á»ƒ chá»‰ ra thá»© tá»± cá»§a cÃ¡c bÆ°á»›c trong chuá»—i, gá»i lÃ  Postitional encoding. Báº¡n cÃ³ thá»ƒ kham kháº£o bÃ i viáº¿t cá»§a Mehreen Saeed. VÃ  code trong R sáº½ vÃ­ dá»± nhÆ° sau:\n\n\nCode\npositional_encoding &lt;- function(seq_len, d, n = 10000) {\n  P &lt;- matrix(0, nrow = seq_len, ncol = d)\n  \n  for (k in 1:seq_len) {\n    for (i in 0:(d / 2 - 1)) {\n      denominator &lt;- n^(2 * i / d)\n      P[k, 2 * i + 1] &lt;- sin(k / denominator)\n      P[k, 2 * i + 2] &lt;- cos(k / denominator)\n    }\n  }\n  \n  return(P)\n}\n\n\n\nThÃ nh pháº§n 3: Self-attention mechanism\n\nÄÃ¢y lÃ  má»™t cÆ¡ cháº¿ Ä‘áº·c biá»‡t cá»§a Transformer, cho phÃ©p mÃ´ hÃ¬nh chÃº Ã½ Ä‘áº¿n táº¥t cáº£ cÃ¡c bÆ°á»›c thá»i gian trÆ°á»›c Ä‘Ã³ trong chuá»—i táº¡i má»—i bÆ°á»›c. Äiá»u nÃ y giÃºp mÃ´ hÃ¬nh náº¯m báº¯t Ä‘Æ°á»£c cÃ¡c má»‘i quan há»‡ dÃ i háº¡n vÃ  sá»± liÃªn há»‡ giá»¯a cÃ¡c bÆ°á»›c thá»i gian vá»›i nhau (giÃºp trÃ¡nh gáº·p váº¥n Ä‘á» ghi nhá»› ngáº¯n háº¡n nhÆ° RNN). Báº¡n cÃ³ thá»ƒ xem Self-attention nhÆ° lÃ  cáº¥u trÃºc chung nháº¥t, cÃ²n khi xÃ¢y dá»±ng mÃ´ hÃ¬nh ngÆ°á»i ta cÃ³ thá»ƒ biáº¿n táº¥u tÃ¹y vÃ o nhu cáº§u.\nNhÆ° á»Ÿ Encoder thÃ¬ sá»­ dá»¥ng Multi-Head Attention cÃ³ thá»ƒ tÃ­nh toÃ¡n chÃº Ã½ nhiá»u láº§n song song (khÃ¡c vá»›i self -attention chá»‰ tÃ­nh toÃ¡n cho single sequence) . Má»—i â€œÄ‘áº§uâ€ cÃ³ thá»ƒ chÃº Ã½ Ä‘áº¿n nhá»¯ng khÃ­a cáº¡nh khÃ¡c nhau cá»§a cÃ¡c má»‘i quan há»‡ thá»i gian trong chuá»—i. VÃ­ dá»¥, má»™t Ä‘áº§u cÃ³ thá»ƒ chÃº Ã½ Ä‘áº¿n cÃ¡c máº«u ngáº¯n háº¡n (vÃ­ dá»¥: sá»± dao Ä‘á»™ng hÃ ng ngÃ y), trong khi má»™t Ä‘áº§u khÃ¡c cÃ³ thá»ƒ náº¯m báº¯t cÃ¡c xu hÆ°á»›ng dÃ i háº¡n (vÃ­ dá»¥: chu ká»³ mÃ¹a). Trong R thÃ¬ Ä‘Ã£ cÃ³ sáºµn hÃ m nn_multihead_attention() trong package torch.\nCÃ²n Ä‘á»‘i vá»›i Decoder thÃ¬ dÃ¹ng Masked Multi-Head Attention Ä‘á»ƒ Ä‘áº£m báº£o ráº±ng khi dá»± bÃ¡o giÃ¡ trá»‹ tiáº¿p theo trong chuá»—i thá»i gian, mÃ´ hÃ¬nh chá»‰ cÃ³ thá»ƒ chÃº Ã½ Ä‘áº¿n cÃ¡c bÆ°á»›c thá»i gian trÆ°á»›c Ä‘Ã³ mÃ  khÃ´ng nhÃ¬n vÃ o cÃ¡c bÆ°á»›c thá»i gian tÆ°Æ¡ng lai. So sÃ¡nh vá»›i Self-attention thÃ¬ báº¡n cáº§n thÃªm bÆ°á»›c Masked score thÃ´i. Trong R sáº½ Ä‘Æ°á»£c code nhÆ° sau:\n\n\n\n\n\n\nShow structure\nmask_self_attention &lt;- nn_module(\n  initialize = function(embed_dim, num_heads) {\n    self$embed_dim &lt;- embed_dim\n    self$num_heads &lt;- num_heads\n    self$head_dim &lt;- embed_dim / num_heads\n\n    if (embed_dim %% num_heads != 0) {\n      stop(\"embed_dim must be divisible by num_heads\")\n    }\n    \n    # Linear layers for Q, K, V \n    self$query &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    self$key &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    self$value &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    \n    # Final linear layer after concatenating heads\n    self$out &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    \n  },\n  \n  forward = function(x) {\n    batch_size &lt;- x$size(1)\n    seq_leng &lt;- x$size(2)\n    \n    # Linear projections for Q, K, V\n    Q &lt;- self$query(x)  # (batch_size, seq_leng, embed_dim)\n    K &lt;- self$key(x)\n    V &lt;- self$value(x)\n    \n    # Reshape to separate heads: (batch_size, num_heads, seq_leng, head_dim)\n    Q &lt;- Q$view(c(batch_size, seq_leng, self$num_heads, self$head_dim))$transpose(2, 3)\n    K &lt;- K$view(c(batch_size, seq_leng, self$num_heads, self$head_dim))$transpose(2, 3)\n    V &lt;- V$view(c(batch_size, seq_leng, self$num_heads, self$head_dim))$transpose(2, 3)\n    \n    # Compute Matmul and scale:\n    d_k &lt;- self$head_dim\n    attention_scores &lt;- torch_matmul(Q, torch_transpose(K, -1, -2)) / sqrt(d_k)\n    \n    # Apply mask if provided\n    mask &lt;- torch_tril(torch_ones(c(seq_leng, seq_leng)))\n    \n    if (!is.null(mask)) {\n      \n      masked_attention_scores &lt;- attention_scores$masked_fill(mask == 0, -Inf)\n      \n    } else {\n      print(\"Warning: No mask provided\")\n    }\n    \n    # Compute attention weights\n    weights &lt;- nnf_softmax(masked_attention_scores, dim = -1)\n    \n    # Apply weights to V\n    attn_output &lt;- torch_matmul(weights, V)  \n    \n    # Reshape again:\n    attn_output &lt;- attn_output$transpose(2, 3)$contiguous()$view(c(batch_size, seq_leng, self$embed_dim))\n    \n    # Final linear layer\n    output &lt;- self$out(attn_output)\n    return(output)\n  }\n)\n\n\n\n\nNgoÃ i ra, trong Decoder cÃ²n cÃ³ Cross-attention nhÆ°ng nÃ³ hÆ¡i phá»©c táº¡p nÃªn mÃ¬nh sáº½ giá»›i thiá»‡u sau.\n\nThÃ nh pháº§n 4: Sub-layer\n\nBáº¡n sáº½ Ä‘á»ƒ Ã½ tháº¥y cÃ¡c phÃ©p tÃ­nh toÃ¡n trong mÃ´ hÃ¬nh sáº½ luÃ´n kÃ¨m theo bá»™ pháº­n Add & Norm Ä‘á»ƒ lÆ°u giá»¯ residual vÃ  cá»™ng vÃ o output Ä‘Æ°á»£c táº¡o sau khi káº¿t thÃºc cÃ¡c phÃ©p tÃ­nh Ä‘Ã³. Viá»‡c nÃ y giÃºp giáº£m thiá»ƒu váº¥n Ä‘á» vanishing gradient Ä‘Ã£ Ä‘á» cáº­p á»Ÿ trang trÆ°á»›c vÃ  giÃºp cho mÃ´ hÃ¬nh há»c sÃ¢u hÆ¡n. Trong R báº¡n chá»‰ cáº§n thÃªm lá»›p nÃ y báº±ng hÃ m nn_layer_norm().\n\nThÃ nh pháº§n 5: Feed-Forward Neural Networks\n\nSau khi tÃ­nh toÃ¡n chÃº Ã½, Ä‘áº¡i diá»‡n cá»§a tá»«ng bÆ°á»›c thá»i gian sáº½ Ä‘Æ°á»£c Ä‘Æ°a qua má»™t máº¡ng nÆ¡-ron Feed-Forward (FFN), thÆ°á»ng bao gá»“m: (i) Má»™t phÃ©p biáº¿n Ä‘á»•i tuyáº¿n tÃ­nh (lá»›p káº¿t ná»‘i Ä‘áº§y Ä‘á»§), (ii) HÃ m kÃ­ch hoáº¡t ReLU vÃ  (iii) Má»™t phÃ©p biáº¿n Ä‘á»•i tuyáº¿n tÃ­nh ná»¯a. Trong R sáº½ code nhÆ° nÃ y:\n\n\nCode\nfeed_forward &lt;- nn_sequential(\n      nn_linear(d_model, d_ff),\n      nn_relu(),\n      nn_linear(d_ff, d_model)\n    )"
  },
  {
    "objectID": "transfer.html#cÃ¡c-thÃ nh-pháº§n-chÃ­nh",
    "href": "transfer.html#cÃ¡c-thÃ nh-pháº§n-chÃ­nh",
    "title": "MÃ´ hÃ¬nh Transformer",
    "section": "3 CÃ¡c thÃ nh pháº§n chÃ­nh:",
    "text": "3 CÃ¡c thÃ nh pháº§n chÃ­nh:\nSau khi hiá»ƒu rÃµ cÃ¡c thÃ nh pháº§n cáº§n thiáº¿t, ta sáº½ ngÃ³ qua workflow Ä‘áº§y Ä‘á»§ cá»§a mÃ´ hÃ¬nh Transformer.Náº¿u báº¡n chÆ°a hiá»ƒu thÃ¬ cÃ³ thá»ƒ kham kháº£o link nÃ y datacamp\n\n  \n  \n  \n  \n    HÃ¬nh 6: Workflow cá»§a mÃ´ hÃ¬nh Transformer\n  \n  \n  \n  \n    Source: Link to Image\n  \n\nMÃ¬nh sáº½ trÃ¬nh bÃ y theo cÃ¡ch cÃ¡ nhÃ¢n Ä‘á»ƒ giÃºp má»i ngÆ°á»i hiá»ƒu rÃµ hÆ¡n:\n\nBÆ°á»›c 1: Xá»­ lÃ­ input: sáº½ gá»“m bÆ°á»›c Embedding dá»¯ liá»‡u sau Ä‘Ã³ cá»™ng thÃªm Positional encoding. LÆ°u Ã½: input cho encoder vÃ  decoder lÃ  khÃ¡c nhau, encoder sáº½ nháº­n Ä‘áº§u vÃ o lÃ  cÃ¡c biáº¿n dá»± bÃ¡o (vÃ­ dá»¥: giÃ¡ trá»‹ lag cá»§a time series,â€¦) vÃ  decoder sáº½ nháº­n Ä‘áº§u vÃ o lÃ  biáº¿n target (lÃ  káº¿t quáº£ báº¡n mong muá»‘n mÃ´ hÃ¬nh dá»± bÃ¡o Ä‘Ãºng).\nBÆ°á»›c 2: Encoder output: Khi dá»¯ liá»‡u Ä‘i vÃ o encoder block thÃ¬ sáº½ tráº£i qua lá»›p multi-head attention* vÃ  feed forward vÃ  cÃ¡c lá»›p sub-layer normalization. LÆ°u Ã½: khi normalizing thÃ¬ pháº£i normalize (káº¿t quáº£ tá»« lá»›p trÆ°á»›c + input ban Ä‘áº§u), báº¡n cÃ³ thá»ƒ nhÃ¬n áº£nh dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ dá»… hiá»ƒu hÆ¡n.\n\n\n  \n  \n  \n  \n    HÃ¬nh 7: Normalization vÃ  residual connection sau lá»›p Multi-Head Attention\n  \n  \n  \n  \n    Source: Link to Image\n  \n\n\nBÆ°á»›c 3: Add encoder output to decoder: Sau khi Decoder thá»±c hiá»‡n tÃ­nh toÃ¡n cho dá»¯ liá»‡u thÃ´ng qua layer Mask multi-head attention vÃ  Normalization thÃ¬ sáº½ Ä‘áº¿n bÆ°á»›c Cross-attention (Máº·c dÃ¹ á»Ÿ hÃ¬nh trÃªn hoáº·c cÃ¡c tÃ i liá»‡u khÃ¡c mÃ  báº¡n tá»«ng Ä‘á»c sáº½ Ä‘á»ƒ lÃ  layer multi-head attention nhÆ°ng thá»±c cháº¥t layer cross-attention má»›i Ä‘Ãºng).\n\nVáº­y cross-attention cÃ³ gÃ¬ Ä‘áº·c biá»‡t? Ta sáº½ nhÃ¬n sÆ¡ qua cáº¥u trÃºc cá»§a nÃ³ thÃ¬ sáº½ nháº­n ra Ä‘iá»ƒm khÃ¡c biá»‡t so vá»›i self-attention thÃ´ng thÆ°á»ng lÃ  cross-attention sáº½ nháº­n dá»¯ liá»‡u tá»« 2 nguá»“n: (i) output cá»§a encoder gÃ¡n cho Q vÃ  (ii) input cá»§a decoder gÃ¡n cho V, K.\n\nCross attention:Self attention:\n\n\n\n  \n  \n  \n  \n    HÃ¬nh 8: Workflow cá»§a Cross-attention\n  \n  \n  \n  \n    Source: Link to Image\n  \n\n\n\n\n  \n  \n  \n  \n    HÃ¬nh 9: Workflow cá»§a Self-attention\n  \n  \n  \n  \n    Source: Link to Image\n  \n\n\n\n\nVá» code trong R sáº½ nhÆ° sau:\n\n\nShow structure\ncross_attention &lt;- nn_module(\n  initialize = function(embed_dim, num_heads) {\n    self$embed_dim &lt;- embed_dim\n    self$num_heads &lt;- num_heads\n    self$head_dim &lt;- embed_dim / num_heads\n    \n    if (self$head_dim %% 1 != 0) {\n      stop(\"embed_dim must be divisible by num_heads\")\n    }\n    \n    self$query &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    self$key &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    self$value &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    self$out &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n  },\n  \n  forward = function(decoder_input, encoder_output, mask = NULL) {\n    batch_size &lt;- decoder_input$size(1)\n    seq_leng_dec &lt;- decoder_input$size(2)\n    seq_leng_enc &lt;- encoder_output$size(2)\n    \n    Q &lt;- self$query(decoder_input)\n    K &lt;- self$key(encoder_output)\n    V &lt;- self$value(encoder_output)\n    \n    Q &lt;- Q$view(c(batch_size, seq_leng_dec, self$num_heads, self$head_dim))$transpose(2, 3)\n    K &lt;- K$view(c(batch_size, seq_leng_enc, self$num_heads, self$head_dim))$transpose(2, 3)\n    V &lt;- V$view(c(batch_size, seq_leng_enc, self$num_heads, self$head_dim))$transpose(2, 3)\n    \n    d_k &lt;- self$head_dim\n    attention_scores &lt;- torch_matmul(Q, torch_transpose(K, -1, -2)) / sqrt(d_k)\n    \n    weights &lt;- nnf_softmax(attention_scores, dim = -1)\n    \n    attn_output &lt;- torch_matmul(weights, V)\n    \n    attn_output &lt;- attn_output$transpose(2, 3)$contiguous()$view(c(batch_size, seq_leng_dec, self$embed_dim))\n    \n    output &lt;- self$out(attn_output)\n    return(output)\n  }\n)\n\n\nKáº¿t quáº£ sau Ä‘Ã³ sáº½ Ä‘Æ°á»£c Ä‘áº©y qua layer feed forward vÃ  normalization Ä‘á»ƒ tráº£ vá» output (giá»‘ng nhÆ° encoder).\n\nBÆ°á»›c 4: Output of decoder: Cuá»‘i cÃ¹ng, output cá»§a decoder sáº½ qua 2 layer linear vÃ  softmax Ä‘á»ƒ tÃ¬m ra output cÃ³ xÃ¡c suáº¥t cao nháº¥t (nghÄ©a lÃ  output Ä‘Ã³ sáº½ cÃ³ Ã½ nghÄ©a nháº¥t trong sequence Ä‘á»ƒ dá»± bÃ¡o cho cÃ¡c step sau).\n\n\n  \n  \n  \n  \n    HÃ¬nh 10: Output cá»§a mÃ´ hÃ¬nh\n  \n  \n  \n  \n    Source: Link to Image\n  \n\nNhÆ° váº­y, chÃºng ta Ä‘Ã£ lÆ°á»›t sÆ¡ qua cÃ¡ch hoáº¡t Ä‘á»™ng vÃ  cÃ¡c lÆ°u Ã½ cá»§a mÃ´ hÃ¬nh Transformer. Tiáº¿p theo, mÃ¬nh sáº½ thá»­ xÃ¢y dá»±ng trong R vÃ  dÃ¹ng nÃ³ Ä‘á»ƒ xá»­ lÃ­ task dá»± bÃ¡o chuá»—i thá»i gian.\n\n\n\n    \n    \n    Go to Next Page\n    \n\n\n    \n        \n            Go to Next Page\n            â”"
  },
  {
    "objectID": "practice.html",
    "href": "practice.html",
    "title": "Time series forecasting",
    "section": "",
    "text": "Khi báº¡n cáº§n xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh Deep learning phá»©c táº¡p hÆ¡n thÃ¬ package torch trong R giá»‘ng vá»›i PyTorch trong Python thÆ°á»ng dÃ¹ng Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh machine learning vÃ  nÃ³ sáº½ lÃ  cÃ´ng cá»¥ máº¡nh máº½ cÃ³ thá»ƒ há»— trá»£ báº¡n (Náº¿u báº¡n chÆ°a biáº¿t thÃ¬ háº§u háº¿t packages Ä‘á»ƒ train machine learning model trong R Ä‘á»u thá»±c hiá»‡n thÃ´ng qua Python vÃ  Ä‘Æ°á»£c báº¯t cáº§u ná»‘i báº±ng package reticulate).\nÄá»ƒ há»c háº¿t vá» torch thÃ¬ báº¡n cÃ³ thá»ƒ tham kháº£o cÃ¡c link sau:\n\nSÃ¡ch Deep Learning and Scientific Computing with R torch cá»§a Sigrid Keydana.\nMá»™t loáº¡t bÃ i post tá»« posit blog.\n\nCÃ²n á»Ÿ bÃ i viáº¿t nÃ y, mÃ¬nh chá»‰ giá»›i thiá»‡u cÆ¡ báº£n cÃ¡ch sá»­ dá»¥ng torch trong R Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh.\n\n\n\n\n\n\nTip\n\n\n\nÄá»ƒ táº£i torch vÃ o mÃ¡y local thÃ¬ báº¡n sá»­ dá»¥ng cÃº phÃ¡p install.package(\"torch\")\n\n\n\n\ná» Ä‘Ã¢y, mÃ¬nh sáº½ giá»›i thiá»‡u cÆ¡ báº£n Ä‘á»ƒ má»i ngÆ°á»i cÃ³ kiáº¿n thá»©c cÆ¡ báº£n nháº¥t vá» torch\nÄáº§u tiÃªn, Ä‘á»ƒ dÃ¹ng package torch trong R thÃ¬ ta cáº§n chuyá»ƒn Ä‘á»•i object sang class tensor thÃ¬ dÃ¹ng hÃ m torch_tensor(). ÄÃ¢y lÃ  vÃ­ dá»¥ vá»:\n\n\nCode\nlibrary(torch)\nm&lt;-torch_tensor(array(1:24, dim = c(4, 3, 2)))\nclass(m)\n\n\n[1] \"torch_tensor\" \"R7\"          \n\n\nNgoÃ i ra, trong object tensor cÃ²n chá»©a thÃªm thÃ´ng tin khÃ¡c nhÆ° lÃ : \\(dtype* sáº½ return data type (vÃ­ dá»¥ nhÆ° object dÆ°á»›i Ä‘Ã¢y lÃ  dáº¡ng *long integer*), *\\)device return nÆ¡i tensor object Ä‘Æ°á»£c lÆ°u trá»¯, $shape return dimensions cá»§a object.\n\n\nCode\nm$dtype\n\n\ntorch_Long\n\n\nCode\nm$device\n\n\ntorch_device(type='cpu') \n\n\nCode\nm$shape\n\n\n[1] 4 3 2\n\n\nVÃ­ dá»¥ ta cÃ³ thá»ƒ simulate cÃ´ng thá»©c Ä‘Æ¡n giáº£n nhÆ° sau báº±ng package torch: \\(f(x) = xw + b\\)\n\n\nCode\nx &lt;- torch_randn(100, 3)\nw &lt;- torch_randn(3, 1, requires_grad = TRUE)\nb &lt;- torch_zeros(1, 1, requires_grad = TRUE)\ny &lt;- x$matmul(w) + b\nhead(y)\n\n\ntorch_tensor\n 0.8659\n 1.1373\n-1.1229\n-0.8550\n 1.3113\n 0.4500\n[ CPUFloatType{6,1} ][ grad_fn = &lt;SliceBackward0&gt; ]\n\n\n\n\n\nTiáº¿p theo, mÃ¬nh sáº½ xÃ¢y dá»±ng mÃ´ hÃ¬nh Transformer Ä‘á»ƒ dá»± bÃ¡o giÃ¡ cá»• phiáº¿u cá»§a Google tá»« nguá»“n Yahoo Finance.\n\n\nCode\n#### Call packages-------------------------------------------------------------\npacman::p_load(quantmod,\n               torch,\n               dplyr,\n               dygraphs)\n#### Input---------------------------------------------------------------------\ngetSymbols(\"GOOG\", src = \"yahoo\", from = \"2020-01-01\", to = \"2022-01-01\")\n\n\n[1] \"GOOG\"\n\n\nCode\nprice_data &lt;- GOOG$GOOG.Close\nprice_data_xts &lt;- xts(price_data, \n                     order.by = index(price_data))\n\ncolors&lt;-RColorBrewer::brewer.pal(9, \"Blues\")[c(4, 6, 8)]\n\ndygraph(price_data_xts, main = \"Google Stock Price (2020 - 2022)\", ylab = \"Price ($)\") |&gt; \n  dyRangeSelector(height = 20) |&gt; \n  dyOptions(\n    fillGraph = TRUE,  \n    colors = colors,   \n    strokeWidth = 2,   \n    gridLineColor = \"gray\",  \n    gridLineWidth = 0.5,     \n    drawPoints = TRUE,   \n    pointSize = 4,       \n    pointShape = \"diamond\" \n  ) |&gt; \n  dyLegend(show = \"follow\") \n\n\n\n\n\n\nNhÆ° biá»ƒu Ä‘á»“, ta tháº¥y giÃ¡ cá»• phiáº¿u tÄƒng cao chÃ³ng máº·t vÃ  má»©c biáº¿n Ä‘á»™ng khÃ¡ má»©c táº¡p (lÃºc lÃªn lÃºc xuá»‘ng). Task nÃ y khÃ¡ khÃ³ nÃªn ta sáº½ tÃ¬m hiá»ƒu xem performance cá»§a mÃ´ hÃ¬nh Transformer sáº½ nhÆ° tháº¿ nÃ o.\nMÃ´ hÃ¬nh Ä‘áº§y Ä‘á»§ sáº½ Ä‘Æ°á»£c code nhÆ° sau:\n\n\nShow structure\n#### Transform input----------------------------------------------------------------\ncreate_supervised_data &lt;- function(series, n) {\n  series &lt;- as.vector(series)\n  data &lt;- data.frame(series)\n  \n  for (i in 1:n) {\n    lagged_column &lt;- lag(series, i)\n    data &lt;- cbind(data, lagged_column)\n  }\n  \n  colnames(data) &lt;- c('t',paste0('t', 1:n))\n\n  data &lt;- na.omit(data)\n  \n  return(data)\n}\n\nseq_leng &lt;- 50\ndim_model &lt;- 32\n\nsupervised_data &lt;- create_supervised_data(price_data, n = seq_leng)\n\nsupervised_data &lt;- scale(supervised_data)\n\n\nx_data &lt;- torch_tensor(as.matrix(supervised_data[, 2:(seq_leng+1)]), dtype = torch_float())  # Features (lags)\ny_data &lt;- torch_tensor(as.matrix(supervised_data[, 1]), dtype = torch_float())    # Target\n\n# Reshape x_data to match (batch_size, seq_leng, feature_size)\nx_data &lt;- x_data$view(c(nrow(x_data), seq_leng, 1))  # (batch_size, seq_leng, feature_size)\ny_data &lt;- y_data$view(c(nrow(y_data), 1, 1)) \n\n# Split the data into training and testing sets (80% for training, 20% for testing)\ntrain_size &lt;- round(0.8 * nrow(supervised_data))\n\nx_train &lt;- x_data[1:train_size, , drop = FALSE]  \ny_train &lt;- y_data[1:train_size]\n\nx_test &lt;- x_data[(train_size + 1):nrow(supervised_data), , drop = FALSE]\ny_test &lt;- y_data[(train_size + 1):nrow(supervised_data)]\n\n#### Build components of model----------------------------------------------------------------\n### Positional encoding:\npositional_encoding &lt;- function(seq_leng, d_model, n = 10000) {\n  if (missing(seq_leng) || missing(d_model)) {\n    stop(\"'seq_leng' and 'd_model' must be provided.\")\n  }\n  \n  P &lt;- matrix(0, nrow = seq_leng, ncol = d_model)  \n  \n  for (k in 1:seq_leng) {\n    for (i in 0:(d_model / 2 - 1)) {\n      denominator &lt;- n^(2 * i / d_model)\n      P[k, 2 * i + 1] &lt;- sin(k / denominator)\n      P[k, 2 * i + 2] &lt;- cos(k / denominator)\n    }\n  }\n  \n  return(P)\n}\n\nen_pe &lt;- positional_encoding(x_data$size(2),dim_model, n = 10000)\nde_pe &lt;- positional_encoding(y_data$size(2),dim_model, n = 10000)\n\n### Encoder block:\nencoder_layer &lt;- nn_module(\n  \"TransformerEncoderLayer\",\n  \n  initialize = function(d_model, num_heads, d_ff) {\n    \n    # Multi-Head Attention\n    self$multihead_attention &lt;- nn_multihead_attention(embed_dim = d_model, num_heads = num_heads)\n    \n    # Feedforward Network (Fully Connected)\n    self$feed_forward &lt;- nn_sequential(\n      nn_linear(d_model, d_ff),\n      nn_relu(),\n      nn_linear(d_ff, d_model)\n    )\n    \n    self$layer_norm &lt;- nn_layer_norm(d_model)\n  \n  },\n  \n  forward = function(x) {\n\n    attn_output &lt;- self$multihead_attention(x, x, x) \n    x &lt;- x + attn_output[[1]]\n    x &lt;- self$layer_norm(x) \n    \n    # Feedforward network with residual connection\n    ff_output &lt;- self$feed_forward(x)\n    x &lt;- x + ff_output\n    x &lt;- self$layer_norm(x)\n    \n    return(x)\n  }\n)\n\n### Mask function:\nmask_self_attention &lt;- nn_module(\n  initialize = function(embed_dim, num_heads) {\n    self$embed_dim &lt;- embed_dim\n    self$num_heads &lt;- num_heads\n    self$head_dim &lt;- embed_dim / num_heads\n    \n    # Ensure that self$head_dim is a scalar\n    if (self$head_dim %% 1 != 0) {\n      stop(\"embed_dim must be divisible by num_heads\")\n    }\n    \n    if (embed_dim %% num_heads != 0) {\n      stop(\"embed_dim must be divisible by num_heads\")\n    }\n    \n    # Linear layers for Q, K, V \n    self$query &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    self$key &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    self$value &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    \n    # Final linear layer after concatenating heads\n    self$out &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    \n  },\n  \n  forward = function(x) {\n    batch_size &lt;- x$size(1)\n    seq_leng &lt;- x$size(2)\n    \n    # Linear projections for Q, K, V\n    Q &lt;- self$query(x)  # (batch_size, seq_leng, embed_dim)\n    K &lt;- self$key(x)\n    V &lt;- self$value(x)\n    \n    # Reshape to separate heads: (batch_size, num_heads, seq_leng, head_dim)\n    Q &lt;- Q$view(c(batch_size, seq_leng, self$num_heads, self$head_dim))$transpose(2, 3)\n    K &lt;- K$view(c(batch_size, seq_leng, self$num_heads, self$head_dim))$transpose(2, 3)\n    V &lt;- V$view(c(batch_size, seq_leng, self$num_heads, self$head_dim))$transpose(2, 3)\n    \n    # Compute attention scores\n    d_k &lt;- self$head_dim\n    attention_scores &lt;- torch_matmul(Q, torch_transpose(K, -1, -2)) / sqrt(d_k)\n    \n    # Apply mask if provided\n    mask &lt;- torch_tril(torch_ones(c(seq_leng, seq_leng)))\n    \n    if (!is.null(mask)) {\n      \n      masked_attention_scores &lt;- attention_scores$masked_fill(mask == 0, -Inf)\n      \n    } else {\n      print(\"Warning: No mask provided\")\n    }\n    \n    # Compute attention weights\n    weights &lt;- nnf_softmax(masked_attention_scores, dim = -1)\n    \n    # Apply weights to V\n    attn_output &lt;- torch_matmul(weights, V)  # (batch_size, num_heads, seq_leng, head_dim)\n    \n    \n    attn_output &lt;- attn_output$transpose(2, 3)$contiguous()$view(c(batch_size, seq_leng, self$embed_dim))\n    \n    \n    output &lt;- self$out(attn_output)\n    return(output)\n  }\n)\n\n### Cross attention:\ncross_attention &lt;- nn_module(\n  initialize = function(embed_dim, num_heads) {\n    self$embed_dim &lt;- embed_dim\n    self$num_heads &lt;- num_heads\n    self$head_dim &lt;- embed_dim / num_heads\n    \n    if (self$head_dim %% 1 != 0) {\n      stop(\"embed_dim must be divisible by num_heads\")\n    }\n    \n    self$query &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    self$key &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    self$value &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    self$out &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n  },\n  \n  forward = function(decoder_input, encoder_output, mask = NULL) {\n    batch_size &lt;- decoder_input$size(1)\n    seq_leng_dec &lt;- decoder_input$size(2)\n    seq_leng_enc &lt;- encoder_output$size(2)\n    \n    Q &lt;- self$query(decoder_input)\n    K &lt;- self$key(encoder_output)\n    V &lt;- self$value(encoder_output)\n    \n    Q &lt;- Q$view(c(batch_size, seq_leng_dec, self$num_heads, self$head_dim))$transpose(2, 3)\n    K &lt;- K$view(c(batch_size, seq_leng_enc, self$num_heads, self$head_dim))$transpose(2, 3)\n    V &lt;- V$view(c(batch_size, seq_leng_enc, self$num_heads, self$head_dim))$transpose(2, 3)\n    \n    d_k &lt;- self$head_dim\n    attention_scores &lt;- torch_matmul(Q, torch_transpose(K, -1, -2)) / sqrt(d_k)\n    \n    weights &lt;- nnf_softmax(attention_scores, dim = -1)\n    \n    attn_output &lt;- torch_matmul(weights, V)\n    \n    attn_output &lt;- attn_output$transpose(2, 3)$contiguous()$view(c(batch_size, seq_leng_dec, self$embed_dim))\n    \n    output &lt;- self$out(attn_output)\n    return(output)\n  }\n)\n\n### Decoder Layer\ndecoder_layer &lt;- nn_module(\n  \"TransformerDecoderLayer\",\n  \n  initialize = function(d_model, num_heads, d_ff) {\n    self$mask_self_attention &lt;- mask_self_attention(embed_dim = d_model, num_heads = num_heads)\n    self$cross_attention &lt;- cross_attention(embed_dim = d_model, num_heads = num_heads)\n    self$feed_forward &lt;- nn_sequential(\n      nn_linear(d_model, d_ff),\n      nn_relu(),\n      nn_linear(d_ff, d_model)\n    )\n    \n    self$layer_norm &lt;- nn_layer_norm(d_model)\n  },\n  \n  forward = function(x, encoder_output) {\n    # Masked Self-Attention\n    mask_output &lt;- self$mask_self_attention(x)\n    x &lt;- x + mask_output\n    x &lt;- self$layer_norm(x)\n    \n    # Encoder-Decoder Multi-Head Attention\n    cross_output &lt;- self$cross_attention(x, encoder_output)\n    x &lt;- x + cross_output\n    x &lt;- self$layer_norm(x)\n    \n    # Feedforward Network\n    ff_output &lt;- self$feed_forward(x)\n    x &lt;- x + ff_output\n    x &lt;- self$layer_norm(x)\n    \n    return(x)\n  }\n)\n\n### Final transformer model: \ntransformer &lt;- nn_module(\n  \"Transformer\",\n  \n  initialize = function(d_model, seq_leng, num_heads, d_ff, num_encoder_layers, num_decoder_layers) {\n    self$d_model &lt;- d_model\n    self$num_heads &lt;- num_heads\n    self$d_ff &lt;- d_ff\n    self$num_encoder_layers &lt;- num_encoder_layers\n    self$num_decoder_layers &lt;- num_decoder_layers\n    self$seq_leng &lt;- seq_leng\n    self$en_pe &lt;- en_pe\n    self$de_pe &lt;- de_pe\n    \n    # Encoder layers\n    self$encoder_layers &lt;- nn_module_list(\n      lapply(1:num_encoder_layers, function(i) {\n        encoder_layer(d_model, num_heads, d_ff)\n      })\n    )\n    \n    # Decoder layers\n    self$decoder_layers &lt;- nn_module_list(\n      lapply(1:num_decoder_layers, function(i) {\n        decoder_layer(d_model, num_heads, d_ff)\n      })\n    )\n    \n    # Final output layer\n    self$output_layer &lt;- nn_linear(d_model, 1)  # Output layer to predict a single value\n    \n  },\n  \n  forward = function(src, trg) {\n    \n    src &lt;- src + self$en_pe  \n    trg &lt;- trg + self$de_pe\n    \n    # Encoder forward pass\n    encoder_output &lt;- src\n    for (i in 1:self$num_encoder_layers) {\n      encoder_output &lt;- self$encoder_layers[[i]](encoder_output)\n    }\n    \n    # Decoder forward pass\n    decoder_output &lt;- trg\n    for (i in 1:self$num_decoder_layers) {\n      decoder_output &lt;- self$decoder_layers[[i]](decoder_output, encoder_output)\n    }\n  \n    # Apply final output layer\n    output &lt;- self$output_layer(decoder_output)\n    \n    return(output)\n  }\n)\n\n#### Training----------------------------------------------------------------\nmodel &lt;- transformer(\n  d_model = dim_model,         # Embedding dimension\n  seq_leng = seq_leng,        # Sequence length\n  num_heads = 8,        # Number of heads\n  d_ff = seq_leng,           # Dimension of the feedforward layer\n  num_encoder_layers = 6, \n  num_decoder_layers = 6\n)\n\n\n#### Training----------------------------------------------------------------\nepochs &lt;- 200\nloss_fn &lt;- nn_mse_loss()\noptimizer &lt;- optim_adam(model$parameters, lr = 1e-3)\n\nfor (epoch in 1:epochs) {\n  model$train()\n  optimizer$zero_grad()\n  \n  # Forward pass\n  y_train_pred &lt;- model(x_train, y_train) \n  \n  # Compute the loss\n  loss &lt;- loss_fn(y_train_pred, y_train)\n  \n  # Backpropagation and optimization\n  loss$backward()\n  optimizer$step()\n  \n  if (epoch %% 10 == 0) {\n    cat(\"Epoch: \", epoch, \" Loss: \", loss$item(), \"\\n\")\n  }\n}\n\n#### Predictions----------------------------------------------------------------\nmodel$eval()\n\n# Make predictions on the test data\ny_test_pred &lt;- model(x_test, y_test)  # Use the test data for both input and output during prediction\n\n# Convert tensors to numeric values for comparison\n\ny_test_pred&lt;- as.numeric(as.array(y_test_pred$cpu()))\n\n#### Evaluating----------------------------------------------------------------\nlibrary(highcharter)\ny_train_pred &lt;- as.numeric(as.array(y_train_pred$cpu()))\ny_train &lt;- as.numeric(as.array(y_train$cpu()))\ny_test &lt;- as.numeric(as.array(y_test$cpu()))\n\ncomparison &lt;- data.frame(\n  time = 1:nrow(supervised_data),\n  actual = c(y_train,y_test),\n  forecast = c(y_train_pred,y_test_pred)\n)\n\n# Compare only errors:\nerror&lt;-highchart() |&gt;\n  hc_title(text = \"Evaluating error of model\") |&gt;\n  hc_xAxis(\n    categories = time,\n    title = list(text = \"Time\")\n  ) |&gt;\n  hc_yAxis(\n    title = list(text = \"Value\"),\n    plotLines = list(list(\n      value = 0,\n      width = 1,\n      color = \"gray\"\n    ))\n  ) |&gt; \n  hc_add_series(\n    name = \"Error\",\n    data = (y_test_pred - y_test)/y_test,\n    type = \"line\",\n    color = \"red\"  # Blue color for actual data\n  ) |&gt;\n  hc_tooltip(\n    shared = TRUE,\n    crosshairs = TRUE\n  ) |&gt;\n  hc_legend(\n    enabled = TRUE\n  )\n\n\n# Compare all:\nall&lt;-highchart() |&gt;\n  hc_title(text = \"Model Predictions vs Actual Values\") |&gt;\n  hc_xAxis(\n    categories = time,\n    title = list(text = \"Time\")\n  ) |&gt;\n  hc_yAxis(\n    title = list(text = \"Value\"),\n    plotLines = list(list(\n      value = 0,\n      width = 1,\n      color = \"gray\"\n    ))\n  ) |&gt; \n  hc_add_series(\n    name = \"Actual Data\",\n    data = comparison$actual,\n    type = \"line\",\n    color = \"#1f77b4\"  # Blue color for actual data\n  ) |&gt;\n  hc_add_series(\n    name = \"Forecast\",\n    data = comparison$forecast,\n    type = \"line\",\n    color = \"#ff7f0e\"  # Orange color for forecast data\n  ) |&gt; \n  hc_tooltip(\n    shared = TRUE,\n    crosshairs = TRUE\n  ) |&gt;\n  hc_legend(\n    enabled = TRUE\n  )\n\n\n\n\n\nÄáº§u tiÃªn ta sáº½ Ä‘Ã¡nh giÃ¡ vá» sai sá»‘ cá»§a mÃ´ hÃ¬nh khi dÃ¹ng testing data. Káº¿t quáº£ khÃ¡ á»•n khi sai sá»‘ khoáº£ng (0.04,0.12).\n\n  \n\nVÃ  cÃ²n nhÃ¬n tá»•ng quan háº¿t thÃ¬ ta tháº¥y mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n khÃ¡ sÃ¡t vá»›i training data nhÆ°ng vá»›i testing data thÃ¬ váº«n chÃªnh lá»‡ch tháº¥p hÆ¡n thá»±c táº¿ (dáº¥u hiá»‡u cho tháº¥y mÃ´ hÃ¬nh Ä‘ang bá»‹ overfitting)."
  },
  {
    "objectID": "practice.html#thá»±c-hÃ nh-trong-r",
    "href": "practice.html#thá»±c-hÃ nh-trong-r",
    "title": "Time series forecasting",
    "section": "",
    "text": "Khi báº¡n cáº§n xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh Deep learning phá»©c táº¡p hÆ¡n thÃ¬ package torch trong R giá»‘ng vá»›i PyTorch trong Python thÆ°á»ng dÃ¹ng Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh machine learning vÃ  nÃ³ sáº½ lÃ  cÃ´ng cá»¥ máº¡nh máº½ cÃ³ thá»ƒ há»— trá»£ báº¡n (Náº¿u báº¡n chÆ°a biáº¿t thÃ¬ háº§u háº¿t packages Ä‘á»ƒ train machine learning model trong R Ä‘á»u thá»±c hiá»‡n thÃ´ng qua Python vÃ  Ä‘Æ°á»£c báº¯t cáº§u ná»‘i báº±ng package reticulate).\nÄá»ƒ há»c háº¿t vá» torch thÃ¬ báº¡n cÃ³ thá»ƒ tham kháº£o cÃ¡c link sau:\n\nSÃ¡ch Deep Learning and Scientific Computing with R torch cá»§a Sigrid Keydana.\nMá»™t loáº¡t bÃ i post tá»« posit blog.\n\nCÃ²n á»Ÿ bÃ i viáº¿t nÃ y, mÃ¬nh chá»‰ giá»›i thiá»‡u cÆ¡ báº£n cÃ¡ch sá»­ dá»¥ng torch trong R Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh.\n\n\n\n\n\n\nTip\n\n\n\nÄá»ƒ táº£i torch vÃ o mÃ¡y local thÃ¬ báº¡n sá»­ dá»¥ng cÃº phÃ¡p install.package(\"torch\")\n\n\n\n\ná» Ä‘Ã¢y, mÃ¬nh sáº½ giá»›i thiá»‡u cÆ¡ báº£n Ä‘á»ƒ má»i ngÆ°á»i cÃ³ kiáº¿n thá»©c cÆ¡ báº£n nháº¥t vá» torch\nÄáº§u tiÃªn, Ä‘á»ƒ dÃ¹ng package torch trong R thÃ¬ ta cáº§n chuyá»ƒn Ä‘á»•i object sang class tensor thÃ¬ dÃ¹ng hÃ m torch_tensor(). ÄÃ¢y lÃ  vÃ­ dá»¥ vá»:\n\n\nCode\nlibrary(torch)\nm&lt;-torch_tensor(array(1:24, dim = c(4, 3, 2)))\nclass(m)\n\n\n[1] \"torch_tensor\" \"R7\"          \n\n\nNgoÃ i ra, trong object tensor cÃ²n chá»©a thÃªm thÃ´ng tin khÃ¡c nhÆ° lÃ : \\(dtype* sáº½ return data type (vÃ­ dá»¥ nhÆ° object dÆ°á»›i Ä‘Ã¢y lÃ  dáº¡ng *long integer*), *\\)device return nÆ¡i tensor object Ä‘Æ°á»£c lÆ°u trá»¯, $shape return dimensions cá»§a object.\n\n\nCode\nm$dtype\n\n\ntorch_Long\n\n\nCode\nm$device\n\n\ntorch_device(type='cpu') \n\n\nCode\nm$shape\n\n\n[1] 4 3 2\n\n\nVÃ­ dá»¥ ta cÃ³ thá»ƒ simulate cÃ´ng thá»©c Ä‘Æ¡n giáº£n nhÆ° sau báº±ng package torch: \\(f(x) = xw + b\\)\n\n\nCode\nx &lt;- torch_randn(100, 3)\nw &lt;- torch_randn(3, 1, requires_grad = TRUE)\nb &lt;- torch_zeros(1, 1, requires_grad = TRUE)\ny &lt;- x$matmul(w) + b\nhead(y)\n\n\ntorch_tensor\n 0.8659\n 1.1373\n-1.1229\n-0.8550\n 1.3113\n 0.4500\n[ CPUFloatType{6,1} ][ grad_fn = &lt;SliceBackward0&gt; ]\n\n\n\n\n\nTiáº¿p theo, mÃ¬nh sáº½ xÃ¢y dá»±ng mÃ´ hÃ¬nh Transformer Ä‘á»ƒ dá»± bÃ¡o giÃ¡ cá»• phiáº¿u cá»§a Google tá»« nguá»“n Yahoo Finance.\n\n\nCode\n#### Call packages-------------------------------------------------------------\npacman::p_load(quantmod,\n               torch,\n               dplyr,\n               dygraphs)\n#### Input---------------------------------------------------------------------\ngetSymbols(\"GOOG\", src = \"yahoo\", from = \"2020-01-01\", to = \"2022-01-01\")\n\n\n[1] \"GOOG\"\n\n\nCode\nprice_data &lt;- GOOG$GOOG.Close\nprice_data_xts &lt;- xts(price_data, \n                     order.by = index(price_data))\n\ncolors&lt;-RColorBrewer::brewer.pal(9, \"Blues\")[c(4, 6, 8)]\n\ndygraph(price_data_xts, main = \"Google Stock Price (2020 - 2022)\", ylab = \"Price ($)\") |&gt; \n  dyRangeSelector(height = 20) |&gt; \n  dyOptions(\n    fillGraph = TRUE,  \n    colors = colors,   \n    strokeWidth = 2,   \n    gridLineColor = \"gray\",  \n    gridLineWidth = 0.5,     \n    drawPoints = TRUE,   \n    pointSize = 4,       \n    pointShape = \"diamond\" \n  ) |&gt; \n  dyLegend(show = \"follow\") \n\n\n\n\n\n\nNhÆ° biá»ƒu Ä‘á»“, ta tháº¥y giÃ¡ cá»• phiáº¿u tÄƒng cao chÃ³ng máº·t vÃ  má»©c biáº¿n Ä‘á»™ng khÃ¡ má»©c táº¡p (lÃºc lÃªn lÃºc xuá»‘ng). Task nÃ y khÃ¡ khÃ³ nÃªn ta sáº½ tÃ¬m hiá»ƒu xem performance cá»§a mÃ´ hÃ¬nh Transformer sáº½ nhÆ° tháº¿ nÃ o.\nMÃ´ hÃ¬nh Ä‘áº§y Ä‘á»§ sáº½ Ä‘Æ°á»£c code nhÆ° sau:\n\n\nShow structure\n#### Transform input----------------------------------------------------------------\ncreate_supervised_data &lt;- function(series, n) {\n  series &lt;- as.vector(series)\n  data &lt;- data.frame(series)\n  \n  for (i in 1:n) {\n    lagged_column &lt;- lag(series, i)\n    data &lt;- cbind(data, lagged_column)\n  }\n  \n  colnames(data) &lt;- c('t',paste0('t', 1:n))\n\n  data &lt;- na.omit(data)\n  \n  return(data)\n}\n\nseq_leng &lt;- 50\ndim_model &lt;- 32\n\nsupervised_data &lt;- create_supervised_data(price_data, n = seq_leng)\n\nsupervised_data &lt;- scale(supervised_data)\n\n\nx_data &lt;- torch_tensor(as.matrix(supervised_data[, 2:(seq_leng+1)]), dtype = torch_float())  # Features (lags)\ny_data &lt;- torch_tensor(as.matrix(supervised_data[, 1]), dtype = torch_float())    # Target\n\n# Reshape x_data to match (batch_size, seq_leng, feature_size)\nx_data &lt;- x_data$view(c(nrow(x_data), seq_leng, 1))  # (batch_size, seq_leng, feature_size)\ny_data &lt;- y_data$view(c(nrow(y_data), 1, 1)) \n\n# Split the data into training and testing sets (80% for training, 20% for testing)\ntrain_size &lt;- round(0.8 * nrow(supervised_data))\n\nx_train &lt;- x_data[1:train_size, , drop = FALSE]  \ny_train &lt;- y_data[1:train_size]\n\nx_test &lt;- x_data[(train_size + 1):nrow(supervised_data), , drop = FALSE]\ny_test &lt;- y_data[(train_size + 1):nrow(supervised_data)]\n\n#### Build components of model----------------------------------------------------------------\n### Positional encoding:\npositional_encoding &lt;- function(seq_leng, d_model, n = 10000) {\n  if (missing(seq_leng) || missing(d_model)) {\n    stop(\"'seq_leng' and 'd_model' must be provided.\")\n  }\n  \n  P &lt;- matrix(0, nrow = seq_leng, ncol = d_model)  \n  \n  for (k in 1:seq_leng) {\n    for (i in 0:(d_model / 2 - 1)) {\n      denominator &lt;- n^(2 * i / d_model)\n      P[k, 2 * i + 1] &lt;- sin(k / denominator)\n      P[k, 2 * i + 2] &lt;- cos(k / denominator)\n    }\n  }\n  \n  return(P)\n}\n\nen_pe &lt;- positional_encoding(x_data$size(2),dim_model, n = 10000)\nde_pe &lt;- positional_encoding(y_data$size(2),dim_model, n = 10000)\n\n### Encoder block:\nencoder_layer &lt;- nn_module(\n  \"TransformerEncoderLayer\",\n  \n  initialize = function(d_model, num_heads, d_ff) {\n    \n    # Multi-Head Attention\n    self$multihead_attention &lt;- nn_multihead_attention(embed_dim = d_model, num_heads = num_heads)\n    \n    # Feedforward Network (Fully Connected)\n    self$feed_forward &lt;- nn_sequential(\n      nn_linear(d_model, d_ff),\n      nn_relu(),\n      nn_linear(d_ff, d_model)\n    )\n    \n    self$layer_norm &lt;- nn_layer_norm(d_model)\n  \n  },\n  \n  forward = function(x) {\n\n    attn_output &lt;- self$multihead_attention(x, x, x) \n    x &lt;- x + attn_output[[1]]\n    x &lt;- self$layer_norm(x) \n    \n    # Feedforward network with residual connection\n    ff_output &lt;- self$feed_forward(x)\n    x &lt;- x + ff_output\n    x &lt;- self$layer_norm(x)\n    \n    return(x)\n  }\n)\n\n### Mask function:\nmask_self_attention &lt;- nn_module(\n  initialize = function(embed_dim, num_heads) {\n    self$embed_dim &lt;- embed_dim\n    self$num_heads &lt;- num_heads\n    self$head_dim &lt;- embed_dim / num_heads\n    \n    # Ensure that self$head_dim is a scalar\n    if (self$head_dim %% 1 != 0) {\n      stop(\"embed_dim must be divisible by num_heads\")\n    }\n    \n    if (embed_dim %% num_heads != 0) {\n      stop(\"embed_dim must be divisible by num_heads\")\n    }\n    \n    # Linear layers for Q, K, V \n    self$query &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    self$key &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    self$value &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    \n    # Final linear layer after concatenating heads\n    self$out &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    \n  },\n  \n  forward = function(x) {\n    batch_size &lt;- x$size(1)\n    seq_leng &lt;- x$size(2)\n    \n    # Linear projections for Q, K, V\n    Q &lt;- self$query(x)  # (batch_size, seq_leng, embed_dim)\n    K &lt;- self$key(x)\n    V &lt;- self$value(x)\n    \n    # Reshape to separate heads: (batch_size, num_heads, seq_leng, head_dim)\n    Q &lt;- Q$view(c(batch_size, seq_leng, self$num_heads, self$head_dim))$transpose(2, 3)\n    K &lt;- K$view(c(batch_size, seq_leng, self$num_heads, self$head_dim))$transpose(2, 3)\n    V &lt;- V$view(c(batch_size, seq_leng, self$num_heads, self$head_dim))$transpose(2, 3)\n    \n    # Compute attention scores\n    d_k &lt;- self$head_dim\n    attention_scores &lt;- torch_matmul(Q, torch_transpose(K, -1, -2)) / sqrt(d_k)\n    \n    # Apply mask if provided\n    mask &lt;- torch_tril(torch_ones(c(seq_leng, seq_leng)))\n    \n    if (!is.null(mask)) {\n      \n      masked_attention_scores &lt;- attention_scores$masked_fill(mask == 0, -Inf)\n      \n    } else {\n      print(\"Warning: No mask provided\")\n    }\n    \n    # Compute attention weights\n    weights &lt;- nnf_softmax(masked_attention_scores, dim = -1)\n    \n    # Apply weights to V\n    attn_output &lt;- torch_matmul(weights, V)  # (batch_size, num_heads, seq_leng, head_dim)\n    \n    \n    attn_output &lt;- attn_output$transpose(2, 3)$contiguous()$view(c(batch_size, seq_leng, self$embed_dim))\n    \n    \n    output &lt;- self$out(attn_output)\n    return(output)\n  }\n)\n\n### Cross attention:\ncross_attention &lt;- nn_module(\n  initialize = function(embed_dim, num_heads) {\n    self$embed_dim &lt;- embed_dim\n    self$num_heads &lt;- num_heads\n    self$head_dim &lt;- embed_dim / num_heads\n    \n    if (self$head_dim %% 1 != 0) {\n      stop(\"embed_dim must be divisible by num_heads\")\n    }\n    \n    self$query &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    self$key &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    self$value &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n    self$out &lt;- nn_linear(embed_dim, embed_dim, bias = FALSE)\n  },\n  \n  forward = function(decoder_input, encoder_output, mask = NULL) {\n    batch_size &lt;- decoder_input$size(1)\n    seq_leng_dec &lt;- decoder_input$size(2)\n    seq_leng_enc &lt;- encoder_output$size(2)\n    \n    Q &lt;- self$query(decoder_input)\n    K &lt;- self$key(encoder_output)\n    V &lt;- self$value(encoder_output)\n    \n    Q &lt;- Q$view(c(batch_size, seq_leng_dec, self$num_heads, self$head_dim))$transpose(2, 3)\n    K &lt;- K$view(c(batch_size, seq_leng_enc, self$num_heads, self$head_dim))$transpose(2, 3)\n    V &lt;- V$view(c(batch_size, seq_leng_enc, self$num_heads, self$head_dim))$transpose(2, 3)\n    \n    d_k &lt;- self$head_dim\n    attention_scores &lt;- torch_matmul(Q, torch_transpose(K, -1, -2)) / sqrt(d_k)\n    \n    weights &lt;- nnf_softmax(attention_scores, dim = -1)\n    \n    attn_output &lt;- torch_matmul(weights, V)\n    \n    attn_output &lt;- attn_output$transpose(2, 3)$contiguous()$view(c(batch_size, seq_leng_dec, self$embed_dim))\n    \n    output &lt;- self$out(attn_output)\n    return(output)\n  }\n)\n\n### Decoder Layer\ndecoder_layer &lt;- nn_module(\n  \"TransformerDecoderLayer\",\n  \n  initialize = function(d_model, num_heads, d_ff) {\n    self$mask_self_attention &lt;- mask_self_attention(embed_dim = d_model, num_heads = num_heads)\n    self$cross_attention &lt;- cross_attention(embed_dim = d_model, num_heads = num_heads)\n    self$feed_forward &lt;- nn_sequential(\n      nn_linear(d_model, d_ff),\n      nn_relu(),\n      nn_linear(d_ff, d_model)\n    )\n    \n    self$layer_norm &lt;- nn_layer_norm(d_model)\n  },\n  \n  forward = function(x, encoder_output) {\n    # Masked Self-Attention\n    mask_output &lt;- self$mask_self_attention(x)\n    x &lt;- x + mask_output\n    x &lt;- self$layer_norm(x)\n    \n    # Encoder-Decoder Multi-Head Attention\n    cross_output &lt;- self$cross_attention(x, encoder_output)\n    x &lt;- x + cross_output\n    x &lt;- self$layer_norm(x)\n    \n    # Feedforward Network\n    ff_output &lt;- self$feed_forward(x)\n    x &lt;- x + ff_output\n    x &lt;- self$layer_norm(x)\n    \n    return(x)\n  }\n)\n\n### Final transformer model: \ntransformer &lt;- nn_module(\n  \"Transformer\",\n  \n  initialize = function(d_model, seq_leng, num_heads, d_ff, num_encoder_layers, num_decoder_layers) {\n    self$d_model &lt;- d_model\n    self$num_heads &lt;- num_heads\n    self$d_ff &lt;- d_ff\n    self$num_encoder_layers &lt;- num_encoder_layers\n    self$num_decoder_layers &lt;- num_decoder_layers\n    self$seq_leng &lt;- seq_leng\n    self$en_pe &lt;- en_pe\n    self$de_pe &lt;- de_pe\n    \n    # Encoder layers\n    self$encoder_layers &lt;- nn_module_list(\n      lapply(1:num_encoder_layers, function(i) {\n        encoder_layer(d_model, num_heads, d_ff)\n      })\n    )\n    \n    # Decoder layers\n    self$decoder_layers &lt;- nn_module_list(\n      lapply(1:num_decoder_layers, function(i) {\n        decoder_layer(d_model, num_heads, d_ff)\n      })\n    )\n    \n    # Final output layer\n    self$output_layer &lt;- nn_linear(d_model, 1)  # Output layer to predict a single value\n    \n  },\n  \n  forward = function(src, trg) {\n    \n    src &lt;- src + self$en_pe  \n    trg &lt;- trg + self$de_pe\n    \n    # Encoder forward pass\n    encoder_output &lt;- src\n    for (i in 1:self$num_encoder_layers) {\n      encoder_output &lt;- self$encoder_layers[[i]](encoder_output)\n    }\n    \n    # Decoder forward pass\n    decoder_output &lt;- trg\n    for (i in 1:self$num_decoder_layers) {\n      decoder_output &lt;- self$decoder_layers[[i]](decoder_output, encoder_output)\n    }\n  \n    # Apply final output layer\n    output &lt;- self$output_layer(decoder_output)\n    \n    return(output)\n  }\n)\n\n#### Training----------------------------------------------------------------\nmodel &lt;- transformer(\n  d_model = dim_model,         # Embedding dimension\n  seq_leng = seq_leng,        # Sequence length\n  num_heads = 8,        # Number of heads\n  d_ff = seq_leng,           # Dimension of the feedforward layer\n  num_encoder_layers = 6, \n  num_decoder_layers = 6\n)\n\n\n#### Training----------------------------------------------------------------\nepochs &lt;- 200\nloss_fn &lt;- nn_mse_loss()\noptimizer &lt;- optim_adam(model$parameters, lr = 1e-3)\n\nfor (epoch in 1:epochs) {\n  model$train()\n  optimizer$zero_grad()\n  \n  # Forward pass\n  y_train_pred &lt;- model(x_train, y_train) \n  \n  # Compute the loss\n  loss &lt;- loss_fn(y_train_pred, y_train)\n  \n  # Backpropagation and optimization\n  loss$backward()\n  optimizer$step()\n  \n  if (epoch %% 10 == 0) {\n    cat(\"Epoch: \", epoch, \" Loss: \", loss$item(), \"\\n\")\n  }\n}\n\n#### Predictions----------------------------------------------------------------\nmodel$eval()\n\n# Make predictions on the test data\ny_test_pred &lt;- model(x_test, y_test)  # Use the test data for both input and output during prediction\n\n# Convert tensors to numeric values for comparison\n\ny_test_pred&lt;- as.numeric(as.array(y_test_pred$cpu()))\n\n#### Evaluating----------------------------------------------------------------\nlibrary(highcharter)\ny_train_pred &lt;- as.numeric(as.array(y_train_pred$cpu()))\ny_train &lt;- as.numeric(as.array(y_train$cpu()))\ny_test &lt;- as.numeric(as.array(y_test$cpu()))\n\ncomparison &lt;- data.frame(\n  time = 1:nrow(supervised_data),\n  actual = c(y_train,y_test),\n  forecast = c(y_train_pred,y_test_pred)\n)\n\n# Compare only errors:\nerror&lt;-highchart() |&gt;\n  hc_title(text = \"Evaluating error of model\") |&gt;\n  hc_xAxis(\n    categories = time,\n    title = list(text = \"Time\")\n  ) |&gt;\n  hc_yAxis(\n    title = list(text = \"Value\"),\n    plotLines = list(list(\n      value = 0,\n      width = 1,\n      color = \"gray\"\n    ))\n  ) |&gt; \n  hc_add_series(\n    name = \"Error\",\n    data = (y_test_pred - y_test)/y_test,\n    type = \"line\",\n    color = \"red\"  # Blue color for actual data\n  ) |&gt;\n  hc_tooltip(\n    shared = TRUE,\n    crosshairs = TRUE\n  ) |&gt;\n  hc_legend(\n    enabled = TRUE\n  )\n\n\n# Compare all:\nall&lt;-highchart() |&gt;\n  hc_title(text = \"Model Predictions vs Actual Values\") |&gt;\n  hc_xAxis(\n    categories = time,\n    title = list(text = \"Time\")\n  ) |&gt;\n  hc_yAxis(\n    title = list(text = \"Value\"),\n    plotLines = list(list(\n      value = 0,\n      width = 1,\n      color = \"gray\"\n    ))\n  ) |&gt; \n  hc_add_series(\n    name = \"Actual Data\",\n    data = comparison$actual,\n    type = \"line\",\n    color = \"#1f77b4\"  # Blue color for actual data\n  ) |&gt;\n  hc_add_series(\n    name = \"Forecast\",\n    data = comparison$forecast,\n    type = \"line\",\n    color = \"#ff7f0e\"  # Orange color for forecast data\n  ) |&gt; \n  hc_tooltip(\n    shared = TRUE,\n    crosshairs = TRUE\n  ) |&gt;\n  hc_legend(\n    enabled = TRUE\n  )\n\n\n\n\n\nÄáº§u tiÃªn ta sáº½ Ä‘Ã¡nh giÃ¡ vá» sai sá»‘ cá»§a mÃ´ hÃ¬nh khi dÃ¹ng testing data. Káº¿t quáº£ khÃ¡ á»•n khi sai sá»‘ khoáº£ng (0.04,0.12).\n\n  \n\nVÃ  cÃ²n nhÃ¬n tá»•ng quan háº¿t thÃ¬ ta tháº¥y mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n khÃ¡ sÃ¡t vá»›i training data nhÆ°ng vá»›i testing data thÃ¬ váº«n chÃªnh lá»‡ch tháº¥p hÆ¡n thá»±c táº¿ (dáº¥u hiá»‡u cho tháº¥y mÃ´ hÃ¬nh Ä‘ang bá»‹ overfitting)."
  },
  {
    "objectID": "practice.html#káº¿t-quáº£",
    "href": "practice.html#káº¿t-quáº£",
    "title": "Thá»±c hÃ nh trong R",
    "section": "2 Káº¿t quáº£:",
    "text": "2 Káº¿t quáº£:\n\n  \n\nNáº¿u báº¡n cÃ³ cÃ¢u há»i hay tháº¯c máº¯c nÃ o, Ä‘á»«ng ngáº§n ngáº¡i liÃªn há»‡ vá»›i mÃ¬nh qua Gmail. BÃªn cáº¡nh Ä‘Ã³, náº¿u báº¡n muá»‘n xem láº¡i cÃ¡c bÃ i viáº¿t trÆ°á»›c Ä‘Ã¢y cá»§a mÃ¬nh, hÃ£y nháº¥n vÃ o hai nÃºt dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ truy cáº­p trang Rpubs hoáº·c mÃ£ nguá»“n trÃªn Github. Ráº¥t vui Ä‘Æ°á»£c Ä‘á»“ng hÃ nh cÃ¹ng báº¡n, háº¹n gáº·p láº¡i! ğŸ˜„ğŸ˜„ğŸ˜„\n\n\n\n    \n    \n    Contact Me\n    \n    \n    \n\n\n    \n        Contact Me\n        \n            Your Email:\n            \n            Please enter a valid email address.\n            Send Email\n        \n        \n            \n                \n                     View Code on GitHub\n                \n            \n        \n        \n            \n                \n                     Visit my RPubs"
  },
  {
    "objectID": "practice.html#káº¿t-luáº­n",
    "href": "practice.html#káº¿t-luáº­n",
    "title": "Time series forecasting",
    "section": "2 Káº¿t luáº­n:",
    "text": "2 Káº¿t luáº­n:\nNhÆ° váº­y ta Ä‘Ã£ tháº¥y Ä‘Æ°á»£c sá»©c máº¡nh cá»§a mÃ´ hÃ¬nh Transformer trong dá»± bÃ¡o cho dá»¯ liá»‡u sequence (máº·c dÃ¹ mÃ¬nh mong muá»‘n error rate &lt; 0.05 nhÆ°ng káº¿t quáº£ váº«n cháº¥p nháº­n Ä‘Æ°á»£c).\nMá»™t sá»‘ suggestion cá»§a mÃ¬nh cho mÃ´ hÃ¬nh Transformer Ä‘á»ƒ improve performance nhÆ° sau:\n\nThÃªm layer nn_dropout(p) vÃ o mÃ´ hÃ¬nh: lÃ  má»™t phÆ°Æ¡ng phÃ¡p regularization (chuáº©n hÃ³a) Ä‘Æ°á»£c sá»­ dá»¥ng trong máº¡ng nÆ¡-ron Ä‘á»ƒ ngÄƒn ngá»«a hiá»‡n tÆ°á»£ng overfitting (quÃ¡ khá»›p) báº±ng cÃ¡ch ngáº«u nhiÃªn â€œloáº¡i bá»â€ má»™t tá»· lá»‡ pháº§n trÄƒm nÆ¡-ron trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. Báº¡n chá»‰ cáº§n thÃªm Ä‘á»‘i sá»‘ p lÃ  tá»· lá»‡ % dropout.\nDÃ¹ng cÃ¡c variant cá»§a Transformer: thá»±c cháº¥t má»¥c Ä‘Ã­ch ban Ä‘áº§u cá»§a Transformer lÃ  deal vá»›i cÃ¡c tasks liÃªn quan vá» dá»‹ch thuáº­t, xá»­ lÃ­ vÄƒn báº£n, phÃ¢n tÃ­ch hÃ¬nh áº£nh,â€¦ chá»© khÃ´ng thiÃªn vá» time series forecasting. MÃ´ hÃ¬nh deep learning khÃ¡c thiÃªn vá» váº¥n Ä‘á» nÃ y mÃ  báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng lÃ  Informer.\n\nNáº¿u báº¡n cÃ³ cÃ¢u há»i hay tháº¯c máº¯c nÃ o, Ä‘á»«ng ngáº§n ngáº¡i liÃªn há»‡ vá»›i mÃ¬nh qua Gmail. BÃªn cáº¡nh Ä‘Ã³, náº¿u báº¡n muá»‘n xem láº¡i cÃ¡c bÃ i viáº¿t trÆ°á»›c Ä‘Ã¢y cá»§a mÃ¬nh, hÃ£y nháº¥n vÃ o hai nÃºt dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ truy cáº­p trang Rpubs hoáº·c mÃ£ nguá»“n trÃªn Github. Ráº¥t vui Ä‘Æ°á»£c Ä‘á»“ng hÃ nh cÃ¹ng báº¡n, háº¹n gáº·p láº¡i! ğŸ˜„ğŸ˜„ğŸ˜„\n\n\n\n    \n    \n    Contact Me\n    \n    \n    \n\n\n    \n        Contact Me\n        \n            Your Email:\n            \n            Please enter a valid email address.\n            Send Email\n        \n        \n            \n                \n                     View Code on GitHub\n                \n            \n        \n        \n            \n                \n                     Visit my RPubs"
  }
]